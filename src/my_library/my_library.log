2025-05-10 18:03:37,042 - INFO - Logger has been set up successfully.
2025-05-10 18:03:37,043 - WARNING - This is a warning message.
2025-05-10 18:03:37,043 - ERROR - This is an error message.
2025-05-10 18:03:37,043 - CRITICAL - This is a critical message.
2025-05-10 18:11:40,337 - INFO - PyTorch version 2.6.0 available.
2025-05-10 18:11:40,338 - INFO - Polars version 1.27.1 available.
2025-05-10 18:11:41,492 - INFO - Initializing RAG components for gemini...
2025-05-10 18:11:41,583 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite "HTTP/1.1 200 OK"
2025-05-10 18:11:41,594 - INFO - gemini LLM initialized successfully
2025-05-10 18:11:41,595 - INFO - gemini embedding model initialized successfully
2025-05-10 18:11:41,769 - INFO - Gemini embedding dimension: 768
2025-05-10 18:11:41,826 - INFO - Testing RAG service for table: data_vasilias_weddings_2025_05_05
2025-05-10 18:11:42,105 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-10 18:11:42,108 - INFO - Query embedding dimension: 768
2025-05-10 18:11:42,697 - ERROR - Error in test_retrieval: relation "vasilias_weddings_2025_05_05" does not exist
LINE 1: SELECT COUNT(*) FROM "vasilias_weddings_2025_05_05"
                             ^

2025-05-10 18:11:42,698 - INFO - New question received
2025-05-10 18:11:42,698 - INFO - Using retriever with similarity_top_k=3
2025-05-10 18:11:42,938 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-10 18:11:44,233 - INFO - Retrieved 3 nodes
2025-05-10 18:11:44,233 - INFO - First retrieved node text: Question: Can you help with legal requirements for getting married in Cyprus?
Answer: Absolutely! ...
2025-05-10 18:11:44,233 - INFO - First retrieved node score: 0.9689950314666403
2025-05-10 18:11:44,536 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-10 18:11:44,688 - INFO - AFC is enabled with max remote calls: 10.
2025-05-10 18:11:45,251 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent "HTTP/1.1 200 OK"
2025-05-10 18:11:45,252 - INFO - AFC remote call 1 is done.
2025-05-10 18:11:45,253 - INFO - Response generated successfully
2025-05-10 18:11:45,253 - INFO - New question received
2025-05-10 18:11:45,253 - INFO - Using retriever with similarity_top_k=3
2025-05-10 18:11:45,560 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-10 18:11:45,704 - INFO - Retrieved 3 nodes
2025-05-10 18:11:45,704 - INFO - First retrieved node text: We can tailor options to your budget and style....
2025-05-10 18:11:45,704 - INFO - First retrieved node score: 0.9655036103932
2025-05-10 18:11:45,969 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-10 18:11:46,120 - INFO - AFC is enabled with max remote calls: 10.
2025-05-10 18:11:46,685 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent "HTTP/1.1 200 OK"
2025-05-10 18:11:46,687 - INFO - AFC remote call 1 is done.
2025-05-10 18:11:46,688 - INFO - Response generated successfully
2025-05-10 18:11:46,689 - INFO - New question received
2025-05-10 18:11:46,689 - INFO - Using retriever with similarity_top_k=3
2025-05-10 18:11:46,994 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-10 18:11:47,140 - INFO - Retrieved 3 nodes
2025-05-10 18:11:47,140 - INFO - First retrieved node text: Question: What is the average cost of a wedding in Cyprus?
Answer: Costs can vary depending on the n...
2025-05-10 18:11:47,140 - INFO - First retrieved node score: 0.9623539231151037
2025-05-10 18:11:47,403 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-10 18:11:47,553 - INFO - AFC is enabled with max remote calls: 10.
2025-05-10 18:11:48,119 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent "HTTP/1.1 200 OK"
2025-05-10 18:11:48,121 - INFO - AFC remote call 1 is done.
2025-05-10 18:11:48,122 - INFO - Response generated successfully
2025-05-24 12:03:23,880 - INFO - PyTorch version 2.6.0 available.
2025-05-24 12:03:23,880 - INFO - Polars version 1.27.1 available.
2025-05-24 12:03:25,335 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:03:25,337 - INFO - Gemini LLM initialized successfully
2025-05-24 12:03:25,533 - INFO - Documents loaded successfully from ./data/VW_dataMar25.txt
2025-05-24 12:03:25,533 - INFO - First document: Title: Why a Groom-To-Be Should Have a Stag Do

Co...
2025-05-24 12:03:25,602 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:03:25,615 - INFO - Connecting to PostgreSQL database: chatbot_rag at 95.217.166.72:5432 as user chatbot
2025-05-24 12:03:25,615 - INFO - Using table name: vasilias_weddings_2025_05_24
2025-05-24 12:03:25,616 - INFO - Vector store created successfully: vasilias_weddings_2025_05_24
2025-05-24 12:03:25,616 - INFO - Storing documents in table: vasilias_weddings_2025_05_24
2025-05-24 12:03:26,043 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:26,349 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:26,623 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:26,902 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:27,270 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:27,681 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:27,987 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:28,294 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:28,705 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:29,011 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:29,318 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:29,585 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:29,932 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:30,240 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:30,547 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:30,854 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:31,192 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:31,571 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:31,982 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:32,288 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:32,697 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:33,107 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:33,414 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:33,767 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:34,032 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:34,438 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:34,746 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:35,053 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:35,360 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:35,667 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:35,974 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:36,281 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:36,588 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:36,897 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:37,204 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:37,715 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:38,023 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:38,329 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:38,636 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:38,905 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:39,251 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:39,558 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:39,867 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:40,136 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:40,404 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:40,684 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:40,993 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:41,299 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:41,607 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:41,913 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:42,178 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:42,528 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:43,118 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:45,395 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:48,365 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:50,413 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:51,437 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:51,948 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:52,212 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:52,563 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:52,972 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:53,281 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:53,586 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:53,895 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:54,154 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:54,416 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:54,677 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:55,123 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:55,533 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:55,840 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:56,147 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:56,454 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:56,762 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:57,068 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:57,329 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:57,785 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:58,195 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:58,604 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:59,014 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:59,277 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:03:59,637 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:00,039 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:00,304 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:00,634 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:00,960 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:01,267 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:01,575 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:01,983 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:02,291 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:02,598 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:02,906 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:03,168 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:03,521 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:03,827 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:04,134 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:04,392 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:04,660 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:05,017 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:05,275 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:05,533 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:05,790 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:06,056 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:06,379 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:06,718 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:06,977 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:07,299 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:07,555 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:07,812 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:08,076 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:08,343 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:08,603 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:08,869 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:09,126 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:09,392 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:09,649 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:09,971 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:10,231 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:10,495 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:10,893 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:11,182 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:11,514 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:11,771 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:12,096 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:12,420 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:12,737 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:13,043 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:13,350 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:13,657 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:13,920 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:14,272 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:14,580 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:14,831 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:15,194 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:15,501 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:15,809 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:16,072 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:16,336 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:16,627 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:16,935 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:17,344 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:17,651 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:18,006 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:18,268 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:18,559 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:18,819 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:19,187 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:19,444 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:19,801 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:20,211 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:20,473 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:20,825 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:21,114 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:21,377 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:21,645 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:21,953 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:22,227 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:22,669 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:22,977 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:23,314 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:23,579 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:23,898 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:24,204 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:24,537 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:24,819 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:25,078 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:25,411 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:25,670 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:26,028 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:26,383 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:26,644 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:26,903 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:27,159 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:27,678 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:28,285 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:28,545 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:04:28,575 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 429 Too Many Requests"
2025-05-24 12:04:28,577 - ERROR - Error storing documents: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': "Quota exceeded for quota metric 'Batch Embed Content API requests' and limit 'Batch embed contents request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:752232435893'.", 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'RATE_LIMIT_EXCEEDED', 'domain': 'googleapis.com', 'metadata': {'quota_unit': '1/min/{project}/{region}', 'quota_location': 'europe-west1', 'quota_limit': 'BatchEmbedContentsRequestsPerMinutePerProjectPerRegion', 'quota_limit_value': '150', 'service': 'generativelanguage.googleapis.com', 'quota_metric': 'generativelanguage.googleapis.com/batch_embed_contents_requests', 'consumer': 'projects/752232435893'}}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Request a higher quota limit.', 'url': 'https://cloud.google.com/docs/quotas/help/request_increase'}]}]}}
2025-05-24 12:04:28,670 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:04:28,673 - INFO - Gemini LLM initialized successfully
2025-05-24 12:04:28,694 - INFO - Parsed 134 documents from CSV file ./data/VWFAQ24052025.csv
2025-05-24 12:04:28,694 - INFO - Documents loaded successfully from ./data/VWFAQ24052025.csv
2025-05-24 12:04:28,694 - INFO - First document: Question: Can you help with legal requirements for...
2025-05-24 12:04:28,749 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:04:28,761 - INFO - Connecting to PostgreSQL database: chatbot_rag at 95.217.166.72:5432 as user chatbot
2025-05-24 12:04:28,761 - INFO - Using table name: vasilias_weddings_2025_05_24
2025-05-24 12:04:28,763 - INFO - Vector store created successfully: vasilias_weddings_2025_05_24
2025-05-24 12:04:28,763 - INFO - Storing documents in table: vasilias_weddings_2025_05_24
2025-05-24 12:04:28,787 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 429 Too Many Requests"
2025-05-24 12:04:28,788 - ERROR - Error storing documents: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': "Quota exceeded for quota metric 'Batch Embed Content API requests' and limit 'Batch embed contents request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:752232435893'.", 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'RATE_LIMIT_EXCEEDED', 'domain': 'googleapis.com', 'metadata': {'quota_metric': 'generativelanguage.googleapis.com/batch_embed_contents_requests', 'quota_limit': 'BatchEmbedContentsRequestsPerMinutePerProjectPerRegion', 'quota_location': 'europe-west1', 'quota_unit': '1/min/{project}/{region}', 'consumer': 'projects/752232435893', 'service': 'generativelanguage.googleapis.com', 'quota_limit_value': '150'}}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Request a higher quota limit.', 'url': 'https://cloud.google.com/docs/quotas/help/request_increase'}]}]}}
2025-05-24 12:09:19,246 - INFO - PyTorch version 2.6.0 available.
2025-05-24 12:09:19,247 - INFO - Polars version 1.27.1 available.
2025-05-24 12:09:20,362 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:09:20,364 - INFO - Gemini LLM initialized successfully
2025-05-24 12:09:20,549 - INFO - Parsed 134 documents from CSV file ./data/VWFAQ24052025.csv
2025-05-24 12:09:20,549 - INFO - Documents loaded successfully from ./data/VWFAQ24052025.csv
2025-05-24 12:09:20,549 - INFO - First document: Question: Can you help with legal requirements for...
2025-05-24 12:09:20,607 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:09:20,619 - INFO - Connecting to PostgreSQL database: chatbot_rag at 95.217.166.72:5432 as user chatbot
2025-05-24 12:09:20,619 - INFO - Using table name: vasilias_weddings_2025_05_24
2025-05-24 12:09:20,620 - INFO - Vector store created successfully: vasilias_weddings_2025_05_24
2025-05-24 12:09:20,621 - INFO - Storing documents in table: vasilias_weddings_2025_05_24
2025-05-24 12:09:20,688 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 429 Too Many Requests"
2025-05-24 12:09:20,689 - ERROR - Error storing documents: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': "Quota exceeded for quota metric 'Batch Embed Content API requests' and limit 'Batch embed contents request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:752232435893'.", 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'RATE_LIMIT_EXCEEDED', 'domain': 'googleapis.com', 'metadata': {'quota_location': 'europe-west1', 'quota_unit': '1/min/{project}/{region}', 'quota_metric': 'generativelanguage.googleapis.com/batch_embed_contents_requests', 'service': 'generativelanguage.googleapis.com', 'consumer': 'projects/752232435893', 'quota_limit_value': '150', 'quota_limit': 'BatchEmbedContentsRequestsPerMinutePerProjectPerRegion'}}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Request a higher quota limit.', 'url': 'https://cloud.google.com/docs/quotas/help/request_increase'}]}]}}
2025-05-24 12:19:51,769 - INFO - PyTorch version 2.6.0 available.
2025-05-24 12:19:51,770 - INFO - Polars version 1.27.1 available.
2025-05-24 12:19:52,863 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:19:52,866 - INFO - Gemini LLM initialized successfully
2025-05-24 12:19:53,052 - INFO - Parsed 134 documents from CSV file ./data/VWFAQ24052025.csv
2025-05-24 12:19:53,052 - INFO - Documents loaded successfully from ./data/VWFAQ24052025.csv
2025-05-24 12:19:53,052 - INFO - First document: Question: Can you help with legal requirements for...
2025-05-24 12:19:53,115 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:19:53,127 - INFO - Connecting to PostgreSQL database: chatbot_rag at 95.217.166.72:5432 as user chatbot
2025-05-24 12:19:53,127 - INFO - Using table name: vasilias_weddings_2025_05_24
2025-05-24 12:19:53,128 - INFO - Vector store created successfully: vasilias_weddings_2025_05_24
2025-05-24 12:19:53,128 - INFO - Storing documents in table: vasilias_weddings_2025_05_24
2025-05-24 12:19:53,487 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:53,799 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:54,027 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:54,306 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:54,612 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:54,920 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:55,227 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:55,534 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:55,762 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:56,046 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:56,353 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:56,660 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:56,968 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:57,275 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:57,583 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:57,892 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:58,196 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:58,431 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:58,709 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:59,016 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:59,323 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:59,630 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:19:59,895 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:00,244 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:00,553 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:00,860 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:01,166 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:01,473 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:01,781 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:02,088 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:02,395 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:02,702 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:03,012 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:03,317 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:03,539 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:03,829 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:04,136 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:04,442 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:04,746 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:05,059 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:05,365 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:05,673 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:05,979 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:06,223 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:06,467 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:06,716 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:06,961 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:07,177 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:07,516 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:07,742 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:07,959 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:08,232 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:08,477 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:08,729 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:08,946 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:09,174 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:09,391 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:09,608 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:09,870 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:10,179 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:10,434 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:10,659 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:10,887 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:11,132 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:11,353 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:11,610 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:11,860 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:12,089 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:12,304 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:12,534 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:12,767 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:13,009 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:13,256 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:13,469 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:13,702 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:13,940 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:14,183 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:14,420 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:14,631 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:14,848 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:15,063 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:15,311 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:15,540 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:15,809 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:16,118 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:16,420 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:16,669 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:16,902 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:17,147 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:17,426 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:17,756 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:18,062 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:18,371 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:18,621 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:18,839 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:19,051 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:19,265 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:19,491 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:19,699 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:20,008 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:20,315 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:20,560 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:20,784 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:21,014 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:21,243 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:21,461 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:21,694 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:21,906 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:22,133 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:22,351 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:22,671 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:22,901 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:23,131 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:23,344 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:23,592 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:23,821 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:24,066 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:24,285 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:24,530 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:24,745 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:25,026 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:25,333 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:25,548 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:25,759 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:25,970 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:26,187 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:26,459 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:26,708 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:27,010 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:27,238 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:27,482 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:27,705 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:27,934 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:28,162 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:20:29,471 - ERROR - Error storing documents: 'dict' object has no attribute 'node_id'
2025-05-24 12:24:27,706 - INFO - PyTorch version 2.6.0 available.
2025-05-24 12:24:27,707 - INFO - Polars version 1.27.1 available.
2025-05-24 12:24:28,892 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:24:28,894 - INFO - Gemini LLM initialized successfully
2025-05-24 12:24:29,124 - INFO - Parsed 134 documents from CSV file ./data/VWFAQ24052025.csv
2025-05-24 12:24:29,125 - INFO - Documents loaded successfully from ./data/VWFAQ24052025.csv
2025-05-24 12:24:29,125 - INFO - First document: Question: Can you help with legal requirements for...
2025-05-24 12:24:29,187 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:24:29,200 - INFO - Connecting to PostgreSQL database: chatbot_rag at 95.217.166.72:5432 as user chatbot
2025-05-24 12:24:29,200 - INFO - Using table name: vasilias_weddings_2025_05_24
2025-05-24 12:24:29,201 - INFO - Vector store created successfully: vasilias_weddings_2025_05_24
2025-05-24 12:24:29,201 - INFO - Storing documents in table: vasilias_weddings_2025_05_24
2025-05-24 12:24:29,499 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:24:29,501 - ERROR - Error storing documents: name 'BaseNode' is not defined
2025-05-24 12:31:17,671 - INFO - PyTorch version 2.6.0 available.
2025-05-24 12:31:17,672 - INFO - Polars version 1.27.1 available.
2025-05-24 12:31:18,834 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:31:18,837 - INFO - Gemini LLM initialized successfully
2025-05-24 12:31:19,030 - INFO - Parsed 134 documents from CSV file ./data/VWFAQ24052025.csv
2025-05-24 12:31:19,030 - INFO - Documents loaded successfully from ./data/VWFAQ24052025.csv
2025-05-24 12:31:19,030 - INFO - First document: Question: Can you help with legal requirements for...
2025-05-24 12:31:19,089 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:31:19,101 - INFO - Connecting to PostgreSQL database: chatbot_rag at 95.217.166.72:5432 as user chatbot
2025-05-24 12:31:19,101 - INFO - Using table name: vasilias_weddings_2025_05_24
2025-05-24 12:31:19,102 - INFO - Vector store created successfully: vasilias_weddings_2025_05_24
2025-05-24 12:31:19,102 - INFO - Storing documents in table: vasilias_weddings_2025_05_24
2025-05-24 12:31:19,466 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:19,772 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:20,079 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:20,386 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:20,694 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:21,002 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:21,308 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:21,615 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:21,925 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:22,231 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:22,454 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:22,672 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:22,949 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:23,254 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:23,561 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:23,869 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:24,175 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:24,409 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:24,687 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:24,937 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:24,956 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 502 Bad Gateway"
2025-05-24 12:31:24,957 - ERROR - Error during embedding: 502 Bad Gateway. {'message': '<!DOCTYPE html>\n<html lang=en>\n  <meta charset=utf-8>\n  <meta name=viewport content="initial-scale=1, minimum-scale=1, width=device-width">\n  <title>Error 502 (Server Error)!!1</title>\n  <style>\n    *{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}\n  </style>\n  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>\n  <p><b>502.</b> <ins>That’s an error.</ins>\n  <p>The server encountered a temporary error and could not complete your request.<p>Please try again in 30 seconds.  <ins>That’s all we know.</ins>\n', 'status': 'Bad Gateway'}
2025-05-24 12:31:24,957 - WARNING - Failed to embed document ed564e7d-39a2-4332-9493-0810b9180aa4
2025-05-24 12:31:25,175 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:25,507 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:25,814 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:26,121 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:26,428 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:26,735 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:27,044 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:27,350 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:27,656 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:27,962 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:28,270 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:28,578 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:28,827 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:29,060 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:29,330 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:29,550 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:29,807 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:30,025 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:30,289 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:30,518 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:30,832 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:31,077 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:31,343 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:31,650 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:31,867 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:32,164 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:32,382 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:32,613 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:32,879 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:35,644 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 502 Bad Gateway"
2025-05-24 12:31:35,646 - ERROR - Error during embedding: 502 Bad Gateway. {'message': '<!DOCTYPE html>\n<html lang=en>\n  <meta charset=utf-8>\n  <meta name=viewport content="initial-scale=1, minimum-scale=1, width=device-width">\n  <title>Error 502 (Server Error)!!1</title>\n  <style>\n    *{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}\n  </style>\n  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>\n  <p><b>502.</b> <ins>That’s an error.</ins>\n  <p>The server encountered a temporary error and could not complete your request.<p>Please try again in 30 seconds.  <ins>That’s all we know.</ins>\n', 'status': 'Bad Gateway'}
2025-05-24 12:31:35,646 - WARNING - Failed to embed document ca11fd64-1c4d-4a3a-ac56-23d9b83fecd8
2025-05-24 12:31:35,863 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:36,080 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:36,292 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:36,509 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:36,770 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:37,078 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:37,386 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:37,693 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:37,999 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:38,308 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:38,552 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:38,818 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:39,058 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:39,332 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:39,637 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:39,945 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:40,252 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:40,559 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:40,970 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:41,277 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:41,686 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:42,096 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:42,505 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:42,915 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:43,529 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:44,584 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:48,549 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:50,698 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:50,913 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:51,130 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:51,517 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:51,733 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:51,948 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:52,541 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:52,847 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:53,464 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:54,076 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:54,589 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:55,101 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:55,318 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:55,535 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:56,044 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:56,257 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:56,502 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:56,802 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:57,149 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:57,765 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:58,173 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:58,583 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:58,912 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:59,136 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:59,397 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:59,647 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:31:59,862 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:00,083 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:00,322 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:00,537 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:00,753 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:01,039 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:01,283 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:01,551 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:01,765 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:01,976 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:02,213 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:02,460 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:02,676 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:02,985 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:03,225 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:03,496 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:03,743 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:03,988 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:04,217 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:04,522 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:04,829 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:05,079 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:05,325 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:05,750 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:05,985 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:06,201 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:06,466 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:06,681 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:06,981 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:07,229 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:32:08,437 - ERROR - Error storing documents: 'dict' object has no attribute 'node_id'
2025-05-24 12:34:31,208 - INFO - PyTorch version 2.6.0 available.
2025-05-24 12:34:31,208 - INFO - Polars version 1.27.1 available.
2025-05-24 12:34:32,314 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:34:32,316 - INFO - Gemini LLM initialized successfully
2025-05-24 12:34:32,510 - INFO - Parsed 134 documents from CSV file ./data/VWFAQ24052025.csv
2025-05-24 12:34:32,510 - INFO - Documents loaded successfully from ./data/VWFAQ24052025.csv
2025-05-24 12:34:32,510 - INFO - First document: Question: Can you help with legal requirements for...
2025-05-24 12:34:32,597 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:34:32,610 - INFO - Connecting to PostgreSQL database: chatbot_rag at 95.217.166.72:5432 as user chatbot
2025-05-24 12:34:32,610 - INFO - Using table name: vasilias_weddings_2025_05_24
2025-05-24 12:34:32,611 - INFO - Vector store created successfully: vasilias_weddings_2025_05_24
2025-05-24 12:34:32,612 - INFO - Storing documents in table: vasilias_weddings_2025_05_24
2025-05-24 12:34:32,899 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:33,118 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:33,413 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:33,821 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:34,128 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:34,437 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:34,684 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:34,908 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:35,151 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:35,461 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:35,767 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:36,075 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:36,306 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:36,522 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:36,790 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:37,097 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:37,404 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:37,711 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:37,944 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:38,159 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:38,380 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:38,633 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:38,941 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:39,164 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:39,453 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:39,680 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:39,964 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:40,271 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:40,581 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:40,887 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:41,193 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:41,472 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:41,717 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:42,012 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:42,319 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:42,628 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:42,858 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:43,139 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:43,464 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:43,999 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:45,290 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:47,908 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:49,361 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:50,145 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:50,394 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:50,717 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:51,024 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:51,331 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:51,638 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:51,946 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:52,174 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:52,389 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:52,662 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:52,912 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:53,164 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:53,482 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:53,789 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:54,020 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:54,245 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:54,505 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:54,733 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:54,950 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:55,222 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:55,530 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:55,748 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:55,978 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:56,223 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:56,475 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:56,722 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:56,951 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:57,271 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:57,577 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:57,884 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:58,109 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:58,363 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:58,582 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:58,799 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:59,029 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:59,250 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:59,471 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:59,701 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:34:59,945 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:00,240 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:00,492 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:00,720 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:00,956 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:01,175 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:01,469 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:01,715 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:01,952 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:02,391 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:02,698 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:03,006 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:03,312 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:03,618 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:03,927 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:04,234 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:04,465 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:04,684 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:04,950 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:05,181 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:05,463 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:05,680 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:05,900 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:06,116 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:06,384 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:06,691 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:06,998 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:07,306 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:07,613 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:07,921 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:08,330 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:08,637 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:08,944 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:09,223 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:09,447 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:09,764 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:10,071 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:10,290 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:10,582 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:10,890 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:11,197 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:11,504 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:11,750 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:12,016 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:12,325 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:12,555 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:12,804 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:13,142 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:13,451 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:13,757 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:13,971 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:14,205 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:14,450 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:35:14,453 - ERROR - Error storing documents: 'PGVectorStore' object has no attribute 'add_nodes'
2025-05-24 12:37:11,420 - INFO - PyTorch version 2.6.0 available.
2025-05-24 12:37:11,420 - INFO - Polars version 1.27.1 available.
2025-05-24 12:37:12,644 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:37:12,650 - INFO - Gemini LLM initialized successfully
2025-05-24 12:37:12,851 - INFO - Parsed 134 documents from CSV file ./data/VWFAQ24052025.csv
2025-05-24 12:37:12,851 - INFO - Documents loaded successfully from ./data/VWFAQ24052025.csv
2025-05-24 12:37:12,851 - INFO - First document: Question: Can you help with legal requirements for...
2025-05-24 12:37:12,913 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:37:12,924 - INFO - Connecting to PostgreSQL database: chatbot_rag at 95.217.166.72:5432 as user chatbot
2025-05-24 12:37:12,924 - INFO - Using table name: vasilias_weddings_2025_05_24
2025-05-24 12:37:12,925 - INFO - Vector store created successfully: vasilias_weddings_2025_05_24
2025-05-24 12:37:12,925 - INFO - Storing documents in table: vasilias_weddings_2025_05_24
2025-05-24 12:37:13,194 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:13,439 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:13,654 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:13,869 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:14,121 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:14,384 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:14,640 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:14,868 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:15,096 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:15,319 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:15,539 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:15,789 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:16,006 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:16,229 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:16,535 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:16,842 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:17,149 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:17,455 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:17,763 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:17,981 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:18,230 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:18,479 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:18,759 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:19,095 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:19,401 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:19,620 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:19,913 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:20,128 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:20,425 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:20,733 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:21,040 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:21,264 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:21,553 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:21,859 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:22,073 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:22,304 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:22,536 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:22,781 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:23,090 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:23,397 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:23,651 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:23,873 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:23,899 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 503 Service Unavailable"
2025-05-24 12:37:23,900 - ERROR - Error during embedding: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The service is currently unavailable.', 'status': 'UNAVAILABLE'}}
2025-05-24 12:37:23,901 - WARNING - Failed to embed document 6c3d5963-e565-4fcb-9aaf-4bfde8047f31
2025-05-24 12:37:24,214 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:24,521 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:24,737 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:25,034 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:25,341 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:25,590 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:25,852 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:26,160 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:26,376 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:26,594 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:26,808 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:27,081 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:27,389 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:27,628 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:27,845 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:28,056 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:28,273 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:28,538 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:28,781 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:28,814 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 503 Service Unavailable"
2025-05-24 12:37:28,816 - ERROR - Error during embedding: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The service is currently unavailable.', 'status': 'UNAVAILABLE'}}
2025-05-24 12:37:28,816 - WARNING - Failed to embed document bae70a1d-e49f-4d1a-8144-366c73e7d00f
2025-05-24 12:37:29,130 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:29,436 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:29,662 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:29,895 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:30,150 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:30,365 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:30,601 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:30,869 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:31,176 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:31,396 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:31,610 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:31,835 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:32,098 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:32,405 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:32,622 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:32,919 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:33,225 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:33,445 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:33,661 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:33,689 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 503 Service Unavailable"
2025-05-24 12:37:33,691 - ERROR - Error during embedding: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The service is currently unavailable.', 'status': 'UNAVAILABLE'}}
2025-05-24 12:37:33,691 - WARNING - Failed to embed document fbf57a8a-5cb3-4b97-bf07-65ea3f49c001
2025-05-24 12:37:33,934 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:34,205 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:34,454 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:34,761 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:35,069 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:35,315 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:35,685 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:35,992 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:36,210 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:36,502 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:36,810 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:37,116 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:37,345 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:37,592 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:37,818 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:38,036 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:38,278 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:38,501 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:38,757 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:38,985 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:39,267 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:39,575 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:39,823 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:39,845 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 503 Service Unavailable"
2025-05-24 12:37:39,845 - ERROR - Error during embedding: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The service is currently unavailable.', 'status': 'UNAVAILABLE'}}
2025-05-24 12:37:39,845 - WARNING - Failed to embed document 57c9c051-0ede-499a-9b3e-4cbfb805c4d2
2025-05-24 12:37:40,090 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:40,320 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:40,598 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:40,818 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:41,110 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:41,418 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:41,724 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:41,970 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:42,189 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:42,545 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:42,792 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:43,055 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:43,366 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:43,669 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:44,183 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:44,215 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 503 Service Unavailable"
2025-05-24 12:37:44,217 - ERROR - Error during embedding: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The service is currently unavailable.', 'status': 'UNAVAILABLE'}}
2025-05-24 12:37:44,217 - WARNING - Failed to embed document c9c2ac01-d487-4b49-aa13-c9f1679a5d8c
2025-05-24 12:37:45,250 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:47,359 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:48,010 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:48,226 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:49,714 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:49,932 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:50,523 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:50,840 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:51,083 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:51,325 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:51,542 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:37:53,386 - INFO - Stored 129 documents in table: vasilias_weddings_2025_05_24
2025-05-24 12:38:26,692 - INFO - PyTorch version 2.6.0 available.
2025-05-24 12:38:26,693 - INFO - Polars version 1.27.1 available.
2025-05-24 12:38:27,810 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:38:27,811 - INFO - Gemini LLM initialized successfully
2025-05-24 12:38:27,995 - INFO - Documents loaded successfully from ./data/VW_dataMar25.txt
2025-05-24 12:38:27,995 - INFO - First document: Title: Why a Groom-To-Be Should Have a Stag Do

Co...
2025-05-24 12:38:28,056 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:38:28,068 - INFO - Connecting to PostgreSQL database: chatbot_rag at 95.217.166.72:5432 as user chatbot
2025-05-24 12:38:28,068 - INFO - Using table name: vasilias_weddings_2025_05_24
2025-05-24 12:38:28,069 - INFO - Vector store created successfully: vasilias_weddings_2025_05_24
2025-05-24 12:38:28,069 - INFO - Storing documents in table: vasilias_weddings_2025_05_24
2025-05-24 12:38:28,626 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:38:30,298 - INFO - Stored 1 documents in table: vasilias_weddings_2025_05_24
2025-05-24 12:41:23,087 - INFO - PyTorch version 2.6.0 available.
2025-05-24 12:41:23,088 - INFO - Polars version 1.27.1 available.
2025-05-24 12:41:24,161 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:41:24,163 - INFO - Gemini LLM initialized successfully
2025-05-24 12:41:24,352 - INFO - Documents loaded successfully from ./data/VW_dataMar25.txt
2025-05-24 12:41:24,353 - INFO - First document: Title: Why a Groom-To-Be Should Have a Stag Do

Co...
2025-05-24 12:41:24,447 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:41:24,461 - INFO - Connecting to PostgreSQL database: chatbot_rag at 95.217.166.72:5432 as user chatbot
2025-05-24 12:41:24,461 - INFO - Using table name: vasilias_weddings_2025_05_24
2025-05-24 12:41:24,462 - INFO - Vector store created successfully: vasilias_weddings_2025_05_24
2025-05-24 12:41:24,462 - INFO - Storing documents in table: vasilias_weddings_2025_05_24
2025-05-24 12:41:24,853 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:41:26,446 - INFO - Stored 1 documents in table: vasilias_weddings_2025_05_24
2025-05-24 12:42:45,819 - INFO - PyTorch version 2.6.0 available.
2025-05-24 12:42:45,819 - INFO - Polars version 1.27.1 available.
2025-05-24 12:42:46,769 - INFO - Initializing RAG components for gemini...
2025-05-24 12:42:46,836 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:42:46,846 - INFO - gemini LLM initialized successfully
2025-05-24 12:42:46,848 - INFO - gemini embedding model initialized successfully
2025-05-24 12:42:47,023 - INFO - Gemini embedding dimension: 768
2025-05-24 12:42:47,083 - INFO - Testing RAG service for table: vasilias_weddings_2025_05_24
2025-05-24 12:42:48,185 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:42:48,187 - INFO - Query embedding dimension: 768
2025-05-24 12:42:48,716 - ERROR - Error in test_retrieval: relation "vasilias_weddings_2025_05_05" does not exist
LINE 1: SELECT COUNT(*) FROM "vasilias_weddings_2025_05_05"
                             ^

2025-05-24 12:42:48,717 - INFO - New question received
2025-05-24 12:42:48,717 - INFO - Using retriever with similarity_top_k=3
2025-05-24 12:42:49,028 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:42:50,416 - INFO - Retrieved 3 nodes
2025-05-24 12:42:50,416 - INFO - First retrieved node text: Question: Can you help with legal requirements for getting married in Cyprus?
Answer: Absolutely! ...
2025-05-24 12:42:50,416 - INFO - First retrieved node score: 0.9689950314666403
2025-05-24 12:42:50,660 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:42:50,822 - INFO - AFC is enabled with max remote calls: 10.
2025-05-24 12:42:51,623 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent "HTTP/1.1 200 OK"
2025-05-24 12:42:51,626 - INFO - AFC remote call 1 is done.
2025-05-24 12:42:51,627 - INFO - Response generated successfully
2025-05-24 12:42:51,627 - INFO - New question received
2025-05-24 12:42:51,628 - INFO - Using retriever with similarity_top_k=3
2025-05-24 12:42:51,847 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:42:51,999 - INFO - Retrieved 3 nodes
2025-05-24 12:42:51,999 - INFO - First retrieved node text: We can tailor options to your budget and style....
2025-05-24 12:42:51,999 - INFO - First retrieved node score: 0.9655036103932
2025-05-24 12:42:52,255 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:42:52,411 - INFO - AFC is enabled with max remote calls: 10.
2025-05-24 12:42:53,111 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent "HTTP/1.1 200 OK"
2025-05-24 12:42:53,113 - INFO - AFC remote call 1 is done.
2025-05-24 12:42:53,114 - INFO - Response generated successfully
2025-05-24 12:42:53,115 - INFO - New question received
2025-05-24 12:42:53,115 - INFO - Using retriever with similarity_top_k=3
2025-05-24 12:42:53,433 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:42:53,587 - INFO - Retrieved 3 nodes
2025-05-24 12:42:53,587 - INFO - First retrieved node text: Question: What is the average cost of a wedding in Cyprus?
Answer: Costs can vary depending on the n...
2025-05-24 12:42:53,587 - INFO - First retrieved node score: 0.9623539231151037
2025-05-24 12:42:53,840 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:42:53,995 - INFO - AFC is enabled with max remote calls: 10.
2025-05-24 12:42:55,172 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent "HTTP/1.1 200 OK"
2025-05-24 12:42:55,174 - INFO - AFC remote call 1 is done.
2025-05-24 12:42:55,175 - INFO - Response generated successfully
2025-05-24 12:44:55,759 - INFO - PyTorch version 2.6.0 available.
2025-05-24 12:44:55,759 - INFO - Polars version 1.27.1 available.
2025-05-24 12:44:56,602 - INFO - Initializing RAG components for gemini...
2025-05-24 12:44:56,680 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-05-24 12:44:56,690 - INFO - gemini LLM initialized successfully
2025-05-24 12:44:56,691 - INFO - gemini embedding model initialized successfully
2025-05-24 12:44:56,834 - INFO - Gemini embedding dimension: 768
2025-05-24 12:44:56,888 - INFO - Testing RAG service for table: vasilias_weddings_2025_05_24
2025-05-24 12:44:57,233 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:44:57,236 - INFO - Query embedding dimension: 768
2025-05-24 12:44:57,769 - ERROR - Error in test_retrieval: relation "vasilias_weddings_2025_05_05" does not exist
LINE 1: SELECT COUNT(*) FROM "vasilias_weddings_2025_05_05"
                             ^

2025-05-24 12:44:57,769 - INFO - New question received
2025-05-24 12:44:57,769 - INFO - Using retriever with similarity_top_k=3
2025-05-24 12:44:58,018 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:44:59,321 - INFO - Retrieved 3 nodes
2025-05-24 12:44:59,321 - INFO - First retrieved node text: We respect and accommodate all beliefs and customs....
2025-05-24 12:44:59,322 - INFO - First retrieved node score: 0.9505559974088389
2025-05-24 12:44:59,589 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:44:59,740 - INFO - AFC is enabled with max remote calls: 10.
2025-05-24 12:45:00,610 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent "HTTP/1.1 200 OK"
2025-05-24 12:45:00,613 - INFO - AFC remote call 1 is done.
2025-05-24 12:45:00,614 - INFO - Response generated successfully
2025-05-24 12:45:00,614 - INFO - New question received
2025-05-24 12:45:00,614 - INFO - Using retriever with similarity_top_k=3
2025-05-24 12:45:00,920 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:45:01,064 - INFO - Retrieved 3 nodes
2025-05-24 12:45:01,065 - INFO - First retrieved node text: Question: Can you provide references or testimonials from past clients?
...
2025-05-24 12:45:01,065 - INFO - First retrieved node score: 0.9842051353825684
2025-05-24 12:45:01,328 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:45:01,475 - INFO - AFC is enabled with max remote calls: 10.
2025-05-24 12:45:02,454 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent "HTTP/1.1 200 OK"
2025-05-24 12:45:02,456 - INFO - AFC remote call 1 is done.
2025-05-24 12:45:02,457 - INFO - Response generated successfully
2025-05-24 12:45:02,458 - INFO - New question received
2025-05-24 12:45:02,458 - INFO - Using retriever with similarity_top_k=3
2025-05-24 12:45:02,763 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:45:02,911 - INFO - Retrieved 3 nodes
2025-05-24 12:45:02,911 - INFO - First retrieved node text: Question: What is the capacity of the venue?
Answer: The venue can accommodate up to 200 guests comf...
2025-05-24 12:45:02,911 - INFO - First retrieved node score: 0.735027783417996
2025-05-24 12:45:03,174 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-24 12:45:03,323 - INFO - AFC is enabled with max remote calls: 10.
2025-05-24 12:45:04,502 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent "HTTP/1.1 200 OK"
2025-05-24 12:45:04,504 - INFO - AFC remote call 1 is done.
2025-05-24 12:45:04,505 - INFO - Response generated successfully
2025-07-11 12:09:22,706 - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-07-11 12:09:22,742 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12f8df380>
2025-07-11 12:09:22,742 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x12f924050> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-07-11 12:09:22,761 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12f8f1950>
2025-07-11 12:09:22,762 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-07-11 12:09:22,762 - DEBUG - send_request_headers.complete
2025-07-11 12:09:22,762 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-07-11 12:09:22,762 - DEBUG - send_request_body.complete
2025-07-11 12:09:22,762 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-07-11 12:09:22,791 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:17 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=20'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:22,792 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-07-11 12:09:22,792 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-07-11 12:09:22,792 - DEBUG - receive_response_body.complete
2025-07-11 12:09:22,792 - DEBUG - response_closed.started
2025-07-11 12:09:22,792 - DEBUG - response_closed.complete
2025-07-11 12:09:22,854 - INFO - Gemini LLM initialized successfully
2025-07-11 12:09:23,369 - DEBUG - open file: /Users/chrys/Projects/my_chatbot/my_library/src/my_library/data/VW_dataMar25.txt
2025-07-11 12:09:23,369 - INFO - Documents loaded successfully from ./data/VW_dataMar25.txt
2025-07-11 12:09:23,370 - INFO - First document: Title: Why a Groom-To-Be Should Have a Stag Do

Co...
2025-07-11 12:09:23,378 - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-07-11 12:09:23,391 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x139760050>
2025-07-11 12:09:23,391 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x13970eba0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-07-11 12:09:23,409 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x139700c30>
2025-07-11 12:09:23,409 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-07-11 12:09:23,409 - DEBUG - send_request_headers.complete
2025-07-11 12:09:23,409 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-07-11 12:09:23,410 - DEBUG - send_request_body.complete
2025-07-11 12:09:23,410 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-07-11 12:09:23,474 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:18 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=51'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:23,474 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-07-11 12:09:23,474 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-07-11 12:09:23,474 - DEBUG - receive_response_body.complete
2025-07-11 12:09:23,474 - DEBUG - response_closed.started
2025-07-11 12:09:23,474 - DEBUG - response_closed.complete
2025-07-11 12:09:23,486 - DEBUG - close.started
2025-07-11 12:09:23,486 - DEBUG - close.complete
2025-07-11 12:09:23,488 - INFO - Connecting to PostgreSQL database: chatbot_rag at 167.99.197.215:5432 as user chatbot
2025-07-11 12:09:23,488 - INFO - Using table name: vasilias_weddings_2025_07_11
2025-07-11 12:09:23,489 - INFO - Vector store created successfully: vasilias_weddings_2025_07_11
2025-07-11 12:09:23,490 - INFO - Storing documents in table: vasilias_weddings_2025_07_11
2025-07-11 12:09:23,491 - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-07-11 12:09:23,502 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x139703a80>
2025-07-11 12:09:23,502 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x13970ec30> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-07-11 12:09:23,522 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1392d5250>
2025-07-11 12:09:23,522 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:23,522 - DEBUG - send_request_headers.complete
2025-07-11 12:09:23,522 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:23,559 - DEBUG - send_request_body.complete
2025-07-11 12:09:23,559 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:24,158 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:19 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=544'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:24,159 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:24,159 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:24,160 - DEBUG - receive_response_body.complete
2025-07-11 12:09:24,161 - DEBUG - response_closed.started
2025-07-11 12:09:24,161 - DEBUG - response_closed.complete
2025-07-11 12:09:24,459 - WARNING - PG Setup: Error creating extension: (psycopg2.errors.UndefinedFile) could not open extension control file "/usr/share/postgresql/14/extension/vector.control": No such file or directory

[SQL: CREATE EXTENSION IF NOT EXISTS vector]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
2025-07-11 12:09:24,507 - WARNING - PG Setup: Error creating tables: (psycopg2.errors.UndefinedObject) type "vector" does not exist
LINE 7:  embedding VECTOR(768), 
                   ^

[SQL: 
CREATE TABLE public.data_vasilias_weddings_2025_07_11 (
	id BIGSERIAL NOT NULL, 
	text VARCHAR NOT NULL, 
	metadata_ JSON, 
	node_id VARCHAR, 
	embedding VECTOR(768), 
	PRIMARY KEY (id)
)

]
(Background on this error at: https://sqlalche.me/e/20/f405)
2025-07-11 12:09:24,639 - ERROR - Error storing documents: (psycopg2.errors.UndefinedTable) relation "public.data_vasilias_weddings_2025_07_11" does not exist
LINE 1: INSERT INTO public.data_vasilias_weddings_2025_07_11 (text, ...
                    ^

[SQL: INSERT INTO public.data_vasilias_weddings_2025_07_11 (text, metadata_, node_id, embedding) VALUES (%(text)s, %(metadata_)s::JSON, %(node_id)s, %(embedding)s) RETURNING public.data_vasilias_weddings_2025_07_11.id]
[parameters: {'text': 'Title: Why a Groom-To-Be Should Have a Stag Do\n\nContent: Why a Groom-To-Be Should Have a Stag Do Ball and chain jokes aside, there are some excelle ... (271276 characters truncated) ... ion to life. For our past couples, thank you for choosing us to be part of your unforgettable journey. God Bless!! From Christina and team\n\n---\n\n', 'metadata_': '{"file_path": "data/VW_dataMar25.txt", "file_name": "VW_dataMar25.txt", "file_type": "text/plain", "file_size": 271740, "creation_date": "2025-04-17" ... (278265 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id': 'ef813c80-d2e0-42a6-aede-44118d30a375', 'embedding': '[-0.02314147725701332,-0.024927489459514618,-0.002672185655683279,-0.02657134272158146,0.026404282078146935,-0.0017854926409199834,-0.045410268008708 ... (15929 characters truncated) ... 018380574882030487,-0.04060577601194382,0.014149913564324379,-0.08689773827791214,0.0008354479214176536,-0.0012618799228221178,-0.020087536424398422]'}]
(Background on this error at: https://sqlalche.me/e/20/f405)
2025-07-11 12:09:24,659 - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-07-11 12:09:24,670 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1397229c0>
2025-07-11 12:09:24,670 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x139794440> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-07-11 12:09:24,689 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1397228b0>
2025-07-11 12:09:24,689 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-07-11 12:09:24,689 - DEBUG - send_request_headers.complete
2025-07-11 12:09:24,689 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-07-11 12:09:24,689 - DEBUG - send_request_body.complete
2025-07-11 12:09:24,689 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-07-11 12:09:24,717 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:19 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=18'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:24,718 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-07-11 12:09:24,718 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-07-11 12:09:24,718 - DEBUG - receive_response_body.complete
2025-07-11 12:09:24,718 - DEBUG - response_closed.started
2025-07-11 12:09:24,718 - DEBUG - response_closed.complete
2025-07-11 12:09:24,719 - INFO - Gemini LLM initialized successfully
2025-07-11 12:09:24,744 - DEBUG - close.started
2025-07-11 12:09:24,744 - DEBUG - close.complete
2025-07-11 12:09:24,745 - DEBUG - close.started
2025-07-11 12:09:24,745 - DEBUG - close.complete
2025-07-11 12:09:24,750 - INFO - Parsed 134 documents from CSV file ./data/VWFAQ24052025.csv
2025-07-11 12:09:24,750 - INFO - Documents loaded successfully from ./data/VWFAQ24052025.csv
2025-07-11 12:09:24,750 - INFO - First document: Question: Can you help with legal requirements for...
2025-07-11 12:09:24,761 - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-07-11 12:09:24,770 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x138453250>
2025-07-11 12:09:24,770 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x13970eb10> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-07-11 12:09:24,788 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x138453350>
2025-07-11 12:09:24,789 - DEBUG - send_request_headers.started request=<Request [b'GET']>
2025-07-11 12:09:24,789 - DEBUG - send_request_headers.complete
2025-07-11 12:09:24,789 - DEBUG - send_request_body.started request=<Request [b'GET']>
2025-07-11 12:09:24,789 - DEBUG - send_request_body.complete
2025-07-11 12:09:24,789 - DEBUG - receive_response_headers.started request=<Request [b'GET']>
2025-07-11 12:09:24,816 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:19 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=18'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:24,817 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20 "HTTP/1.1 200 OK"
2025-07-11 12:09:24,817 - DEBUG - receive_response_body.started request=<Request [b'GET']>
2025-07-11 12:09:24,817 - DEBUG - receive_response_body.complete
2025-07-11 12:09:24,817 - DEBUG - response_closed.started
2025-07-11 12:09:24,817 - DEBUG - response_closed.complete
2025-07-11 12:09:24,829 - DEBUG - close.started
2025-07-11 12:09:24,829 - DEBUG - close.complete
2025-07-11 12:09:24,831 - INFO - Connecting to PostgreSQL database: chatbot_rag at 167.99.197.215:5432 as user chatbot
2025-07-11 12:09:24,831 - INFO - Using table name: vasilias_weddings_2025_07_11
2025-07-11 12:09:24,832 - INFO - Vector store created successfully: vasilias_weddings_2025_07_11
2025-07-11 12:09:24,832 - INFO - Storing documents in table: vasilias_weddings_2025_07_11
2025-07-11 12:09:24,832 - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-07-11 12:09:24,842 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1397a48c0>
2025-07-11 12:09:24,842 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x13970ea80> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-07-11 12:09:24,860 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1397a49b0>
2025-07-11 12:09:24,860 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:24,860 - DEBUG - send_request_headers.complete
2025-07-11 12:09:24,860 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:24,860 - DEBUG - send_request_body.complete
2025-07-11 12:09:24,860 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:25,182 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:20 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=278'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:25,183 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:25,183 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:25,184 - DEBUG - receive_response_body.complete
2025-07-11 12:09:25,184 - DEBUG - response_closed.started
2025-07-11 12:09:25,184 - DEBUG - response_closed.complete
2025-07-11 12:09:25,187 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:25,187 - DEBUG - send_request_headers.complete
2025-07-11 12:09:25,188 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:25,188 - DEBUG - send_request_body.complete
2025-07-11 12:09:25,188 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:25,490 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:20 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=219'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:25,491 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:25,491 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:25,492 - DEBUG - receive_response_body.complete
2025-07-11 12:09:25,492 - DEBUG - response_closed.started
2025-07-11 12:09:25,492 - DEBUG - response_closed.complete
2025-07-11 12:09:25,494 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:25,495 - DEBUG - send_request_headers.complete
2025-07-11 12:09:25,495 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:25,495 - DEBUG - send_request_body.complete
2025-07-11 12:09:25,495 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:25,796 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:20 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=238'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:25,797 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:25,797 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:25,799 - DEBUG - receive_response_body.complete
2025-07-11 12:09:25,799 - DEBUG - response_closed.started
2025-07-11 12:09:25,799 - DEBUG - response_closed.complete
2025-07-11 12:09:25,801 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:25,801 - DEBUG - send_request_headers.complete
2025-07-11 12:09:25,801 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:25,802 - DEBUG - send_request_body.complete
2025-07-11 12:09:25,802 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:26,104 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:21 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=227'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:26,105 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:26,105 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:26,106 - DEBUG - receive_response_body.complete
2025-07-11 12:09:26,106 - DEBUG - response_closed.started
2025-07-11 12:09:26,106 - DEBUG - response_closed.complete
2025-07-11 12:09:26,108 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:26,109 - DEBUG - send_request_headers.complete
2025-07-11 12:09:26,109 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:26,109 - DEBUG - send_request_body.complete
2025-07-11 12:09:26,109 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:26,410 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:21 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=243'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:26,411 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:26,411 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:26,413 - DEBUG - receive_response_body.complete
2025-07-11 12:09:26,413 - DEBUG - response_closed.started
2025-07-11 12:09:26,413 - DEBUG - response_closed.complete
2025-07-11 12:09:26,415 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:26,416 - DEBUG - send_request_headers.complete
2025-07-11 12:09:26,416 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:26,416 - DEBUG - send_request_body.complete
2025-07-11 12:09:26,416 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:26,718 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:21 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=253'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:26,719 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:26,719 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:26,721 - DEBUG - receive_response_body.complete
2025-07-11 12:09:26,721 - DEBUG - response_closed.started
2025-07-11 12:09:26,721 - DEBUG - response_closed.complete
2025-07-11 12:09:26,723 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:26,723 - DEBUG - send_request_headers.complete
2025-07-11 12:09:26,723 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:26,724 - DEBUG - send_request_body.complete
2025-07-11 12:09:26,724 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:27,025 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:21 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=223'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:27,025 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:27,025 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:27,026 - DEBUG - receive_response_body.complete
2025-07-11 12:09:27,026 - DEBUG - response_closed.started
2025-07-11 12:09:27,026 - DEBUG - response_closed.complete
2025-07-11 12:09:27,027 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:27,027 - DEBUG - send_request_headers.complete
2025-07-11 12:09:27,027 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:27,028 - DEBUG - send_request_body.complete
2025-07-11 12:09:27,028 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:27,333 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:22 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=225'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:27,334 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:27,334 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:27,335 - DEBUG - receive_response_body.complete
2025-07-11 12:09:27,335 - DEBUG - response_closed.started
2025-07-11 12:09:27,335 - DEBUG - response_closed.complete
2025-07-11 12:09:27,338 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:27,338 - DEBUG - send_request_headers.complete
2025-07-11 12:09:27,338 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:27,338 - DEBUG - send_request_body.complete
2025-07-11 12:09:27,338 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:27,695 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:22 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=347'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:27,695 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:27,695 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:27,696 - DEBUG - receive_response_body.complete
2025-07-11 12:09:27,696 - DEBUG - response_closed.started
2025-07-11 12:09:27,697 - DEBUG - response_closed.complete
2025-07-11 12:09:27,698 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:27,699 - DEBUG - send_request_headers.complete
2025-07-11 12:09:27,699 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:27,699 - DEBUG - send_request_body.complete
2025-07-11 12:09:27,699 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:28,049 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:22 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=238'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:28,050 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:28,050 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:28,051 - DEBUG - receive_response_body.complete
2025-07-11 12:09:28,052 - DEBUG - response_closed.started
2025-07-11 12:09:28,052 - DEBUG - response_closed.complete
2025-07-11 12:09:28,054 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:28,055 - DEBUG - send_request_headers.complete
2025-07-11 12:09:28,055 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:28,055 - DEBUG - send_request_body.complete
2025-07-11 12:09:28,055 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:28,355 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:23 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=227'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:28,356 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:28,356 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:28,357 - DEBUG - receive_response_body.complete
2025-07-11 12:09:28,358 - DEBUG - response_closed.started
2025-07-11 12:09:28,358 - DEBUG - response_closed.complete
2025-07-11 12:09:28,360 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:28,361 - DEBUG - send_request_headers.complete
2025-07-11 12:09:28,361 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:28,361 - DEBUG - send_request_body.complete
2025-07-11 12:09:28,361 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:28,616 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:23 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=246'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:28,616 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:28,617 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:28,618 - DEBUG - receive_response_body.complete
2025-07-11 12:09:28,618 - DEBUG - response_closed.started
2025-07-11 12:09:28,618 - DEBUG - response_closed.complete
2025-07-11 12:09:28,620 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:28,620 - DEBUG - send_request_headers.complete
2025-07-11 12:09:28,620 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:28,621 - DEBUG - send_request_body.complete
2025-07-11 12:09:28,621 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:28,971 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:23 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=240'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:28,972 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:28,972 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:28,974 - DEBUG - receive_response_body.complete
2025-07-11 12:09:28,974 - DEBUG - response_closed.started
2025-07-11 12:09:28,974 - DEBUG - response_closed.complete
2025-07-11 12:09:28,976 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:28,976 - DEBUG - send_request_headers.complete
2025-07-11 12:09:28,976 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:28,976 - DEBUG - send_request_body.complete
2025-07-11 12:09:28,976 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:29,278 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:24 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=232'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:29,279 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:29,279 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:29,280 - DEBUG - receive_response_body.complete
2025-07-11 12:09:29,281 - DEBUG - response_closed.started
2025-07-11 12:09:29,281 - DEBUG - response_closed.complete
2025-07-11 12:09:29,283 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:29,283 - DEBUG - send_request_headers.complete
2025-07-11 12:09:29,283 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:29,284 - DEBUG - send_request_body.complete
2025-07-11 12:09:29,284 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:29,586 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:24 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=213'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:29,586 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:29,587 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:29,588 - DEBUG - receive_response_body.complete
2025-07-11 12:09:29,588 - DEBUG - response_closed.started
2025-07-11 12:09:29,588 - DEBUG - response_closed.complete
2025-07-11 12:09:29,591 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:29,591 - DEBUG - send_request_headers.complete
2025-07-11 12:09:29,591 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:29,592 - DEBUG - send_request_body.complete
2025-07-11 12:09:29,592 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:29,828 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:24 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=227'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:29,829 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:29,829 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:29,831 - DEBUG - receive_response_body.complete
2025-07-11 12:09:29,831 - DEBUG - response_closed.started
2025-07-11 12:09:29,831 - DEBUG - response_closed.complete
2025-07-11 12:09:29,833 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:29,833 - DEBUG - send_request_headers.complete
2025-07-11 12:09:29,834 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:29,834 - DEBUG - send_request_body.complete
2025-07-11 12:09:29,834 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:30,096 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:25 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=210'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:30,097 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:30,097 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:30,098 - DEBUG - receive_response_body.complete
2025-07-11 12:09:30,098 - DEBUG - response_closed.started
2025-07-11 12:09:30,099 - DEBUG - response_closed.complete
2025-07-11 12:09:30,100 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:30,101 - DEBUG - send_request_headers.complete
2025-07-11 12:09:30,101 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:30,101 - DEBUG - send_request_body.complete
2025-07-11 12:09:30,101 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:30,403 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:25 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=248'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:30,404 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:30,404 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:30,405 - DEBUG - receive_response_body.complete
2025-07-11 12:09:30,406 - DEBUG - response_closed.started
2025-07-11 12:09:30,406 - DEBUG - response_closed.complete
2025-07-11 12:09:30,408 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:30,408 - DEBUG - send_request_headers.complete
2025-07-11 12:09:30,408 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:30,408 - DEBUG - send_request_body.complete
2025-07-11 12:09:30,408 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:30,713 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:25 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=242'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:30,714 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:30,714 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:30,715 - DEBUG - receive_response_body.complete
2025-07-11 12:09:30,716 - DEBUG - response_closed.started
2025-07-11 12:09:30,716 - DEBUG - response_closed.complete
2025-07-11 12:09:30,718 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:30,719 - DEBUG - send_request_headers.complete
2025-07-11 12:09:30,719 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:30,719 - DEBUG - send_request_body.complete
2025-07-11 12:09:30,719 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:31,018 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:25 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=240'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:31,019 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:31,019 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:31,020 - DEBUG - receive_response_body.complete
2025-07-11 12:09:31,021 - DEBUG - response_closed.started
2025-07-11 12:09:31,021 - DEBUG - response_closed.complete
2025-07-11 12:09:31,023 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:31,024 - DEBUG - send_request_headers.complete
2025-07-11 12:09:31,024 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:31,024 - DEBUG - send_request_body.complete
2025-07-11 12:09:31,024 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:31,326 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:26 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=233'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:31,326 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:31,327 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:31,328 - DEBUG - receive_response_body.complete
2025-07-11 12:09:31,328 - DEBUG - response_closed.started
2025-07-11 12:09:31,328 - DEBUG - response_closed.complete
2025-07-11 12:09:31,331 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:31,332 - DEBUG - send_request_headers.complete
2025-07-11 12:09:31,332 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:31,332 - DEBUG - send_request_body.complete
2025-07-11 12:09:31,332 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:31,632 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:26 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=215'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:31,633 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:31,633 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:31,634 - DEBUG - receive_response_body.complete
2025-07-11 12:09:31,634 - DEBUG - response_closed.started
2025-07-11 12:09:31,634 - DEBUG - response_closed.complete
2025-07-11 12:09:31,637 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:31,637 - DEBUG - send_request_headers.complete
2025-07-11 12:09:31,637 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:31,637 - DEBUG - send_request_body.complete
2025-07-11 12:09:31,637 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:31,940 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:26 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=226'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:31,941 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:31,941 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:31,942 - DEBUG - receive_response_body.complete
2025-07-11 12:09:31,942 - DEBUG - response_closed.started
2025-07-11 12:09:31,942 - DEBUG - response_closed.complete
2025-07-11 12:09:31,945 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:31,945 - DEBUG - send_request_headers.complete
2025-07-11 12:09:31,945 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:31,945 - DEBUG - send_request_body.complete
2025-07-11 12:09:31,945 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:32,248 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:27 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=213'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:32,248 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:32,249 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:32,250 - DEBUG - receive_response_body.complete
2025-07-11 12:09:32,250 - DEBUG - response_closed.started
2025-07-11 12:09:32,250 - DEBUG - response_closed.complete
2025-07-11 12:09:32,253 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:32,253 - DEBUG - send_request_headers.complete
2025-07-11 12:09:32,253 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:32,253 - DEBUG - send_request_body.complete
2025-07-11 12:09:32,253 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:32,554 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:27 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=252'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:32,555 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:32,555 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:32,557 - DEBUG - receive_response_body.complete
2025-07-11 12:09:32,557 - DEBUG - response_closed.started
2025-07-11 12:09:32,557 - DEBUG - response_closed.complete
2025-07-11 12:09:32,560 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:32,560 - DEBUG - send_request_headers.complete
2025-07-11 12:09:32,560 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:32,561 - DEBUG - send_request_body.complete
2025-07-11 12:09:32,561 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:32,861 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:27 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=240'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:32,861 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:32,862 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:32,863 - DEBUG - receive_response_body.complete
2025-07-11 12:09:32,863 - DEBUG - response_closed.started
2025-07-11 12:09:32,863 - DEBUG - response_closed.complete
2025-07-11 12:09:32,865 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:32,866 - DEBUG - send_request_headers.complete
2025-07-11 12:09:32,866 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:32,866 - DEBUG - send_request_body.complete
2025-07-11 12:09:32,866 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:33,169 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:28 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=220'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:33,170 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:33,170 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:33,171 - DEBUG - receive_response_body.complete
2025-07-11 12:09:33,171 - DEBUG - response_closed.started
2025-07-11 12:09:33,171 - DEBUG - response_closed.complete
2025-07-11 12:09:33,174 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:33,174 - DEBUG - send_request_headers.complete
2025-07-11 12:09:33,174 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:33,175 - DEBUG - send_request_body.complete
2025-07-11 12:09:33,175 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:33,475 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:28 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=213'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:33,476 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:33,476 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:33,477 - DEBUG - receive_response_body.complete
2025-07-11 12:09:33,477 - DEBUG - response_closed.started
2025-07-11 12:09:33,477 - DEBUG - response_closed.complete
2025-07-11 12:09:33,479 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:33,479 - DEBUG - send_request_headers.complete
2025-07-11 12:09:33,480 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:33,480 - DEBUG - send_request_body.complete
2025-07-11 12:09:33,480 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:33,785 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:28 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=241'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:33,786 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:33,786 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:33,788 - DEBUG - receive_response_body.complete
2025-07-11 12:09:33,788 - DEBUG - response_closed.started
2025-07-11 12:09:33,788 - DEBUG - response_closed.complete
2025-07-11 12:09:33,790 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:33,791 - DEBUG - send_request_headers.complete
2025-07-11 12:09:33,791 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:33,791 - DEBUG - send_request_body.complete
2025-07-11 12:09:33,791 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:34,090 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:29 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=221'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:34,091 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:34,091 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:34,092 - DEBUG - receive_response_body.complete
2025-07-11 12:09:34,092 - DEBUG - response_closed.started
2025-07-11 12:09:34,092 - DEBUG - response_closed.complete
2025-07-11 12:09:34,095 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:34,095 - DEBUG - send_request_headers.complete
2025-07-11 12:09:34,096 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:34,096 - DEBUG - send_request_body.complete
2025-07-11 12:09:34,096 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:34,398 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:29 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=239'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:34,398 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:34,399 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:34,400 - DEBUG - receive_response_body.complete
2025-07-11 12:09:34,400 - DEBUG - response_closed.started
2025-07-11 12:09:34,400 - DEBUG - response_closed.complete
2025-07-11 12:09:34,403 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:34,403 - DEBUG - send_request_headers.complete
2025-07-11 12:09:34,403 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:34,403 - DEBUG - send_request_body.complete
2025-07-11 12:09:34,403 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:34,705 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:29 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=225'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:34,705 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:34,706 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:34,707 - DEBUG - receive_response_body.complete
2025-07-11 12:09:34,707 - DEBUG - response_closed.started
2025-07-11 12:09:34,707 - DEBUG - response_closed.complete
2025-07-11 12:09:34,710 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:34,710 - DEBUG - send_request_headers.complete
2025-07-11 12:09:34,710 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:34,711 - DEBUG - send_request_body.complete
2025-07-11 12:09:34,711 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:35,011 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:29 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=226'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:35,012 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:35,012 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:35,013 - DEBUG - receive_response_body.complete
2025-07-11 12:09:35,014 - DEBUG - response_closed.started
2025-07-11 12:09:35,014 - DEBUG - response_closed.complete
2025-07-11 12:09:35,017 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:35,017 - DEBUG - send_request_headers.complete
2025-07-11 12:09:35,017 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:35,018 - DEBUG - send_request_body.complete
2025-07-11 12:09:35,018 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:35,319 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:30 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=216'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:35,320 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:35,320 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:35,321 - DEBUG - receive_response_body.complete
2025-07-11 12:09:35,321 - DEBUG - response_closed.started
2025-07-11 12:09:35,322 - DEBUG - response_closed.complete
2025-07-11 12:09:35,324 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:35,324 - DEBUG - send_request_headers.complete
2025-07-11 12:09:35,324 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:35,324 - DEBUG - send_request_body.complete
2025-07-11 12:09:35,325 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:35,626 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:30 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=215'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:35,626 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:35,627 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:35,628 - DEBUG - receive_response_body.complete
2025-07-11 12:09:35,628 - DEBUG - response_closed.started
2025-07-11 12:09:35,628 - DEBUG - response_closed.complete
2025-07-11 12:09:35,630 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:35,631 - DEBUG - send_request_headers.complete
2025-07-11 12:09:35,631 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:35,631 - DEBUG - send_request_body.complete
2025-07-11 12:09:35,631 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:35,933 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:30 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=218'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:35,934 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:35,934 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:35,934 - DEBUG - receive_response_body.complete
2025-07-11 12:09:35,934 - DEBUG - response_closed.started
2025-07-11 12:09:35,934 - DEBUG - response_closed.complete
2025-07-11 12:09:35,935 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:35,935 - DEBUG - send_request_headers.complete
2025-07-11 12:09:35,935 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:35,935 - DEBUG - send_request_body.complete
2025-07-11 12:09:35,935 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:36,241 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:31 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=238'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:36,241 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:36,242 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:36,243 - DEBUG - receive_response_body.complete
2025-07-11 12:09:36,243 - DEBUG - response_closed.started
2025-07-11 12:09:36,243 - DEBUG - response_closed.complete
2025-07-11 12:09:36,246 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:36,246 - DEBUG - send_request_headers.complete
2025-07-11 12:09:36,246 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:36,247 - DEBUG - send_request_body.complete
2025-07-11 12:09:36,247 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:36,500 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:31 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=243'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:36,500 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:36,500 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:36,505 - DEBUG - receive_response_body.complete
2025-07-11 12:09:36,505 - DEBUG - response_closed.started
2025-07-11 12:09:36,505 - DEBUG - response_closed.complete
2025-07-11 12:09:36,507 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:36,508 - DEBUG - send_request_headers.complete
2025-07-11 12:09:36,508 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:36,508 - DEBUG - send_request_body.complete
2025-07-11 12:09:36,508 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:36,857 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:31 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=237'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:36,858 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:36,858 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:36,859 - DEBUG - receive_response_body.complete
2025-07-11 12:09:36,860 - DEBUG - response_closed.started
2025-07-11 12:09:36,860 - DEBUG - response_closed.complete
2025-07-11 12:09:36,861 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:36,862 - DEBUG - send_request_headers.complete
2025-07-11 12:09:36,862 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:36,862 - DEBUG - send_request_body.complete
2025-07-11 12:09:36,862 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:37,086 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:32 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=215'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:37,087 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:37,087 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:37,087 - DEBUG - receive_response_body.complete
2025-07-11 12:09:37,087 - DEBUG - response_closed.started
2025-07-11 12:09:37,087 - DEBUG - response_closed.complete
2025-07-11 12:09:37,088 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:37,089 - DEBUG - send_request_headers.complete
2025-07-11 12:09:37,089 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:37,089 - DEBUG - send_request_body.complete
2025-07-11 12:09:37,089 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:37,308 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:32 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=210'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:37,309 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:37,309 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:37,310 - DEBUG - receive_response_body.complete
2025-07-11 12:09:37,310 - DEBUG - response_closed.started
2025-07-11 12:09:37,310 - DEBUG - response_closed.complete
2025-07-11 12:09:37,312 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:37,313 - DEBUG - send_request_headers.complete
2025-07-11 12:09:37,313 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:37,313 - DEBUG - send_request_body.complete
2025-07-11 12:09:37,313 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:37,566 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:32 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=243'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:37,567 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:37,567 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:37,569 - DEBUG - receive_response_body.complete
2025-07-11 12:09:37,569 - DEBUG - response_closed.started
2025-07-11 12:09:37,569 - DEBUG - response_closed.complete
2025-07-11 12:09:37,572 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:37,572 - DEBUG - send_request_headers.complete
2025-07-11 12:09:37,572 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:37,573 - DEBUG - send_request_body.complete
2025-07-11 12:09:37,573 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:37,802 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:32 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=220'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:37,803 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:37,803 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:37,804 - DEBUG - receive_response_body.complete
2025-07-11 12:09:37,804 - DEBUG - response_closed.started
2025-07-11 12:09:37,805 - DEBUG - response_closed.complete
2025-07-11 12:09:37,807 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:37,807 - DEBUG - send_request_headers.complete
2025-07-11 12:09:37,807 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:37,808 - DEBUG - send_request_body.complete
2025-07-11 12:09:37,808 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:38,060 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:33 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=243'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:38,061 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:38,061 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:38,062 - DEBUG - receive_response_body.complete
2025-07-11 12:09:38,062 - DEBUG - response_closed.started
2025-07-11 12:09:38,062 - DEBUG - response_closed.complete
2025-07-11 12:09:38,064 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:38,064 - DEBUG - send_request_headers.complete
2025-07-11 12:09:38,064 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:38,065 - DEBUG - send_request_body.complete
2025-07-11 12:09:38,065 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:38,307 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:33 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=233'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:38,308 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:38,308 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:38,309 - DEBUG - receive_response_body.complete
2025-07-11 12:09:38,309 - DEBUG - response_closed.started
2025-07-11 12:09:38,309 - DEBUG - response_closed.complete
2025-07-11 12:09:38,310 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:38,311 - DEBUG - send_request_headers.complete
2025-07-11 12:09:38,311 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:38,311 - DEBUG - send_request_body.complete
2025-07-11 12:09:38,311 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:38,596 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:33 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=213'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:38,597 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:38,597 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:38,598 - DEBUG - receive_response_body.complete
2025-07-11 12:09:38,598 - DEBUG - response_closed.started
2025-07-11 12:09:38,599 - DEBUG - response_closed.complete
2025-07-11 12:09:38,601 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:38,601 - DEBUG - send_request_headers.complete
2025-07-11 12:09:38,601 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:38,602 - DEBUG - send_request_body.complete
2025-07-11 12:09:38,602 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:38,905 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:33 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=240'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:38,906 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:38,906 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:38,907 - DEBUG - receive_response_body.complete
2025-07-11 12:09:38,907 - DEBUG - response_closed.started
2025-07-11 12:09:38,907 - DEBUG - response_closed.complete
2025-07-11 12:09:38,909 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:38,910 - DEBUG - send_request_headers.complete
2025-07-11 12:09:38,910 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:38,910 - DEBUG - send_request_body.complete
2025-07-11 12:09:38,910 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:39,162 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:34 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=241'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:39,163 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:39,163 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:39,164 - DEBUG - receive_response_body.complete
2025-07-11 12:09:39,164 - DEBUG - response_closed.started
2025-07-11 12:09:39,164 - DEBUG - response_closed.complete
2025-07-11 12:09:39,167 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:39,167 - DEBUG - send_request_headers.complete
2025-07-11 12:09:39,167 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:39,167 - DEBUG - send_request_body.complete
2025-07-11 12:09:39,167 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:39,518 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:34 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=238'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:39,519 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:39,519 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:39,520 - DEBUG - receive_response_body.complete
2025-07-11 12:09:39,520 - DEBUG - response_closed.started
2025-07-11 12:09:39,520 - DEBUG - response_closed.complete
2025-07-11 12:09:39,523 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:39,524 - DEBUG - send_request_headers.complete
2025-07-11 12:09:39,524 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:39,524 - DEBUG - send_request_body.complete
2025-07-11 12:09:39,524 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:39,826 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:34 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=216'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:39,827 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:39,827 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:39,828 - DEBUG - receive_response_body.complete
2025-07-11 12:09:39,828 - DEBUG - response_closed.started
2025-07-11 12:09:39,828 - DEBUG - response_closed.complete
2025-07-11 12:09:39,831 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:39,831 - DEBUG - send_request_headers.complete
2025-07-11 12:09:39,831 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:39,831 - DEBUG - send_request_body.complete
2025-07-11 12:09:39,832 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:40,133 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:35 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=211'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:40,133 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:40,134 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:40,135 - DEBUG - receive_response_body.complete
2025-07-11 12:09:40,135 - DEBUG - response_closed.started
2025-07-11 12:09:40,135 - DEBUG - response_closed.complete
2025-07-11 12:09:40,137 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:40,138 - DEBUG - send_request_headers.complete
2025-07-11 12:09:40,138 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:40,138 - DEBUG - send_request_body.complete
2025-07-11 12:09:40,138 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:40,440 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:35 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=235'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:40,441 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:40,441 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:40,442 - DEBUG - receive_response_body.complete
2025-07-11 12:09:40,443 - DEBUG - response_closed.started
2025-07-11 12:09:40,443 - DEBUG - response_closed.complete
2025-07-11 12:09:40,445 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:40,445 - DEBUG - send_request_headers.complete
2025-07-11 12:09:40,446 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:40,446 - DEBUG - send_request_body.complete
2025-07-11 12:09:40,446 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:40,676 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:35 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=221'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:40,677 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:40,677 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:40,678 - DEBUG - receive_response_body.complete
2025-07-11 12:09:40,678 - DEBUG - response_closed.started
2025-07-11 12:09:40,678 - DEBUG - response_closed.complete
2025-07-11 12:09:40,680 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:40,681 - DEBUG - send_request_headers.complete
2025-07-11 12:09:40,681 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:40,681 - DEBUG - send_request_body.complete
2025-07-11 12:09:40,681 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:40,953 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:35 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=242'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:40,953 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:40,954 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:40,954 - DEBUG - receive_response_body.complete
2025-07-11 12:09:40,955 - DEBUG - response_closed.started
2025-07-11 12:09:40,955 - DEBUG - response_closed.complete
2025-07-11 12:09:40,956 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:40,957 - DEBUG - send_request_headers.complete
2025-07-11 12:09:40,957 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:40,957 - DEBUG - send_request_body.complete
2025-07-11 12:09:40,957 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:41,259 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:36 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=236'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:41,259 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:41,260 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:41,261 - DEBUG - receive_response_body.complete
2025-07-11 12:09:41,261 - DEBUG - response_closed.started
2025-07-11 12:09:41,261 - DEBUG - response_closed.complete
2025-07-11 12:09:41,268 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:41,268 - DEBUG - send_request_headers.complete
2025-07-11 12:09:41,268 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:41,268 - DEBUG - send_request_body.complete
2025-07-11 12:09:41,269 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:41,565 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:36 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=216'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:41,565 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:41,566 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:41,567 - DEBUG - receive_response_body.complete
2025-07-11 12:09:41,567 - DEBUG - response_closed.started
2025-07-11 12:09:41,567 - DEBUG - response_closed.complete
2025-07-11 12:09:41,569 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:41,570 - DEBUG - send_request_headers.complete
2025-07-11 12:09:41,570 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:41,570 - DEBUG - send_request_body.complete
2025-07-11 12:09:41,570 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:41,873 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:36 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=215'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:41,874 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:41,874 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:41,874 - DEBUG - receive_response_body.complete
2025-07-11 12:09:41,874 - DEBUG - response_closed.started
2025-07-11 12:09:41,874 - DEBUG - response_closed.complete
2025-07-11 12:09:41,876 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:41,876 - DEBUG - send_request_headers.complete
2025-07-11 12:09:41,876 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:41,876 - DEBUG - send_request_body.complete
2025-07-11 12:09:41,876 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:42,107 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:37 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=222'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:42,107 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:42,107 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:42,108 - DEBUG - receive_response_body.complete
2025-07-11 12:09:42,108 - DEBUG - response_closed.started
2025-07-11 12:09:42,108 - DEBUG - response_closed.complete
2025-07-11 12:09:42,109 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:42,109 - DEBUG - send_request_headers.complete
2025-07-11 12:09:42,109 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:42,109 - DEBUG - send_request_body.complete
2025-07-11 12:09:42,109 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:42,386 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:37 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=224'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:42,386 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:42,387 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:42,388 - DEBUG - receive_response_body.complete
2025-07-11 12:09:42,388 - DEBUG - response_closed.started
2025-07-11 12:09:42,388 - DEBUG - response_closed.complete
2025-07-11 12:09:42,391 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:42,391 - DEBUG - send_request_headers.complete
2025-07-11 12:09:42,392 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:42,392 - DEBUG - send_request_body.complete
2025-07-11 12:09:42,392 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:42,693 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:37 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=233'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:42,693 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:42,694 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:42,694 - DEBUG - receive_response_body.complete
2025-07-11 12:09:42,694 - DEBUG - response_closed.started
2025-07-11 12:09:42,694 - DEBUG - response_closed.complete
2025-07-11 12:09:42,695 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:42,695 - DEBUG - send_request_headers.complete
2025-07-11 12:09:42,695 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:42,695 - DEBUG - send_request_body.complete
2025-07-11 12:09:42,695 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:43,001 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:37 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=216'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:43,001 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:43,001 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:43,002 - DEBUG - receive_response_body.complete
2025-07-11 12:09:43,002 - DEBUG - response_closed.started
2025-07-11 12:09:43,002 - DEBUG - response_closed.complete
2025-07-11 12:09:43,004 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:43,004 - DEBUG - send_request_headers.complete
2025-07-11 12:09:43,004 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:43,004 - DEBUG - send_request_body.complete
2025-07-11 12:09:43,004 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:43,309 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:38 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=208'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:43,310 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:43,310 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:43,311 - DEBUG - receive_response_body.complete
2025-07-11 12:09:43,311 - DEBUG - response_closed.started
2025-07-11 12:09:43,311 - DEBUG - response_closed.complete
2025-07-11 12:09:43,314 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:43,314 - DEBUG - send_request_headers.complete
2025-07-11 12:09:43,314 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:43,314 - DEBUG - send_request_body.complete
2025-07-11 12:09:43,314 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:43,615 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:38 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=239'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:43,616 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:43,616 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:43,617 - DEBUG - receive_response_body.complete
2025-07-11 12:09:43,618 - DEBUG - response_closed.started
2025-07-11 12:09:43,618 - DEBUG - response_closed.complete
2025-07-11 12:09:43,620 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:43,620 - DEBUG - send_request_headers.complete
2025-07-11 12:09:43,620 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:43,621 - DEBUG - send_request_body.complete
2025-07-11 12:09:43,621 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:43,921 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:38 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=240'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:43,922 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:43,922 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:43,923 - DEBUG - receive_response_body.complete
2025-07-11 12:09:43,923 - DEBUG - response_closed.started
2025-07-11 12:09:43,924 - DEBUG - response_closed.complete
2025-07-11 12:09:43,925 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:43,926 - DEBUG - send_request_headers.complete
2025-07-11 12:09:43,926 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:43,926 - DEBUG - send_request_body.complete
2025-07-11 12:09:43,926 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:44,228 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:39 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=216'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:44,229 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:44,229 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:44,230 - DEBUG - receive_response_body.complete
2025-07-11 12:09:44,231 - DEBUG - response_closed.started
2025-07-11 12:09:44,231 - DEBUG - response_closed.complete
2025-07-11 12:09:44,233 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:44,233 - DEBUG - send_request_headers.complete
2025-07-11 12:09:44,233 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:44,233 - DEBUG - send_request_body.complete
2025-07-11 12:09:44,233 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:44,535 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:39 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=226'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:44,536 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:44,536 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:44,537 - DEBUG - receive_response_body.complete
2025-07-11 12:09:44,537 - DEBUG - response_closed.started
2025-07-11 12:09:44,537 - DEBUG - response_closed.complete
2025-07-11 12:09:44,539 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:44,539 - DEBUG - send_request_headers.complete
2025-07-11 12:09:44,539 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:44,539 - DEBUG - send_request_body.complete
2025-07-11 12:09:44,539 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:44,763 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:39 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=213'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:44,763 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:44,763 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:44,764 - DEBUG - receive_response_body.complete
2025-07-11 12:09:44,764 - DEBUG - response_closed.started
2025-07-11 12:09:44,764 - DEBUG - response_closed.complete
2025-07-11 12:09:44,766 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:44,766 - DEBUG - send_request_headers.complete
2025-07-11 12:09:44,766 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:44,766 - DEBUG - send_request_body.complete
2025-07-11 12:09:44,766 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:45,049 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:40 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=220'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:45,049 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:45,049 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:45,050 - DEBUG - receive_response_body.complete
2025-07-11 12:09:45,050 - DEBUG - response_closed.started
2025-07-11 12:09:45,050 - DEBUG - response_closed.complete
2025-07-11 12:09:45,051 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:45,051 - DEBUG - send_request_headers.complete
2025-07-11 12:09:45,051 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:45,051 - DEBUG - send_request_body.complete
2025-07-11 12:09:45,051 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:45,355 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:40 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=218'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:45,355 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:45,356 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:45,357 - DEBUG - receive_response_body.complete
2025-07-11 12:09:45,357 - DEBUG - response_closed.started
2025-07-11 12:09:45,357 - DEBUG - response_closed.complete
2025-07-11 12:09:45,359 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:45,360 - DEBUG - send_request_headers.complete
2025-07-11 12:09:45,360 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:45,360 - DEBUG - send_request_body.complete
2025-07-11 12:09:45,360 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:45,662 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:40 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=242'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:45,663 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:45,663 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:45,664 - DEBUG - receive_response_body.complete
2025-07-11 12:09:45,664 - DEBUG - response_closed.started
2025-07-11 12:09:45,664 - DEBUG - response_closed.complete
2025-07-11 12:09:45,667 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:45,667 - DEBUG - send_request_headers.complete
2025-07-11 12:09:45,667 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:45,667 - DEBUG - send_request_body.complete
2025-07-11 12:09:45,667 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:45,929 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:40 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=252'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:45,930 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:45,930 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:45,931 - DEBUG - receive_response_body.complete
2025-07-11 12:09:45,931 - DEBUG - response_closed.started
2025-07-11 12:09:45,932 - DEBUG - response_closed.complete
2025-07-11 12:09:45,933 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:45,934 - DEBUG - send_request_headers.complete
2025-07-11 12:09:45,934 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:45,934 - DEBUG - send_request_body.complete
2025-07-11 12:09:45,934 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:46,188 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:41 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=245'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:46,189 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:46,189 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:46,190 - DEBUG - receive_response_body.complete
2025-07-11 12:09:46,191 - DEBUG - response_closed.started
2025-07-11 12:09:46,191 - DEBUG - response_closed.complete
2025-07-11 12:09:46,193 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:46,194 - DEBUG - send_request_headers.complete
2025-07-11 12:09:46,194 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:46,194 - DEBUG - send_request_body.complete
2025-07-11 12:09:46,194 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:46,481 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:41 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=227'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:46,482 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:46,482 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:46,483 - DEBUG - receive_response_body.complete
2025-07-11 12:09:46,484 - DEBUG - response_closed.started
2025-07-11 12:09:46,484 - DEBUG - response_closed.complete
2025-07-11 12:09:46,486 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:46,486 - DEBUG - send_request_headers.complete
2025-07-11 12:09:46,486 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:46,486 - DEBUG - send_request_body.complete
2025-07-11 12:09:46,487 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:46,789 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:41 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=224'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:46,789 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:46,790 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:46,790 - DEBUG - receive_response_body.complete
2025-07-11 12:09:46,791 - DEBUG - response_closed.started
2025-07-11 12:09:46,791 - DEBUG - response_closed.complete
2025-07-11 12:09:46,793 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:46,794 - DEBUG - send_request_headers.complete
2025-07-11 12:09:46,794 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:46,794 - DEBUG - send_request_body.complete
2025-07-11 12:09:46,794 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:47,097 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:42 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=227'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:47,097 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:47,097 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:47,097 - DEBUG - receive_response_body.complete
2025-07-11 12:09:47,097 - DEBUG - response_closed.started
2025-07-11 12:09:47,097 - DEBUG - response_closed.complete
2025-07-11 12:09:47,098 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:47,098 - DEBUG - send_request_headers.complete
2025-07-11 12:09:47,099 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:47,099 - DEBUG - send_request_body.complete
2025-07-11 12:09:47,099 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:47,403 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:42 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=236'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:47,404 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:47,404 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:47,405 - DEBUG - receive_response_body.complete
2025-07-11 12:09:47,405 - DEBUG - response_closed.started
2025-07-11 12:09:47,405 - DEBUG - response_closed.complete
2025-07-11 12:09:47,407 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:47,408 - DEBUG - send_request_headers.complete
2025-07-11 12:09:47,408 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:47,408 - DEBUG - send_request_body.complete
2025-07-11 12:09:47,408 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:47,711 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:42 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=253'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:47,712 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:47,712 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:47,713 - DEBUG - receive_response_body.complete
2025-07-11 12:09:47,713 - DEBUG - response_closed.started
2025-07-11 12:09:47,713 - DEBUG - response_closed.complete
2025-07-11 12:09:47,716 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:47,716 - DEBUG - send_request_headers.complete
2025-07-11 12:09:47,716 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:47,716 - DEBUG - send_request_body.complete
2025-07-11 12:09:47,716 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:48,015 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:42 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=209'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:48,016 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:48,016 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:48,016 - DEBUG - receive_response_body.complete
2025-07-11 12:09:48,016 - DEBUG - response_closed.started
2025-07-11 12:09:48,017 - DEBUG - response_closed.complete
2025-07-11 12:09:48,017 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:48,017 - DEBUG - send_request_headers.complete
2025-07-11 12:09:48,017 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:48,017 - DEBUG - send_request_body.complete
2025-07-11 12:09:48,018 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:48,324 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:43 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=233'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:48,325 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:48,325 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:48,325 - DEBUG - receive_response_body.complete
2025-07-11 12:09:48,325 - DEBUG - response_closed.started
2025-07-11 12:09:48,326 - DEBUG - response_closed.complete
2025-07-11 12:09:48,327 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:48,328 - DEBUG - send_request_headers.complete
2025-07-11 12:09:48,328 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:48,328 - DEBUG - send_request_body.complete
2025-07-11 12:09:48,328 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:48,632 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:43 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=217'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:48,633 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:48,633 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:48,634 - DEBUG - receive_response_body.complete
2025-07-11 12:09:48,634 - DEBUG - response_closed.started
2025-07-11 12:09:48,635 - DEBUG - response_closed.complete
2025-07-11 12:09:48,637 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:48,638 - DEBUG - send_request_headers.complete
2025-07-11 12:09:48,638 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:48,638 - DEBUG - send_request_body.complete
2025-07-11 12:09:48,638 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:48,939 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:43 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=238'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:48,940 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:48,940 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:48,941 - DEBUG - receive_response_body.complete
2025-07-11 12:09:48,941 - DEBUG - response_closed.started
2025-07-11 12:09:48,941 - DEBUG - response_closed.complete
2025-07-11 12:09:48,943 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:48,944 - DEBUG - send_request_headers.complete
2025-07-11 12:09:48,944 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:48,944 - DEBUG - send_request_body.complete
2025-07-11 12:09:48,944 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:49,245 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:44 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=225'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:49,246 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:49,246 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:49,247 - DEBUG - receive_response_body.complete
2025-07-11 12:09:49,247 - DEBUG - response_closed.started
2025-07-11 12:09:49,247 - DEBUG - response_closed.complete
2025-07-11 12:09:49,249 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:49,249 - DEBUG - send_request_headers.complete
2025-07-11 12:09:49,249 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:49,249 - DEBUG - send_request_body.complete
2025-07-11 12:09:49,249 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:49,553 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:44 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=235'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:49,553 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:49,554 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:49,555 - DEBUG - receive_response_body.complete
2025-07-11 12:09:49,555 - DEBUG - response_closed.started
2025-07-11 12:09:49,555 - DEBUG - response_closed.complete
2025-07-11 12:09:49,557 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:49,558 - DEBUG - send_request_headers.complete
2025-07-11 12:09:49,558 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:49,558 - DEBUG - send_request_body.complete
2025-07-11 12:09:49,558 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:49,783 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:44 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=215'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:49,784 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:49,784 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:49,785 - DEBUG - receive_response_body.complete
2025-07-11 12:09:49,786 - DEBUG - response_closed.started
2025-07-11 12:09:49,786 - DEBUG - response_closed.complete
2025-07-11 12:09:49,788 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:49,788 - DEBUG - send_request_headers.complete
2025-07-11 12:09:49,788 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:49,788 - DEBUG - send_request_body.complete
2025-07-11 12:09:49,788 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:50,064 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:45 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=219'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:50,064 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:50,065 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:50,065 - DEBUG - receive_response_body.complete
2025-07-11 12:09:50,066 - DEBUG - response_closed.started
2025-07-11 12:09:50,066 - DEBUG - response_closed.complete
2025-07-11 12:09:50,068 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:50,068 - DEBUG - send_request_headers.complete
2025-07-11 12:09:50,068 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:50,068 - DEBUG - send_request_body.complete
2025-07-11 12:09:50,068 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:50,372 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:45 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=208'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:50,373 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:50,373 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:50,373 - DEBUG - receive_response_body.complete
2025-07-11 12:09:50,373 - DEBUG - response_closed.started
2025-07-11 12:09:50,374 - DEBUG - response_closed.complete
2025-07-11 12:09:50,375 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:50,376 - DEBUG - send_request_headers.complete
2025-07-11 12:09:50,376 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:50,376 - DEBUG - send_request_body.complete
2025-07-11 12:09:50,376 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:50,679 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:45 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=220'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:50,680 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:50,680 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:50,681 - DEBUG - receive_response_body.complete
2025-07-11 12:09:50,681 - DEBUG - response_closed.started
2025-07-11 12:09:50,681 - DEBUG - response_closed.complete
2025-07-11 12:09:50,683 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:50,683 - DEBUG - send_request_headers.complete
2025-07-11 12:09:50,683 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:50,683 - DEBUG - send_request_body.complete
2025-07-11 12:09:50,683 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:50,986 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:45 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=222'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:50,986 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:50,987 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:50,988 - DEBUG - receive_response_body.complete
2025-07-11 12:09:50,988 - DEBUG - response_closed.started
2025-07-11 12:09:50,988 - DEBUG - response_closed.complete
2025-07-11 12:09:50,990 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:50,990 - DEBUG - send_request_headers.complete
2025-07-11 12:09:50,990 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:50,991 - DEBUG - send_request_body.complete
2025-07-11 12:09:50,991 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:51,242 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:46 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=242'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:51,243 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:51,243 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:51,244 - DEBUG - receive_response_body.complete
2025-07-11 12:09:51,245 - DEBUG - response_closed.started
2025-07-11 12:09:51,245 - DEBUG - response_closed.complete
2025-07-11 12:09:51,247 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:51,247 - DEBUG - send_request_headers.complete
2025-07-11 12:09:51,248 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:51,248 - DEBUG - send_request_body.complete
2025-07-11 12:09:51,248 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:51,495 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:46 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=236'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:51,495 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:51,495 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:51,496 - DEBUG - receive_response_body.complete
2025-07-11 12:09:51,496 - DEBUG - response_closed.started
2025-07-11 12:09:51,496 - DEBUG - response_closed.complete
2025-07-11 12:09:51,497 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:51,497 - DEBUG - send_request_headers.complete
2025-07-11 12:09:51,497 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:51,497 - DEBUG - send_request_body.complete
2025-07-11 12:09:51,497 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:51,723 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:46 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=217'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:51,723 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:51,723 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:51,724 - DEBUG - receive_response_body.complete
2025-07-11 12:09:51,724 - DEBUG - response_closed.started
2025-07-11 12:09:51,724 - DEBUG - response_closed.complete
2025-07-11 12:09:51,724 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:51,724 - DEBUG - send_request_headers.complete
2025-07-11 12:09:51,724 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:51,724 - DEBUG - send_request_body.complete
2025-07-11 12:09:51,724 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:52,010 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:46 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=207'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:52,011 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:52,011 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:52,011 - DEBUG - receive_response_body.complete
2025-07-11 12:09:52,011 - DEBUG - response_closed.started
2025-07-11 12:09:52,011 - DEBUG - response_closed.complete
2025-07-11 12:09:52,013 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:52,013 - DEBUG - send_request_headers.complete
2025-07-11 12:09:52,013 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:52,013 - DEBUG - send_request_body.complete
2025-07-11 12:09:52,013 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:52,318 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:47 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=218'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:52,318 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:52,319 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:52,320 - DEBUG - receive_response_body.complete
2025-07-11 12:09:52,320 - DEBUG - response_closed.started
2025-07-11 12:09:52,320 - DEBUG - response_closed.complete
2025-07-11 12:09:52,322 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:52,322 - DEBUG - send_request_headers.complete
2025-07-11 12:09:52,322 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:52,322 - DEBUG - send_request_body.complete
2025-07-11 12:09:52,322 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:52,729 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:47 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=315'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:52,730 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:52,730 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:52,732 - DEBUG - receive_response_body.complete
2025-07-11 12:09:52,732 - DEBUG - response_closed.started
2025-07-11 12:09:52,732 - DEBUG - response_closed.complete
2025-07-11 12:09:52,734 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:52,735 - DEBUG - send_request_headers.complete
2025-07-11 12:09:52,735 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:52,735 - DEBUG - send_request_body.complete
2025-07-11 12:09:52,735 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:53,034 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:48 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=260'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:53,034 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:53,035 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:53,036 - DEBUG - receive_response_body.complete
2025-07-11 12:09:53,036 - DEBUG - response_closed.started
2025-07-11 12:09:53,036 - DEBUG - response_closed.complete
2025-07-11 12:09:53,038 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:53,039 - DEBUG - send_request_headers.complete
2025-07-11 12:09:53,039 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:53,039 - DEBUG - send_request_body.complete
2025-07-11 12:09:53,039 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:53,342 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:48 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=236'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:53,342 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:53,343 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:53,344 - DEBUG - receive_response_body.complete
2025-07-11 12:09:53,344 - DEBUG - response_closed.started
2025-07-11 12:09:53,344 - DEBUG - response_closed.complete
2025-07-11 12:09:53,346 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:53,347 - DEBUG - send_request_headers.complete
2025-07-11 12:09:53,347 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:53,347 - DEBUG - send_request_body.complete
2025-07-11 12:09:53,347 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:53,575 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:48 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=217'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:53,576 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:53,576 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:53,578 - DEBUG - receive_response_body.complete
2025-07-11 12:09:53,578 - DEBUG - response_closed.started
2025-07-11 12:09:53,578 - DEBUG - response_closed.complete
2025-07-11 12:09:53,580 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:53,580 - DEBUG - send_request_headers.complete
2025-07-11 12:09:53,580 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:53,580 - DEBUG - send_request_body.complete
2025-07-11 12:09:53,581 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:53,826 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:48 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=236'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:53,827 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:53,827 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:53,828 - DEBUG - receive_response_body.complete
2025-07-11 12:09:53,828 - DEBUG - response_closed.started
2025-07-11 12:09:53,828 - DEBUG - response_closed.complete
2025-07-11 12:09:53,830 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:53,831 - DEBUG - send_request_headers.complete
2025-07-11 12:09:53,831 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:53,831 - DEBUG - send_request_body.complete
2025-07-11 12:09:53,831 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:54,058 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:49 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=218'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:54,059 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:54,059 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:54,061 - DEBUG - receive_response_body.complete
2025-07-11 12:09:54,061 - DEBUG - response_closed.started
2025-07-11 12:09:54,061 - DEBUG - response_closed.complete
2025-07-11 12:09:54,063 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:54,064 - DEBUG - send_request_headers.complete
2025-07-11 12:09:54,064 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:54,064 - DEBUG - send_request_body.complete
2025-07-11 12:09:54,064 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:54,278 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:49 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=205'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:54,279 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:54,279 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:54,281 - DEBUG - receive_response_body.complete
2025-07-11 12:09:54,281 - DEBUG - response_closed.started
2025-07-11 12:09:54,281 - DEBUG - response_closed.complete
2025-07-11 12:09:54,283 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:54,283 - DEBUG - send_request_headers.complete
2025-07-11 12:09:54,284 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:54,284 - DEBUG - send_request_body.complete
2025-07-11 12:09:54,284 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:54,571 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:49 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=210'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:54,572 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:54,572 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:54,573 - DEBUG - receive_response_body.complete
2025-07-11 12:09:54,573 - DEBUG - response_closed.started
2025-07-11 12:09:54,574 - DEBUG - response_closed.complete
2025-07-11 12:09:54,576 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:54,576 - DEBUG - send_request_headers.complete
2025-07-11 12:09:54,576 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:54,577 - DEBUG - send_request_body.complete
2025-07-11 12:09:54,577 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:54,793 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:49 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=207'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:54,794 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:54,794 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:54,795 - DEBUG - receive_response_body.complete
2025-07-11 12:09:54,795 - DEBUG - response_closed.started
2025-07-11 12:09:54,796 - DEBUG - response_closed.complete
2025-07-11 12:09:54,798 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:54,798 - DEBUG - send_request_headers.complete
2025-07-11 12:09:54,798 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:54,798 - DEBUG - send_request_body.complete
2025-07-11 12:09:54,798 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:55,083 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:50 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=237'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:55,084 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:55,084 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:55,086 - DEBUG - receive_response_body.complete
2025-07-11 12:09:55,086 - DEBUG - response_closed.started
2025-07-11 12:09:55,086 - DEBUG - response_closed.complete
2025-07-11 12:09:55,088 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:55,089 - DEBUG - send_request_headers.complete
2025-07-11 12:09:55,089 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:55,089 - DEBUG - send_request_body.complete
2025-07-11 12:09:55,089 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:55,389 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:50 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=247'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:55,390 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:55,390 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:55,391 - DEBUG - receive_response_body.complete
2025-07-11 12:09:55,391 - DEBUG - response_closed.started
2025-07-11 12:09:55,391 - DEBUG - response_closed.complete
2025-07-11 12:09:55,394 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:55,394 - DEBUG - send_request_headers.complete
2025-07-11 12:09:55,394 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:55,394 - DEBUG - send_request_body.complete
2025-07-11 12:09:55,394 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:55,697 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:50 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=222'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:55,698 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:55,699 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:55,700 - DEBUG - receive_response_body.complete
2025-07-11 12:09:55,700 - DEBUG - response_closed.started
2025-07-11 12:09:55,700 - DEBUG - response_closed.complete
2025-07-11 12:09:55,702 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:55,702 - DEBUG - send_request_headers.complete
2025-07-11 12:09:55,702 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:55,702 - DEBUG - send_request_body.complete
2025-07-11 12:09:55,702 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:56,005 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:50 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=218'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:56,006 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:56,006 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:56,007 - DEBUG - receive_response_body.complete
2025-07-11 12:09:56,007 - DEBUG - response_closed.started
2025-07-11 12:09:56,007 - DEBUG - response_closed.complete
2025-07-11 12:09:56,009 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:56,009 - DEBUG - send_request_headers.complete
2025-07-11 12:09:56,009 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:56,009 - DEBUG - send_request_body.complete
2025-07-11 12:09:56,009 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:56,313 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:51 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=216'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:56,314 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:56,314 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:56,315 - DEBUG - receive_response_body.complete
2025-07-11 12:09:56,315 - DEBUG - response_closed.started
2025-07-11 12:09:56,315 - DEBUG - response_closed.complete
2025-07-11 12:09:56,317 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:56,318 - DEBUG - send_request_headers.complete
2025-07-11 12:09:56,318 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:56,318 - DEBUG - send_request_body.complete
2025-07-11 12:09:56,318 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:56,566 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:51 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=239'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:56,567 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:56,567 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:56,568 - DEBUG - receive_response_body.complete
2025-07-11 12:09:56,569 - DEBUG - response_closed.started
2025-07-11 12:09:56,569 - DEBUG - response_closed.complete
2025-07-11 12:09:56,571 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:56,571 - DEBUG - send_request_headers.complete
2025-07-11 12:09:56,571 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:56,571 - DEBUG - send_request_body.complete
2025-07-11 12:09:56,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:56,816 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:51 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=235'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:56,816 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:56,817 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:56,818 - DEBUG - receive_response_body.complete
2025-07-11 12:09:56,818 - DEBUG - response_closed.started
2025-07-11 12:09:56,818 - DEBUG - response_closed.complete
2025-07-11 12:09:56,820 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:56,821 - DEBUG - send_request_headers.complete
2025-07-11 12:09:56,821 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:56,821 - DEBUG - send_request_body.complete
2025-07-11 12:09:56,821 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:57,132 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:52 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=238'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:57,132 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:57,132 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:57,133 - DEBUG - receive_response_body.complete
2025-07-11 12:09:57,133 - DEBUG - response_closed.started
2025-07-11 12:09:57,133 - DEBUG - response_closed.complete
2025-07-11 12:09:57,134 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:57,134 - DEBUG - send_request_headers.complete
2025-07-11 12:09:57,135 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:57,135 - DEBUG - send_request_body.complete
2025-07-11 12:09:57,135 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:57,439 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:52 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=223'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:57,439 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:57,440 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:57,441 - DEBUG - receive_response_body.complete
2025-07-11 12:09:57,441 - DEBUG - response_closed.started
2025-07-11 12:09:57,441 - DEBUG - response_closed.complete
2025-07-11 12:09:57,443 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:57,444 - DEBUG - send_request_headers.complete
2025-07-11 12:09:57,444 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:57,444 - DEBUG - send_request_body.complete
2025-07-11 12:09:57,444 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:57,745 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:52 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=218'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:57,746 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:57,746 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:57,747 - DEBUG - receive_response_body.complete
2025-07-11 12:09:57,748 - DEBUG - response_closed.started
2025-07-11 12:09:57,748 - DEBUG - response_closed.complete
2025-07-11 12:09:57,750 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:57,750 - DEBUG - send_request_headers.complete
2025-07-11 12:09:57,750 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:57,750 - DEBUG - send_request_body.complete
2025-07-11 12:09:57,750 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:58,051 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:52 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=210'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:58,052 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:58,052 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:58,053 - DEBUG - receive_response_body.complete
2025-07-11 12:09:58,053 - DEBUG - response_closed.started
2025-07-11 12:09:58,054 - DEBUG - response_closed.complete
2025-07-11 12:09:58,056 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:58,056 - DEBUG - send_request_headers.complete
2025-07-11 12:09:58,056 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:58,056 - DEBUG - send_request_body.complete
2025-07-11 12:09:58,056 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:58,361 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:53 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=229'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:58,361 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:58,362 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:58,363 - DEBUG - receive_response_body.complete
2025-07-11 12:09:58,363 - DEBUG - response_closed.started
2025-07-11 12:09:58,363 - DEBUG - response_closed.complete
2025-07-11 12:09:58,366 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:58,366 - DEBUG - send_request_headers.complete
2025-07-11 12:09:58,366 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:58,366 - DEBUG - send_request_body.complete
2025-07-11 12:09:58,367 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:58,595 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:53 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=220'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:58,595 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:58,596 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:58,596 - DEBUG - receive_response_body.complete
2025-07-11 12:09:58,596 - DEBUG - response_closed.started
2025-07-11 12:09:58,596 - DEBUG - response_closed.complete
2025-07-11 12:09:58,597 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:58,597 - DEBUG - send_request_headers.complete
2025-07-11 12:09:58,598 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:58,598 - DEBUG - send_request_body.complete
2025-07-11 12:09:58,598 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:58,842 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:53 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=235'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:58,843 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:58,843 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:58,844 - DEBUG - receive_response_body.complete
2025-07-11 12:09:58,844 - DEBUG - response_closed.started
2025-07-11 12:09:58,844 - DEBUG - response_closed.complete
2025-07-11 12:09:58,846 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:58,846 - DEBUG - send_request_headers.complete
2025-07-11 12:09:58,846 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:58,847 - DEBUG - send_request_body.complete
2025-07-11 12:09:58,847 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:59,073 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:54 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=216'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:59,073 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:59,074 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:59,075 - DEBUG - receive_response_body.complete
2025-07-11 12:09:59,075 - DEBUG - response_closed.started
2025-07-11 12:09:59,075 - DEBUG - response_closed.complete
2025-07-11 12:09:59,077 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:59,078 - DEBUG - send_request_headers.complete
2025-07-11 12:09:59,078 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:59,078 - DEBUG - send_request_body.complete
2025-07-11 12:09:59,078 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:59,298 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:54 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=210'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:59,299 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:59,299 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:59,301 - DEBUG - receive_response_body.complete
2025-07-11 12:09:59,301 - DEBUG - response_closed.started
2025-07-11 12:09:59,301 - DEBUG - response_closed.complete
2025-07-11 12:09:59,304 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:59,304 - DEBUG - send_request_headers.complete
2025-07-11 12:09:59,304 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:59,305 - DEBUG - send_request_body.complete
2025-07-11 12:09:59,305 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:59,517 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:54 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=202'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:59,517 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:59,517 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:59,518 - DEBUG - receive_response_body.complete
2025-07-11 12:09:59,518 - DEBUG - response_closed.started
2025-07-11 12:09:59,518 - DEBUG - response_closed.complete
2025-07-11 12:09:59,520 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:59,520 - DEBUG - send_request_headers.complete
2025-07-11 12:09:59,520 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:59,520 - DEBUG - send_request_body.complete
2025-07-11 12:09:59,520 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:09:59,792 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:54 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=244'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:09:59,793 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:09:59,793 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:09:59,794 - DEBUG - receive_response_body.complete
2025-07-11 12:09:59,794 - DEBUG - response_closed.started
2025-07-11 12:09:59,794 - DEBUG - response_closed.complete
2025-07-11 12:09:59,797 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:09:59,798 - DEBUG - send_request_headers.complete
2025-07-11 12:09:59,798 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:09:59,798 - DEBUG - send_request_body.complete
2025-07-11 12:09:59,798 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:10:00,100 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:55 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=212'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:10:00,100 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:10:00,101 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:10:00,101 - DEBUG - receive_response_body.complete
2025-07-11 12:10:00,101 - DEBUG - response_closed.started
2025-07-11 12:10:00,101 - DEBUG - response_closed.complete
2025-07-11 12:10:00,103 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:10:00,104 - DEBUG - send_request_headers.complete
2025-07-11 12:10:00,104 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:10:00,104 - DEBUG - send_request_body.complete
2025-07-11 12:10:00,104 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:10:00,410 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:55 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=232'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:10:00,413 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:10:00,413 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:10:00,414 - DEBUG - receive_response_body.complete
2025-07-11 12:10:00,414 - DEBUG - response_closed.started
2025-07-11 12:10:00,414 - DEBUG - response_closed.complete
2025-07-11 12:10:00,416 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:10:00,417 - DEBUG - send_request_headers.complete
2025-07-11 12:10:00,417 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:10:00,417 - DEBUG - send_request_body.complete
2025-07-11 12:10:00,417 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:10:00,634 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:55 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=208'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:10:00,634 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:10:00,634 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:10:00,635 - DEBUG - receive_response_body.complete
2025-07-11 12:10:00,635 - DEBUG - response_closed.started
2025-07-11 12:10:00,635 - DEBUG - response_closed.complete
2025-07-11 12:10:00,636 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:10:00,636 - DEBUG - send_request_headers.complete
2025-07-11 12:10:00,637 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:10:00,637 - DEBUG - send_request_body.complete
2025-07-11 12:10:00,637 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:10:00,919 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:55 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=210'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:10:00,920 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:10:00,920 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:10:00,921 - DEBUG - receive_response_body.complete
2025-07-11 12:10:00,921 - DEBUG - response_closed.started
2025-07-11 12:10:00,921 - DEBUG - response_closed.complete
2025-07-11 12:10:00,923 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:10:00,924 - DEBUG - send_request_headers.complete
2025-07-11 12:10:00,924 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:10:00,924 - DEBUG - send_request_body.complete
2025-07-11 12:10:00,924 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:10:01,226 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:56 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=211'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:10:01,226 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:10:01,227 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:10:01,228 - DEBUG - receive_response_body.complete
2025-07-11 12:10:01,228 - DEBUG - response_closed.started
2025-07-11 12:10:01,228 - DEBUG - response_closed.complete
2025-07-11 12:10:01,230 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:10:01,230 - DEBUG - send_request_headers.complete
2025-07-11 12:10:01,230 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:10:01,231 - DEBUG - send_request_body.complete
2025-07-11 12:10:01,231 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:10:01,534 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:56 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=205'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:10:01,535 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:10:01,535 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:10:01,536 - DEBUG - receive_response_body.complete
2025-07-11 12:10:01,536 - DEBUG - response_closed.started
2025-07-11 12:10:01,536 - DEBUG - response_closed.complete
2025-07-11 12:10:01,538 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:10:01,538 - DEBUG - send_request_headers.complete
2025-07-11 12:10:01,538 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:10:01,538 - DEBUG - send_request_body.complete
2025-07-11 12:10:01,538 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:10:01,841 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:56 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=231'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:10:01,841 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:10:01,842 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:10:01,843 - DEBUG - receive_response_body.complete
2025-07-11 12:10:01,843 - DEBUG - response_closed.started
2025-07-11 12:10:01,843 - DEBUG - response_closed.complete
2025-07-11 12:10:01,845 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:10:01,846 - DEBUG - send_request_headers.complete
2025-07-11 12:10:01,846 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:10:01,846 - DEBUG - send_request_body.complete
2025-07-11 12:10:01,846 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:10:02,148 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:57 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=236'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:10:02,149 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:10:02,149 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:10:02,149 - DEBUG - receive_response_body.complete
2025-07-11 12:10:02,149 - DEBUG - response_closed.started
2025-07-11 12:10:02,149 - DEBUG - response_closed.complete
2025-07-11 12:10:02,150 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:10:02,151 - DEBUG - send_request_headers.complete
2025-07-11 12:10:02,151 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:10:02,151 - DEBUG - send_request_body.complete
2025-07-11 12:10:02,151 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:10:02,457 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:57 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=232'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:10:02,457 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:10:02,458 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:10:02,459 - DEBUG - receive_response_body.complete
2025-07-11 12:10:02,459 - DEBUG - response_closed.started
2025-07-11 12:10:02,459 - DEBUG - response_closed.complete
2025-07-11 12:10:02,461 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:10:02,461 - DEBUG - send_request_headers.complete
2025-07-11 12:10:02,461 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:10:02,461 - DEBUG - send_request_body.complete
2025-07-11 12:10:02,461 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:10:02,763 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:57 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=211'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:10:02,763 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:10:02,764 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:10:02,764 - DEBUG - receive_response_body.complete
2025-07-11 12:10:02,765 - DEBUG - response_closed.started
2025-07-11 12:10:02,765 - DEBUG - response_closed.complete
2025-07-11 12:10:02,767 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:10:02,767 - DEBUG - send_request_headers.complete
2025-07-11 12:10:02,767 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:10:02,768 - DEBUG - send_request_body.complete
2025-07-11 12:10:02,768 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:10:03,068 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:58 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=205'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:10:03,069 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:10:03,069 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:10:03,070 - DEBUG - receive_response_body.complete
2025-07-11 12:10:03,071 - DEBUG - response_closed.started
2025-07-11 12:10:03,071 - DEBUG - response_closed.complete
2025-07-11 12:10:03,073 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:10:03,074 - DEBUG - send_request_headers.complete
2025-07-11 12:10:03,074 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:10:03,074 - DEBUG - send_request_body.complete
2025-07-11 12:10:03,074 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:10:03,376 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:58 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=216'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:10:03,377 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:10:03,377 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:10:03,378 - DEBUG - receive_response_body.complete
2025-07-11 12:10:03,378 - DEBUG - response_closed.started
2025-07-11 12:10:03,379 - DEBUG - response_closed.complete
2025-07-11 12:10:03,381 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:10:03,381 - DEBUG - send_request_headers.complete
2025-07-11 12:10:03,381 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:10:03,381 - DEBUG - send_request_body.complete
2025-07-11 12:10:03,382 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:10:03,683 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:58 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=217'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:10:03,684 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:10:03,684 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:10:03,685 - DEBUG - receive_response_body.complete
2025-07-11 12:10:03,685 - DEBUG - response_closed.started
2025-07-11 12:10:03,685 - DEBUG - response_closed.complete
2025-07-11 12:10:03,688 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-11 12:10:03,688 - DEBUG - send_request_headers.complete
2025-07-11 12:10:03,688 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-11 12:10:03,688 - DEBUG - send_request_body.complete
2025-07-11 12:10:03,688 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-07-11 12:10:03,991 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 11 Jul 2025 11:10:58 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=215'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-11 12:10:03,992 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 12:10:03,992 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-11 12:10:03,993 - DEBUG - receive_response_body.complete
2025-07-11 12:10:03,993 - DEBUG - response_closed.started
2025-07-11 12:10:03,993 - DEBUG - response_closed.complete
2025-07-11 12:10:04,222 - WARNING - PG Setup: Error creating extension: (psycopg2.errors.UndefinedFile) could not open extension control file "/usr/share/postgresql/14/extension/vector.control": No such file or directory

[SQL: CREATE EXTENSION IF NOT EXISTS vector]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
2025-07-11 12:10:04,265 - WARNING - PG Setup: Error creating tables: (psycopg2.errors.UndefinedObject) type "vector" does not exist
LINE 7:  embedding VECTOR(768), 
                   ^

[SQL: 
CREATE TABLE public.data_vasilias_weddings_2025_07_11 (
	id BIGSERIAL NOT NULL, 
	text VARCHAR NOT NULL, 
	metadata_ JSON, 
	node_id VARCHAR, 
	embedding VECTOR(768), 
	PRIMARY KEY (id)
)

]
(Background on this error at: https://sqlalche.me/e/20/f405)
2025-07-11 12:10:04,684 - ERROR - Error storing documents: (psycopg2.errors.UndefinedTable) relation "public.data_vasilias_weddings_2025_07_11" does not exist
LINE 1: INSERT INTO public.data_vasilias_weddings_2025_07_11 (text, ...
                    ^

[SQL: INSERT INTO public.data_vasilias_weddings_2025_07_11 (text, metadata_, node_id, embedding) SELECT p0::VARCHAR, p1::JSON, p2::VARCHAR, p3::VECTOR(768) FROM (VALUES (%(text__0)s, %(metadata___0)s::JSON, %(node_id__0)s, %(embedding__0)s, 0), (%(text__1) ... 10955 characters truncated ... NG public.data_vasilias_weddings_2025_07_11.id, public.data_vasilias_weddings_2025_07_11.id AS id__1]
[parameters: {'metadata___0': '{"faq_question": "Can you help with legal requirements for getting married in Cyprus?", "source_row": 0, "_node_content": "{\\"id_\\": \\"e0d0eb9f-e4 ... (1127 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__0': 'Question: Can you help with legal requirements for getting married in Cyprus?\nAnswer: Absolutely! We offer this service by simply hiring our ceremon ... (185 characters truncated) ... ou through legal requirements, provide templates of documents to be prepared , we make sure all of documents are prepared before arriving to Cyprus. ', 'node_id__0': 'e0d0eb9f-e4b9-4a1e-818f-0d212060551b', 'embedding__0': '[-0.003521137172356248,-0.0066353799775242805,0.016753770411014557,-0.012627629563212395,-0.004592158365994692,0.0024435652885586023,-0.0556698963046 ... (15919 characters truncated) ... 45,0.03280869498848915,0.025542886927723885,-0.029910899698734283,-0.07283629477024078,0.06193118542432785,0.045108769088983536,0.006253676488995552]', 'metadata___1': '{"faq_question": "Can you recommend vendors for photography, catering, flowers, and entertainment?", "source_row": 1, "_node_content": "{\\"id_\\": \ ... (1065 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__1': 'Question: Can you recommend vendors for photography, catering, flowers, and entertainment?\nAnswer: We have a curated list of trusted vendors who con ... (97 characters truncated) ... . We also provide packages to cover your needs and requirements. Get in touch to inquire information for our signature and finishing touches packages', 'node_id__1': '44a119bb-3891-4e9b-abff-2c5d2d1b7feb', 'embedding__1': '[0.021801121532917023,-0.027187617495656013,0.0005390840815380216,-0.059614889323711395,0.01590261608362198,-0.0290156751871109,-0.018292680382728577 ... (15930 characters truncated) ... 14726,0.0476800873875618,-0.03482653945684433,-0.00534750334918499,-0.09378547966480255,0.07293721288442612,0.007791683543473482,0.02103935368359089]', 'metadata___2': '{"faq_question": "What is the average cost of a wedding in Cyprus?", "source_row": 2, "_node_content": "{\\"id_\\": \\"f5f3b1df-8966-40ab-801a-04e9a5 ... (808 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__2': 'Question: What is the average cost of a wedding in Cyprus?\nAnswer: Costs can vary depending on the number of guests and chosen services. We can provide you with detailed estimates based on your vision.', 'node_id__2': 'f5f3b1df-8966-40ab-801a-04e9a514e553', 'embedding__2': '[0.0015328294830396771,-0.01993921585381031,0.0046431575901806355,-0.03541792184114456,0.020298872143030167,0.008592203259468079,-0.0411539264023304, ... (15920 characters truncated) ... 6,0.028845373541116714,0.011752652004361153,-0.05776868760585785,-0.08110488206148148,0.06558333337306976,0.05077998340129852,-0.0021256771869957447]', 'metadata___3': '{"faq_question": "Can you assist with accommodation for our guests?", "source_row": 3, "_node_content": "{\\"id_\\": \\"25cde31b-a7c5-4c25-ad0f-0a371 ... (802 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__3': 'Question: Can you assist with accommodation for our guests?\nAnswer: We offer 8 double rooms to accomodate up to 16 guests , baby cots and z beds available in some rooms to accomodate families. ', 'node_id__3': '25cde31b-a7c5-4c25-ad0f-0a37185e1242', 'embedding__3': '[0.0060534183867275715,0.003151927376165986,-0.026441678404808044,-0.01933486945927143,-0.003803863888606429,-0.033827703446149826,-0.011098930612206 ... (15886 characters truncated) ... 64,0.09505253285169601,-0.021301735192537308,0.01262130681425333,-0.06785786151885986,0.022755730897188187,0.04809804633259773,-0.021841563284397125]', 'metadata___4': '{"faq_question": "What are your packages and services, and are they customizable?", "source_row": 4, "_node_content": "{\\"id_\\": \\"03d1938a-9be4-4 ... (874 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__4': 'Question: What are your packages and services, and are they customizable?\nAnswer: We offer various packages to suit different budgets and needs, but everything is customizable. We want to create a wedding that reflects your unique style.', 'node_id__4': '03d1938a-9be4-4928-ba1f-b837874c619a', 'embedding__4': '[0.00448133610188961,-0.015780551359057426,-0.00042393291369080544,-0.044817302376031876,0.02451528236269951,-0.028621243312954903,-0.011779692955315 ... (15940 characters truncated) ... 7836,0.057228367775678635,-0.03727880120277405,-0.00792950950562954,-0.0879889726638794,0.06714031100273132,0.013294834643602371,0.04040525108575821]', 'metadata___5': '{"faq_question": "Can you help with transportation for us and our guests?", "source_row": 5, "_node_content": "{\\"id_\\": \\"fce8e8f8-ec97-4a10-9b7e ... (910 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__5': 'Question: Can you help with transportation for us and our guests?\nAnswer: Yes sure! We have a list of trusted transport suppliers which we bring you in touch with, you can easily book transports to and from the venue and also any other transports you might need during your stay in Cyprus ', 'node_id__5': 'fce8e8f8-ec97-4a10-9b7e-da1b727267c7', 'embedding__5': '[-0.01271857600659132,-0.029498668387532234,-0.006249622907489538,-0.010318796150386333,0.01675616391003132,0.026828253641724586,-0.00663742795586586 ... (15889 characters truncated) ... 1777,0.03738567978143692,0.01561706978827715,-0.00949171930551529,-0.09156358987092972,0.06917829811573029,0.017930718138813972,0.002931680530309677]', 'metadata___6': '{"faq_question": "How can we incorporate local traditions and customs into our wedding?", "source_row": 6, "_node_content": "{\\"id_\\": \\"d4602cae- ... (870 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__6': 'Question: How can we incorporate local traditions and customs into our wedding?\nAnswer: Cyprus has beautiful traditions we can incorporate, such as traditional music, food, or even a local priest for a religious ceremony.', 'node_id__6': 'd4602cae-39bb-4fd2-9a11-03f7d55332b9', 'embedding__6': '[0.0007431902922689915,-0.012287347577512264,-0.0012391286436468363,-0.01875673234462738,0.023223210126161575,0.019865043461322784,-0.021328845992684 ... (15917 characters truncated) ... 4,0.027798166498541832,0.01096865814179182,-0.04778503254055977,-0.12343020737171173,0.03094291128218174,0.005597976036369801,-0.0018757489742711186]', 'metadata___7': '{"faq_question": "Do you have experience with weddings for couples of different nationalities or religions?", "source_row": 7, "_node_content": "{\\" ... (940 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__7': "Question: Do you have experience with weddings for couples of different nationalities or religions?\nAnswer: Yes, we've organized weddings for couples from all over the world and various backgrounds. We respect and accommodate all beliefs and customs.", 'node_id__7': '781bbf11-25a3-4fd1-9754-f64c1c589aa2', 'embedding__7': '[-0.01304658129811287,-0.019954005256295204,-0.004262115340679884,-0.045741088688373566,0.01026479434221983,0.010428296402096748,-0.04691123217344284 ... (15879 characters truncated) ... 76,0.054333969950675964,-0.005400399677455425,-0.032327890396118164,-0.08221275359392166,0.05851846933364868,0.03658043593168259,0.00739607959985733]', 'metadata___8': '{"faq_question": "What is your cancellation policy in case of unforeseen circumstances?", "source_row": 8, "_node_content": "{\\"id_\\": \\"3970a37c- ... (902 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__8': 'Question: What is your cancellation policy in case of unforeseen circumstances?\nAnswer: We have a transparent cancellation policy outlined in our contract, protecting both your investment and our services. We can discuss details during our consultation.', 'node_id__8': '3970a37c-0bae-452d-b80b-95e30362c104', 'embedding__8': '[0.026068540289998055,-0.011953231878578663,0.017875872552394867,-0.03966611996293068,-0.00519147701561451,-0.040955815464258194,-0.00112301192712038 ... (15921 characters truncated) ... 66,0.06851436197757721,-0.04030156880617142,-0.017369981855154037,-0.04702078178524971,0.012587767094373703,0.017712220549583435,0.01478699129074812]', 'metadata___9': '{"faq_question": "How far in advance should we book your services?", "source_row": 9, "_node_content": "{\\"id_\\": \\"735ac010-637f-40ed-89d4-03ee52 ... (805 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__9': 'Question: How far in advance should we book your services?\nAnswer: We recommend booking as early as possible, especially during peak season, to ensure we can secure your preferred dates and vendors.', 'node_id__9': '735ac010-637f-40ed-89d4-03ee529b82e8', 'embedding__9': '[-0.0072282408364117146,-0.0034712827764451504,0.023404419422149658,-0.05266619846224785,0.006455372553318739,-0.03349047526717186,-0.032349120825529 ... (15924 characters truncated) ... 86,0.06850205361843109,-0.049972157925367355,0.0073627084493637085,-0.06711537390947342,0.05485919862985611,0.012252098880708218,0.03887719660997391]', 'metadata___10': '{"faq_question": "Can you help with obtaining marriage licenses and translating documents if needed?", "source_row": 10, "_node_content": "{\\"id_\\" ... (887 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__10': 'Question: Can you help with obtaining marriage licenses and translating documents if needed?\nAnswer: Yes, we can guide you through the legal process, including obtaining and translating any necessary documents.', 'node_id__10': '5b94f1e3-9444-4fcb-9e20-7af35ec796e6', 'embedding__10': '[-0.004093841649591923,0.003023357130587101,0.016032977029681206,-0.03866356238722801,-0.0017407042905688286,0.008592227473855019,-0.0307604465633630 ... (15922 characters truncated) ... 978,0.03701029717922211,0.006144729442894459,0.004448761697858572,-0.08211206644773483,0.033695876598358154,0.055812302976846695,0.02112174965441227]', 'metadata___11': '{"faq_question": "How can we personalize our wedding ceremony and reception?", "source_row": 11, "_node_content": "{\\"id_\\": \\"3ff68ced-5f2c-42d5- ... (837 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__11': 'Question: How can we personalize our wedding ceremony and reception?\nAnswer: We can incorporate your personal touches, such as special music, readings, vows, decorations, and even unique activities or themes.', 'node_id__11': '3ff68ced-5f2c-42d5-8668-9fa47d24a3af', 'embedding__11': '[0.0039054921362549067,0.025029079988598824,-0.0032337885349988937,-0.06546318531036377,0.014655236154794693,0.010035338811576366,-0.0122612500563263 ... (15889 characters truncated) ... 7701,0.030639128759503365,-0.026248455047607422,-0.00918348878622055,-0.0927334651350975,0.0396924652159214,0.016259601339697838,0.04383939132094383]', 'metadata___12': '{"faq_question": "What happens if the weather is bad on our wedding day?", "source_row": 12, "_node_content": "{\\"id_\\": \\"7e86241e-772a-4e7e-a91e ... (889 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__12': 'Question: What happens if the weather is bad on our wedding day?\nAnswer: Our main terrace is covered and rain protected, we also offer an inside bar and area you can move into in case of rain, also in rainy weather conditions we can provide tents at an additional fee ' ... 436 parameters truncated ... 'node_id__121': '1b50d568-a1f1-4c59-9c2e-40ff2dab5067', 'embedding__121': '[0.002337385667487979,0.0043272050097584724,-0.020630354061722755,-0.01848488301038742,-0.012329916469752789,-0.006979485508054495,-0.040347900241613 ... (15886 characters truncated) ... 54,0.033715784549713135,0.030258115381002426,-0.002536023035645485,-0.07660462707281113,0.02335846796631813,0.0229889415204525,-0.051711760461330414]', 'metadata___122': '{"faq_question": "Can we post wedding items to the venue before our wedding?", "source_row": 122, "_node_content": "{\\"id_\\": \\"8390a4fc-d01d-4a2c ... (753 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__122': 'Question: Can we post wedding items to the venue before our wedding?\nAnswer: Yes you can post the earliest a month before ', 'node_id__122': '8390a4fc-d01d-4a2c-bb0f-aed0ecf32750', 'embedding__122': '[-0.01437144074589014,0.013674351386725903,0.0002252271369798109,-0.034585196524858475,0.01740536093711853,-0.03094731830060482,-0.0401078499853611,0 ... (15907 characters truncated) ... 048047058284282684,-0.011931858025491238,-0.0027660150080919266,-0.06812866032123566,0.060231611132621765,-0.010899638757109642,0.015656588599085808]', 'metadata___123': '{"faq_question": "Can we bring our own favors ?", "source_row": 123, "_node_content": "{\\"id_\\": \\"c352914a-d613-4907-b729-d0d98ca5327b\\", \\"emb ... (649 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__123': 'Question: Can we bring our own favors ?\nAnswer: Yes you can provide your own', 'node_id__123': 'c352914a-d613-4907-b729-d0d98ca5327b', 'embedding__123': '[-0.003930754028260708,-0.006633037701249123,0.017456447705626488,-0.055153511464595795,0.020403379574418068,-0.027411440387368202,-0.004641768056899 ... (15907 characters truncated) ... 81,0.07758873701095581,0.002522301860153675,-0.008075299672782421,-0.08431090414524078,0.04499030113220215,0.015309548005461693,0.004961888771504164]', 'metadata___124': '{"faq_question": "How far in advance do you take bookigs?", "source_row": 124, "_node_content": "{\\"id_\\": \\"1058fb2e-1b6a-4af5-9157-e6943ee32f20\ ... (676 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__124': 'Question: How far in advance do you take bookigs?\nAnswer: Up to 2 years in advance ', 'node_id__124': '1058fb2e-1b6a-4af5-9157-e6943ee32f20', 'embedding__124': '[-0.025211472064256668,-0.013059044256806374,-0.01266062818467617,-0.036643967032432556,0.006102901417762041,-0.03610974922776222,-0.0409423485398292 ... (15899 characters truncated) ... 804,0.09516053646802902,-0.03168744593858719,0.014530285261571407,-0.03594430536031723,0.023303518071770668,0.02065304107964039,0.022630827501416206]', 'metadata___125': '{"faq_question": "How far in advance are you booked up?", "source_row": 125, "_node_content": "{\\"id_\\": \\"beac9aee-5c7f-4032-857c-798f7a93a9fc\\" ... (669 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__125': 'Question: How far in advance are you booked up?\nAnswer: Up to 1 year in advance ', 'node_id__125': 'beac9aee-5c7f-4032-857c-798f7a93a9fc', 'embedding__125': '[-0.009154390543699265,-0.006166578270494938,-0.004509102553129196,-0.03092135675251484,0.02261774241924286,-0.03969356790184975,-0.03120462596416473 ... (15896 characters truncated) ... 5,0.09195733815431595,-0.03338978439569473,0.008565546944737434,-0.044270023703575134,0.04153653606772423,0.0007988733123056591,0.024590497836470604]', 'metadata___126': '{"faq_question": "Is there a first aid kit available ?", "source_row": 126, "_node_content": "{\\"id_\\": \\"0da72cab-deba-403c-829d-2e5706877feb\\", ... (655 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__126': 'Question: Is there a first aid kit available ?\nAnswer: Yes there is ', 'node_id__126': '0da72cab-deba-403c-829d-2e5706877feb', 'embedding__126': '[0.006361409090459347,-0.007464279420673847,4.30935833719559e-05,-0.045082297176122665,0.003962505608797073,-0.011339101940393448,-0.0052608023397624 ... (15850 characters truncated) ... 72,0.10499167442321777,0.012469385750591755,-0.006697732489556074,-0.05203147232532501,0.05559743568301201,0.031483713537454605,0.003280109027400613]', 'metadata___127': '{"faq_question": "Up to what age do you consider a child?", "source_row": 127, "_node_content": "{\\"id_\\": \\"84afe331-5cce-4f5b-a8f9-2852a7c81f2a\ ... (697 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__127': 'Question: Up to what age do you consider a child?\nAnswer: Up to 12 years can order from childrens meals ', 'node_id__127': '84afe331-5cce-4f5b-a8f9-2852a7c81f2a', 'embedding__127': '[-0.019473019987344742,-0.001345382770523429,-0.04216736927628517,-0.034654971212148666,0.011878903023898602,-0.053187720477581024,-0.003387155476957 ... (15878 characters truncated) ... 1086,0.06542441993951797,-0.016056649386882782,0.016862627118825912,-0.011570729315280914,0.08996746689081192,0.0345112644135952,0.00643604900687933]', 'metadata___128': '{"faq_question": "Do you offer non alcoholic drinks ", "source_row": 128, "_node_content": "{\\"id_\\": \\"61d59d6d-e8ae-43f7-a9e7-35e296ec6198\\", \ ... (743 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__128': 'Question: Do you offer non alcoholic drinks \nAnswer: Yes of course,we offer non alcoholic cocktails from the bar, non alcoholic beer and non alcoholic prosecco ', 'node_id__128': '61d59d6d-e8ae-43f7-a9e7-35e296ec6198', 'embedding__128': '[-0.003192455042153597,-0.024405822157859802,-0.030045825988054276,-0.02793676033616066,-0.027735702693462372,-0.07140562683343887,-0.004404275212436 ... (15886 characters truncated) ... 591,0.05268755555152893,0.01643887534737587,0.006887074094265699,-0.02396492101252079,0.05428694188594818,-0.01681523025035858,-0.011984645389020443]', 'metadata___129': '{"faq_question": "Does the venue have fairy lights? Do they cost extra? ", "source_row": 129, "_node_content": "{\\"id_\\": \\"c94a9e83-cd63-41c9-b81 ... (776 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__129': 'Question: Does the venue have fairy lights? Do they cost extra? \nAnswer: Yes fairy lights are set above the main dinner area no additional charge applies', 'node_id__129': 'c94a9e83-cd63-41c9-b81b-f2f9da641341', 'embedding__129': '[-0.002875101985409856,-0.01975240558385849,-0.0385885015130043,-0.0531228706240654,-0.020586783066391945,-0.03674594312906265,-0.03141775727272034,- ... (15887 characters truncated) ... 87405,0.04113975167274475,-0.02106093429028988,-0.014783401973545551,-0.0860760435461998,0.0675274133682251,0.04684889316558838,0.006298755295574665]', 'metadata___130': '{"faq_question": "Do you offer fairy lights packages?", "source_row": 130, "_node_content": "{\\"id_\\": \\"b78c7b27-8e99-4f07-8f1a-5a094c0ce1f8\\",  ... (700 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__130': 'Question: Do you offer fairy lights packages?\nAnswer: Yes you can hire fairy light packages from suggested ventors ', 'node_id__130': 'b78c7b27-8e99-4f07-8f1a-5a094c0ce1f8', 'embedding__130': '[-0.022461144253611565,-0.01744770258665085,-0.02908291295170784,-0.04099619388580322,0.0005974787636660039,-0.04344586655497551,-0.01736037805676460 ... (15897 characters truncated) ... 092285,0.05682354420423508,-0.0351269468665123,-0.013536954298615456,-0.09071972966194153,0.06438392400741577,0.0228826105594635,0.03674847632646561]', 'metadata___131': '{"faq_question": "Is your venue child friendly?", "source_row": 131, "_node_content": "{\\"id_\\": \\"599bc5b9-85a8-4e0e-81cd-efe574ead458\\", \\"emb ... (724 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__131': 'Question: Is your venue child friendly?\nAnswer: Yes we would say our venue is child friendly, we welcome families with young children most of the time ', 'node_id__131': '599bc5b9-85a8-4e0e-81cd-efe574ead458', 'embedding__131': '[-0.0446934811770916,-0.035919517278671265,-0.027393562719225883,-0.054229333996772766,0.00013371089880820364,-0.054871074855327606,0.019008820876479 ... (15890 characters truncated) ... 7226,0.06824860721826553,0.0062518916092813015,0.014546978287398815,-0.05343842878937721,0.0400112085044384,0.007313424721360207,0.02629460208117962]', 'metadata___132': '{"faq_question": "Are there any facilities in rooms?", "source_row": 132, "_node_content": "{\\"id_\\": \\"d7341b2d-8bf3-4d39-af0a-600be388f1c9\\", \ ... (807 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__132': 'Question: Are there any facilities in rooms?\nAnswer: Yes of course, in our rooms we provide tea and coffee facilities, hairdryer, safe, mini fridge with small bottles of water. For the shower we provide shower gel and soap. ', 'node_id__132': 'd7341b2d-8bf3-4d39-af0a-600be388f1c9', 'embedding__132': '[-0.006934785284101963,-0.016350481659173965,-0.02842964045703411,-0.022188808768987656,-0.01789422146975994,-0.024045007303357124,-0.024615639820694 ... (15913 characters truncated) ... ,0.09094378352165222,0.004178320523351431,-0.009394531138241291,-0.061488643288612366,0.025287069380283356,0.052145395427942276,-0.03846484422683716]', 'metadata___133': '{"faq_question": "Is there a smoking area? ", "source_row": 133, "_node_content": "{\\"id_\\": \\"4b40aaa6-2aca-4472-8131-b1609b935336\\", \\"embeddi ... (746 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__133': 'Question: Is there a smoking area? \nAnswer: There is no designated area for smoking however we encourage guests to use the carob tree area for smoking as we provide ashtrays there. ', 'node_id__133': '4b40aaa6-2aca-4472-8131-b1609b935336', 'embedding__133': '[0.0019000262254849076,-0.015416349284350872,-0.02678222768008709,-0.07339641451835632,-0.007842722348868847,-0.05898557975888252,-0.0149022247642278 ... (15903 characters truncated) ... 6465,0.04639805480837822,0.03003525175154209,0.030347861349582672,-0.04560208320617676,0.05326217785477638,0.03359312191605568,-0.026956506073474884]'}]
(Background on this error at: https://sqlalche.me/e/20/f405)
2025-07-11 13:14:39,313 - INFO - Local LLM initialized successfully
2025-07-11 13:14:39,745 - INFO - Local embedding model initialized successfully
2025-07-11 13:14:39,754 - INFO - Documents loaded successfully from ./data/VW_dataMar25.txt
2025-07-11 13:14:39,754 - INFO - First document: Title: Why a Groom-To-Be Should Have a Stag Do

Co...
2025-07-11 13:14:39,841 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite-preview-06-17 "HTTP/1.1 200 OK"
2025-07-11 13:14:39,852 - INFO - Connecting to PostgreSQL database: chatbot_rag at 167.99.197.215:5432 as user chatbot
2025-07-11 13:14:39,852 - INFO - Using table name: vasilias_weddings_2025_07_11
2025-07-11 13:14:39,854 - INFO - Vector store created successfully: vasilias_weddings_2025_07_11
2025-07-11 13:14:39,854 - INFO - Storing documents in table: vasilias_weddings_2025_07_11
2025-07-11 13:14:40,352 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:40,705 - WARNING - PG Setup: Error creating extension: (psycopg2.errors.UndefinedFile) could not open extension control file "/usr/share/postgresql/14/extension/vector.control": No such file or directory

[SQL: CREATE EXTENSION IF NOT EXISTS vector]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
2025-07-11 13:14:40,752 - WARNING - PG Setup: Error creating tables: (psycopg2.errors.UndefinedObject) type "vector" does not exist
LINE 7:  embedding VECTOR(768), 
                   ^

[SQL: 
CREATE TABLE public.data_vasilias_weddings_2025_07_11 (
	id BIGSERIAL NOT NULL, 
	text VARCHAR NOT NULL, 
	metadata_ JSON, 
	node_id VARCHAR, 
	embedding VECTOR(768), 
	PRIMARY KEY (id)
)

]
(Background on this error at: https://sqlalche.me/e/20/f405)
2025-07-11 13:14:40,911 - ERROR - Error storing documents: (psycopg2.errors.UndefinedTable) relation "public.data_vasilias_weddings_2025_07_11" does not exist
LINE 1: INSERT INTO public.data_vasilias_weddings_2025_07_11 (text, ...
                    ^

[SQL: INSERT INTO public.data_vasilias_weddings_2025_07_11 (text, metadata_, node_id, embedding) VALUES (%(text)s, %(metadata_)s::JSON, %(node_id)s, %(embedding)s) RETURNING public.data_vasilias_weddings_2025_07_11.id]
[parameters: {'text': 'Title: Why a Groom-To-Be Should Have a Stag Do\n\nContent: Why a Groom-To-Be Should Have a Stag Do Ball and chain jokes aside, there are some excelle ... (271276 characters truncated) ... ion to life. For our past couples, thank you for choosing us to be part of your unforgettable journey. God Bless!! From Christina and team\n\n---\n\n', 'metadata_': '{"file_path": "data/VW_dataMar25.txt", "file_name": "VW_dataMar25.txt", "file_type": "text/plain", "file_size": 271740, "creation_date": "2025-04-17" ... (278265 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id': 'f5a7bfae-fc44-4a83-a5a1-63aa384a65ad', 'embedding': '[-0.02314147725701332,-0.024927489459514618,-0.002672185655683279,-0.02657134272158146,0.026404282078146935,-0.0017854926409199834,-0.045410268008708 ... (15929 characters truncated) ... 018380574882030487,-0.04060577601194382,0.014149913564324379,-0.08689773827791214,0.0008354479214176536,-0.0012618799228221178,-0.020087536424398422]'}]
(Background on this error at: https://sqlalche.me/e/20/f405)
2025-07-11 13:14:40,911 - INFO - Local LLM initialized successfully
2025-07-11 13:14:40,932 - INFO - Local embedding model initialized successfully
2025-07-11 13:14:40,950 - INFO - Parsed 134 documents from CSV file ./data/VWFAQ24052025.csv
2025-07-11 13:14:40,950 - INFO - Documents loaded successfully from ./data/VWFAQ24052025.csv
2025-07-11 13:14:40,950 - INFO - First document: Question: Can you help with legal requirements for...
2025-07-11 13:14:41,052 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite-preview-06-17 "HTTP/1.1 200 OK"
2025-07-11 13:14:41,069 - INFO - Connecting to PostgreSQL database: chatbot_rag at 167.99.197.215:5432 as user chatbot
2025-07-11 13:14:41,069 - INFO - Using table name: vasilias_weddings_2025_07_11
2025-07-11 13:14:41,070 - INFO - Vector store created successfully: vasilias_weddings_2025_07_11
2025-07-11 13:14:41,070 - INFO - Storing documents in table: vasilias_weddings_2025_07_11
2025-07-11 13:14:41,479 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:41,785 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:42,014 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:42,297 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:42,604 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:42,833 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:43,115 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:43,367 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:43,628 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:43,859 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:44,140 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:44,447 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:44,754 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:44,991 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:45,266 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:45,574 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:45,880 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:46,102 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:46,393 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:46,700 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:47,009 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:47,314 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:47,622 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:47,929 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:48,236 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:48,543 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:48,850 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:49,107 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:49,356 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:49,609 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:49,875 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:50,182 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:50,443 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:50,796 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:51,105 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:51,411 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:51,718 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:51,951 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:52,188 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:52,435 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:52,741 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:53,049 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:53,356 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:53,662 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:53,971 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:54,278 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:54,585 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:54,893 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:55,201 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:55,506 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:55,729 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:56,018 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:56,327 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:56,564 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:56,837 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:57,145 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:57,451 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:57,760 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:58,068 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:58,375 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:58,683 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:58,988 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:59,297 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:59,603 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:14:59,857 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:00,095 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:00,319 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:00,553 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:00,831 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:01,139 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:01,388 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:01,640 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:01,889 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:02,111 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:02,368 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:02,595 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:02,879 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:03,187 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:03,444 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:03,700 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:03,940 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:04,161 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:04,417 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:04,723 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:04,948 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:05,182 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:05,446 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:05,746 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:06,054 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:06,362 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:06,667 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:06,975 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:07,216 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:07,488 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:08,051 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:08,306 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:08,614 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:08,922 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:09,149 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:09,432 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:09,740 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:09,962 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:10,186 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:10,415 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:10,641 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:10,861 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:11,173 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:11,419 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:11,648 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:11,872 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:12,093 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:12,313 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:12,545 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:12,789 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:13,017 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:13,252 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:13,501 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:13,734 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:14,044 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:14,347 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:14,657 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:14,963 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:15,270 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:15,578 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:15,885 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:16,191 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:16,619 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:16,839 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:17,071 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:17,289 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:17,624 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:17,930 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:18,239 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:18,495 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:15:18,770 - WARNING - PG Setup: Error creating extension: (psycopg2.errors.UndefinedFile) could not open extension control file "/usr/share/postgresql/14/extension/vector.control": No such file or directory

[SQL: CREATE EXTENSION IF NOT EXISTS vector]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
2025-07-11 13:15:18,812 - WARNING - PG Setup: Error creating tables: (psycopg2.errors.UndefinedObject) type "vector" does not exist
LINE 7:  embedding VECTOR(768), 
                   ^

[SQL: 
CREATE TABLE public.data_vasilias_weddings_2025_07_11 (
	id BIGSERIAL NOT NULL, 
	text VARCHAR NOT NULL, 
	metadata_ JSON, 
	node_id VARCHAR, 
	embedding VECTOR(768), 
	PRIMARY KEY (id)
)

]
(Background on this error at: https://sqlalche.me/e/20/f405)
2025-07-11 13:15:19,388 - ERROR - Error storing documents: (psycopg2.errors.UndefinedTable) relation "public.data_vasilias_weddings_2025_07_11" does not exist
LINE 1: INSERT INTO public.data_vasilias_weddings_2025_07_11 (text, ...
                    ^

[SQL: INSERT INTO public.data_vasilias_weddings_2025_07_11 (text, metadata_, node_id, embedding) SELECT p0::VARCHAR, p1::JSON, p2::VARCHAR, p3::VECTOR(768) FROM (VALUES (%(text__0)s, %(metadata___0)s::JSON, %(node_id__0)s, %(embedding__0)s, 0), (%(text__1) ... 10955 characters truncated ... NG public.data_vasilias_weddings_2025_07_11.id, public.data_vasilias_weddings_2025_07_11.id AS id__1]
[parameters: {'text__0': 'Question: Can you help with legal requirements for getting married in Cyprus?\nAnswer: Absolutely! We offer this service by simply hiring our ceremon ... (185 characters truncated) ... ou through legal requirements, provide templates of documents to be prepared , we make sure all of documents are prepared before arriving to Cyprus. ', 'node_id__0': '3c996df7-62b3-40eb-9e72-4985f7421bb2', 'embedding__0': '[-0.003521137172356248,-0.0066353799775242805,0.016753770411014557,-0.012627629563212395,-0.004592158365994692,0.0024435652885586023,-0.0556698963046 ... (15919 characters truncated) ... 45,0.03280869498848915,0.025542886927723885,-0.029910899698734283,-0.07283629477024078,0.06193118542432785,0.045108769088983536,0.006253676488995552]', 'metadata___0': '{"faq_question": "Can you help with legal requirements for getting married in Cyprus?", "source_row": 0, "_node_content": "{\\"id_\\": \\"3c996df7-62 ... (1127 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__1': 'Question: Can you recommend vendors for photography, catering, flowers, and entertainment?\nAnswer: We have a curated list of trusted vendors who con ... (97 characters truncated) ... . We also provide packages to cover your needs and requirements. Get in touch to inquire information for our signature and finishing touches packages', 'node_id__1': '5a37d2f7-71e8-4d7a-9500-052c00d3d368', 'embedding__1': '[0.021801121532917023,-0.027187617495656013,0.0005390840815380216,-0.059614889323711395,0.01590261608362198,-0.0290156751871109,-0.018292680382728577 ... (15930 characters truncated) ... 14726,0.0476800873875618,-0.03482653945684433,-0.00534750334918499,-0.09378547966480255,0.07293721288442612,0.007791683543473482,0.02103935368359089]', 'metadata___1': '{"faq_question": "Can you recommend vendors for photography, catering, flowers, and entertainment?", "source_row": 1, "_node_content": "{\\"id_\\": \ ... (1065 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__2': 'Question: What is the average cost of a wedding in Cyprus?\nAnswer: Costs can vary depending on the number of guests and chosen services. We can provide you with detailed estimates based on your vision.', 'node_id__2': 'af71dc0d-9810-4486-b638-643c5db4797e', 'embedding__2': '[0.0015328294830396771,-0.01993921585381031,0.0046431575901806355,-0.03541792184114456,0.020298872143030167,0.008592203259468079,-0.0411539264023304, ... (15920 characters truncated) ... 6,0.028845373541116714,0.011752652004361153,-0.05776868760585785,-0.08110488206148148,0.06558333337306976,0.05077998340129852,-0.0021256771869957447]', 'metadata___2': '{"faq_question": "What is the average cost of a wedding in Cyprus?", "source_row": 2, "_node_content": "{\\"id_\\": \\"af71dc0d-9810-4486-b638-643c5d ... (808 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__3': 'Question: Can you assist with accommodation for our guests?\nAnswer: We offer 8 double rooms to accomodate up to 16 guests , baby cots and z beds available in some rooms to accomodate families. ', 'node_id__3': 'feb21ed1-4615-402a-98e3-907a54fdd5d7', 'embedding__3': '[0.0060534183867275715,0.003151927376165986,-0.026441678404808044,-0.01933486945927143,-0.003803863888606429,-0.033827703446149826,-0.011098930612206 ... (15886 characters truncated) ... 64,0.09505253285169601,-0.021301735192537308,0.01262130681425333,-0.06785786151885986,0.022755730897188187,0.04809804633259773,-0.021841563284397125]', 'metadata___3': '{"faq_question": "Can you assist with accommodation for our guests?", "source_row": 3, "_node_content": "{\\"id_\\": \\"feb21ed1-4615-402a-98e3-907a5 ... (802 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__4': 'Question: What are your packages and services, and are they customizable?\nAnswer: We offer various packages to suit different budgets and needs, but everything is customizable. We want to create a wedding that reflects your unique style.', 'node_id__4': '85451c1a-e62f-43e8-9b9e-7da3a941b63d', 'embedding__4': '[0.00448133610188961,-0.015780551359057426,-0.00042393291369080544,-0.044817302376031876,0.02451528236269951,-0.028621243312954903,-0.011779692955315 ... (15940 characters truncated) ... 7836,0.057228367775678635,-0.03727880120277405,-0.00792950950562954,-0.0879889726638794,0.06714031100273132,0.013294834643602371,0.04040525108575821]', 'metadata___4': '{"faq_question": "What are your packages and services, and are they customizable?", "source_row": 4, "_node_content": "{\\"id_\\": \\"85451c1a-e62f-4 ... (874 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__5': 'Question: Can you help with transportation for us and our guests?\nAnswer: Yes sure! We have a list of trusted transport suppliers which we bring you in touch with, you can easily book transports to and from the venue and also any other transports you might need during your stay in Cyprus ', 'node_id__5': '8c61969a-c400-4337-88e9-12f2747e2be1', 'embedding__5': '[-0.01271857600659132,-0.029498668387532234,-0.006249622907489538,-0.010318796150386333,0.01675616391003132,0.026828253641724586,-0.00663742795586586 ... (15889 characters truncated) ... 1777,0.03738567978143692,0.01561706978827715,-0.00949171930551529,-0.09156358987092972,0.06917829811573029,0.017930718138813972,0.002931680530309677]', 'metadata___5': '{"faq_question": "Can you help with transportation for us and our guests?", "source_row": 5, "_node_content": "{\\"id_\\": \\"8c61969a-c400-4337-88e9 ... (910 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__6': 'Question: How can we incorporate local traditions and customs into our wedding?\nAnswer: Cyprus has beautiful traditions we can incorporate, such as traditional music, food, or even a local priest for a religious ceremony.', 'node_id__6': '15444432-56c3-44ab-8971-0125203d278b', 'embedding__6': '[0.0007431902922689915,-0.012287347577512264,-0.0012391286436468363,-0.01875673234462738,0.023223210126161575,0.019865043461322784,-0.021328845992684 ... (15917 characters truncated) ... 4,0.027798166498541832,0.01096865814179182,-0.04778503254055977,-0.12343020737171173,0.03094291128218174,0.005597976036369801,-0.0018757489742711186]', 'metadata___6': '{"faq_question": "How can we incorporate local traditions and customs into our wedding?", "source_row": 6, "_node_content": "{\\"id_\\": \\"15444432- ... (870 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__7': "Question: Do you have experience with weddings for couples of different nationalities or religions?\nAnswer: Yes, we've organized weddings for couples from all over the world and various backgrounds. We respect and accommodate all beliefs and customs.", 'node_id__7': '9498cfd3-0a4f-4098-8f53-831b2e423c3f', 'embedding__7': '[-0.01304658129811287,-0.019954005256295204,-0.004262115340679884,-0.045741088688373566,0.01026479434221983,0.010428296402096748,-0.04691123217344284 ... (15879 characters truncated) ... 76,0.054333969950675964,-0.005400399677455425,-0.032327890396118164,-0.08221275359392166,0.05851846933364868,0.03658043593168259,0.00739607959985733]', 'metadata___7': '{"faq_question": "Do you have experience with weddings for couples of different nationalities or religions?", "source_row": 7, "_node_content": "{\\" ... (940 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__8': 'Question: What is your cancellation policy in case of unforeseen circumstances?\nAnswer: We have a transparent cancellation policy outlined in our contract, protecting both your investment and our services. We can discuss details during our consultation.', 'node_id__8': 'd28911c8-d47d-4307-aaea-28b6f3825002', 'embedding__8': '[0.026068540289998055,-0.011953231878578663,0.017875872552394867,-0.03966611996293068,-0.00519147701561451,-0.040955815464258194,-0.00112301192712038 ... (15921 characters truncated) ... 66,0.06851436197757721,-0.04030156880617142,-0.017369981855154037,-0.04702078178524971,0.012587767094373703,0.017712220549583435,0.01478699129074812]', 'metadata___8': '{"faq_question": "What is your cancellation policy in case of unforeseen circumstances?", "source_row": 8, "_node_content": "{\\"id_\\": \\"d28911c8- ... (902 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__9': 'Question: How far in advance should we book your services?\nAnswer: We recommend booking as early as possible, especially during peak season, to ensure we can secure your preferred dates and vendors.', 'node_id__9': '31e94089-575b-4710-9070-a24435f4379f', 'embedding__9': '[-0.0072282408364117146,-0.0034712827764451504,0.023404419422149658,-0.05266619846224785,0.006455372553318739,-0.03349047526717186,-0.032349120825529 ... (15924 characters truncated) ... 86,0.06850205361843109,-0.049972157925367355,0.0073627084493637085,-0.06711537390947342,0.05485919862985611,0.012252098880708218,0.03887719660997391]', 'metadata___9': '{"faq_question": "How far in advance should we book your services?", "source_row": 9, "_node_content": "{\\"id_\\": \\"31e94089-575b-4710-9070-a24435 ... (805 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__10': 'Question: Can you help with obtaining marriage licenses and translating documents if needed?\nAnswer: Yes, we can guide you through the legal process, including obtaining and translating any necessary documents.', 'node_id__10': '14e2861c-4d26-489f-af6b-6c27788b8cf2', 'embedding__10': '[-0.004093841649591923,0.003023357130587101,0.016032977029681206,-0.03866356238722801,-0.0017407042905688286,0.008592227473855019,-0.0307604465633630 ... (15922 characters truncated) ... 978,0.03701029717922211,0.006144729442894459,0.004448761697858572,-0.08211206644773483,0.033695876598358154,0.055812302976846695,0.02112174965441227]', 'metadata___10': '{"faq_question": "Can you help with obtaining marriage licenses and translating documents if needed?", "source_row": 10, "_node_content": "{\\"id_\\" ... (887 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__11': 'Question: How can we personalize our wedding ceremony and reception?\nAnswer: We can incorporate your personal touches, such as special music, readings, vows, decorations, and even unique activities or themes.', 'node_id__11': '908ceed3-5c86-4f9e-9b96-f5c4f2813aa7', 'embedding__11': '[0.0039054921362549067,0.025029079988598824,-0.0032337885349988937,-0.06546318531036377,0.014655236154794693,0.010035338811576366,-0.0122612500563263 ... (15889 characters truncated) ... 7701,0.030639128759503365,-0.026248455047607422,-0.00918348878622055,-0.0927334651350975,0.0396924652159214,0.016259601339697838,0.04383939132094383]', 'metadata___11': '{"faq_question": "How can we personalize our wedding ceremony and reception?", "source_row": 11, "_node_content": "{\\"id_\\": \\"908ceed3-5c86-4f9e- ... (837 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__12': 'Question: What happens if the weather is bad on our wedding day?\nAnswer: Our main terrace is covered and rain protected, we also offer an inside bar and area you can move into in case of rain, also in rainy weather conditions we can provide tents at an additional fee ', 'node_id__12': '34c4a708-a044-4746-9c9d-ac042e3759ae' ... 436 parameters truncated ... 'embedding__121': '[0.002337385667487979,0.0043272050097584724,-0.020630354061722755,-0.01848488301038742,-0.012329916469752789,-0.006979485508054495,-0.040347900241613 ... (15886 characters truncated) ... 54,0.033715784549713135,0.030258115381002426,-0.002536023035645485,-0.07660462707281113,0.02335846796631813,0.0229889415204525,-0.051711760461330414]', 'metadata___121': '{"faq_question": "How much does a taxi costs from Paphos to Vasilias ? ", "source_row": 121, "_node_content": "{\\"id_\\": \\"455a637d-8e36-4d4b-837f ... (708 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__122': 'Question: Can we post wedding items to the venue before our wedding?\nAnswer: Yes you can post the earliest a month before ', 'node_id__122': '6cec7213-2687-4a15-b008-19d019f04814', 'embedding__122': '[-0.01437144074589014,0.013674351386725903,0.0002252271369798109,-0.034585196524858475,0.01740536093711853,-0.03094731830060482,-0.0401078499853611,0 ... (15907 characters truncated) ... 048047058284282684,-0.011931858025491238,-0.0027660150080919266,-0.06812866032123566,0.060231611132621765,-0.010899638757109642,0.015656588599085808]', 'metadata___122': '{"faq_question": "Can we post wedding items to the venue before our wedding?", "source_row": 122, "_node_content": "{\\"id_\\": \\"6cec7213-2687-4a15 ... (753 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__123': 'Question: Can we bring our own favors ?\nAnswer: Yes you can provide your own', 'node_id__123': '297aecf5-78b1-450b-b1bc-8c36a67b04cb', 'embedding__123': '[-0.003930754028260708,-0.006633037701249123,0.017456447705626488,-0.055153511464595795,0.020403379574418068,-0.027411440387368202,-0.004641768056899 ... (15907 characters truncated) ... 81,0.07758873701095581,0.002522301860153675,-0.008075299672782421,-0.08431090414524078,0.04499030113220215,0.015309548005461693,0.004961888771504164]', 'metadata___123': '{"faq_question": "Can we bring our own favors ?", "source_row": 123, "_node_content": "{\\"id_\\": \\"297aecf5-78b1-450b-b1bc-8c36a67b04cb\\", \\"emb ... (649 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__124': 'Question: How far in advance do you take bookigs?\nAnswer: Up to 2 years in advance ', 'node_id__124': '125d0589-b008-4e13-a248-6da9b2c061ac', 'embedding__124': '[-0.025211472064256668,-0.013059044256806374,-0.01266062818467617,-0.036643967032432556,0.006102901417762041,-0.03610974922776222,-0.0409423485398292 ... (15899 characters truncated) ... 804,0.09516053646802902,-0.03168744593858719,0.014530285261571407,-0.03594430536031723,0.023303518071770668,0.02065304107964039,0.022630827501416206]', 'metadata___124': '{"faq_question": "How far in advance do you take bookigs?", "source_row": 124, "_node_content": "{\\"id_\\": \\"125d0589-b008-4e13-a248-6da9b2c061ac\ ... (676 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__125': 'Question: How far in advance are you booked up?\nAnswer: Up to 1 year in advance ', 'node_id__125': '228fe355-891c-49bf-b701-9bf9be1bba54', 'embedding__125': '[-0.009154390543699265,-0.006166578270494938,-0.004509102553129196,-0.03092135675251484,0.02261774241924286,-0.03969356790184975,-0.03120462596416473 ... (15896 characters truncated) ... 5,0.09195733815431595,-0.03338978439569473,0.008565546944737434,-0.044270023703575134,0.04153653606772423,0.0007988733123056591,0.024590497836470604]', 'metadata___125': '{"faq_question": "How far in advance are you booked up?", "source_row": 125, "_node_content": "{\\"id_\\": \\"228fe355-891c-49bf-b701-9bf9be1bba54\\" ... (669 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__126': 'Question: Is there a first aid kit available ?\nAnswer: Yes there is ', 'node_id__126': '3a8a8916-01f9-4d53-ab67-7639f3cdbb88', 'embedding__126': '[0.006361409090459347,-0.007464279420673847,4.30935833719559e-05,-0.045082297176122665,0.003962505608797073,-0.011339101940393448,-0.0052608023397624 ... (15850 characters truncated) ... 72,0.10499167442321777,0.012469385750591755,-0.006697732489556074,-0.05203147232532501,0.05559743568301201,0.031483713537454605,0.003280109027400613]', 'metadata___126': '{"faq_question": "Is there a first aid kit available ?", "source_row": 126, "_node_content": "{\\"id_\\": \\"3a8a8916-01f9-4d53-ab67-7639f3cdbb88\\", ... (655 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__127': 'Question: Up to what age do you consider a child?\nAnswer: Up to 12 years can order from childrens meals ', 'node_id__127': 'e4e75216-303d-4eb0-89c1-225410aeb362', 'embedding__127': '[-0.019473019987344742,-0.001345382770523429,-0.04216736927628517,-0.034654971212148666,0.011878903023898602,-0.053187720477581024,-0.003387155476957 ... (15878 characters truncated) ... 1086,0.06542441993951797,-0.016056649386882782,0.016862627118825912,-0.011570729315280914,0.08996746689081192,0.0345112644135952,0.00643604900687933]', 'metadata___127': '{"faq_question": "Up to what age do you consider a child?", "source_row": 127, "_node_content": "{\\"id_\\": \\"e4e75216-303d-4eb0-89c1-225410aeb362\ ... (697 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__128': 'Question: Do you offer non alcoholic drinks \nAnswer: Yes of course,we offer non alcoholic cocktails from the bar, non alcoholic beer and non alcoholic prosecco ', 'node_id__128': '267ecb06-0809-4d2b-9e93-326373e1e3a4', 'embedding__128': '[-0.003192455042153597,-0.024405822157859802,-0.030045825988054276,-0.02793676033616066,-0.027735702693462372,-0.07140562683343887,-0.004404275212436 ... (15886 characters truncated) ... 591,0.05268755555152893,0.01643887534737587,0.006887074094265699,-0.02396492101252079,0.05428694188594818,-0.01681523025035858,-0.011984645389020443]', 'metadata___128': '{"faq_question": "Do you offer non alcoholic drinks ", "source_row": 128, "_node_content": "{\\"id_\\": \\"267ecb06-0809-4d2b-9e93-326373e1e3a4\\", \ ... (743 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__129': 'Question: Does the venue have fairy lights? Do they cost extra? \nAnswer: Yes fairy lights are set above the main dinner area no additional charge applies', 'node_id__129': 'd644ee63-4c5e-4fd5-a3c4-99ce7007a7d2', 'embedding__129': '[-0.002875101985409856,-0.01975240558385849,-0.0385885015130043,-0.0531228706240654,-0.020586783066391945,-0.03674594312906265,-0.03141775727272034,- ... (15887 characters truncated) ... 87405,0.04113975167274475,-0.02106093429028988,-0.014783401973545551,-0.0860760435461998,0.0675274133682251,0.04684889316558838,0.006298755295574665]', 'metadata___129': '{"faq_question": "Does the venue have fairy lights? Do they cost extra? ", "source_row": 129, "_node_content": "{\\"id_\\": \\"d644ee63-4c5e-4fd5-a3c ... (776 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__130': 'Question: Do you offer fairy lights packages?\nAnswer: Yes you can hire fairy light packages from suggested ventors ', 'node_id__130': '832dec2e-9b85-4574-8b09-1e2e93353b7e', 'embedding__130': '[-0.022461144253611565,-0.01744770258665085,-0.02908291295170784,-0.04099619388580322,0.0005974787636660039,-0.04344586655497551,-0.01736037805676460 ... (15897 characters truncated) ... 092285,0.05682354420423508,-0.0351269468665123,-0.013536954298615456,-0.09071972966194153,0.06438392400741577,0.0228826105594635,0.03674847632646561]', 'metadata___130': '{"faq_question": "Do you offer fairy lights packages?", "source_row": 130, "_node_content": "{\\"id_\\": \\"832dec2e-9b85-4574-8b09-1e2e93353b7e\\",  ... (700 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__131': 'Question: Is your venue child friendly?\nAnswer: Yes we would say our venue is child friendly, we welcome families with young children most of the time ', 'node_id__131': '30987909-830f-4870-b166-75f70543dbfb', 'embedding__131': '[-0.0446934811770916,-0.035919517278671265,-0.027393562719225883,-0.054229333996772766,0.00013371089880820364,-0.054871074855327606,0.019008820876479 ... (15890 characters truncated) ... 7226,0.06824860721826553,0.0062518916092813015,0.014546978287398815,-0.05343842878937721,0.0400112085044384,0.007313424721360207,0.02629460208117962]', 'metadata___131': '{"faq_question": "Is your venue child friendly?", "source_row": 131, "_node_content": "{\\"id_\\": \\"30987909-830f-4870-b166-75f70543dbfb\\", \\"emb ... (724 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__132': 'Question: Are there any facilities in rooms?\nAnswer: Yes of course, in our rooms we provide tea and coffee facilities, hairdryer, safe, mini fridge with small bottles of water. For the shower we provide shower gel and soap. ', 'node_id__132': 'f618017b-ac4e-4191-b8a1-fe80f2f4de71', 'embedding__132': '[-0.006934785284101963,-0.016350481659173965,-0.02842964045703411,-0.022188808768987656,-0.01789422146975994,-0.024045007303357124,-0.024615639820694 ... (15913 characters truncated) ... ,0.09094378352165222,0.004178320523351431,-0.009394531138241291,-0.061488643288612366,0.025287069380283356,0.052145395427942276,-0.03846484422683716]', 'metadata___132': '{"faq_question": "Are there any facilities in rooms?", "source_row": 132, "_node_content": "{\\"id_\\": \\"f618017b-ac4e-4191-b8a1-fe80f2f4de71\\", \ ... (807 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'text__133': 'Question: Is there a smoking area? \nAnswer: There is no designated area for smoking however we encourage guests to use the carob tree area for smoking as we provide ashtrays there. ', 'node_id__133': '059aa725-002d-46bf-a634-e9c43bc1d323', 'embedding__133': '[0.0019000262254849076,-0.015416349284350872,-0.02678222768008709,-0.07339641451835632,-0.007842722348868847,-0.05898557975888252,-0.0149022247642278 ... (15903 characters truncated) ... 6465,0.04639805480837822,0.03003525175154209,0.030347861349582672,-0.04560208320617676,0.05326217785477638,0.03359312191605568,-0.026956506073474884]', 'metadata___133': '{"faq_question": "Is there a smoking area? ", "source_row": 133, "_node_content": "{\\"id_\\": \\"059aa725-002d-46bf-a634-e9c43bc1d323\\", \\"embeddi ... (746 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}'}]
(Background on this error at: https://sqlalche.me/e/20/f405)
2025-07-11 13:27:07,656 - INFO - Local LLM initialized successfully
2025-07-11 13:27:08,063 - INFO - Local embedding model initialized successfully
2025-07-11 13:27:08,073 - INFO - Documents loaded successfully from ./data/VW_dataMar25.txt
2025-07-11 13:27:08,073 - INFO - First document: Title: Why a Groom-To-Be Should Have a Stag Do

Co...
2025-07-11 13:27:08,172 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite-preview-06-17 "HTTP/1.1 200 OK"
2025-07-11 13:27:08,184 - INFO - Connecting to PostgreSQL database: chatbot_rag at 167.99.197.215:5432 as user chatbot
2025-07-11 13:27:08,184 - INFO - Using table name: vasilias_weddings_2025_07_11
2025-07-11 13:27:08,185 - INFO - Vector store created successfully: vasilias_weddings_2025_07_11
2025-07-11 13:27:08,185 - INFO - Storing documents in table: vasilias_weddings_2025_07_11
2025-07-11 13:27:08,898 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:09,228 - WARNING - PG Setup: Error creating extension: (psycopg2.errors.UndefinedFile) could not open extension control file "/usr/share/postgresql/14/extension/vector.control": No such file or directory

[SQL: CREATE EXTENSION IF NOT EXISTS vector]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
2025-07-11 13:27:09,280 - WARNING - PG Setup: Error creating tables: (psycopg2.errors.UndefinedObject) type "vector" does not exist
LINE 7:  embedding VECTOR(768), 
                   ^

[SQL: 
CREATE TABLE public.data_vasilias_weddings_2025_07_11 (
	id BIGSERIAL NOT NULL, 
	text VARCHAR NOT NULL, 
	metadata_ JSON, 
	node_id VARCHAR, 
	embedding VECTOR(768), 
	PRIMARY KEY (id)
)

]
(Background on this error at: https://sqlalche.me/e/20/f405)
2025-07-11 13:27:09,468 - ERROR - Error storing documents: (psycopg2.errors.UndefinedTable) relation "public.data_vasilias_weddings_2025_07_11" does not exist
LINE 1: INSERT INTO public.data_vasilias_weddings_2025_07_11 (text, ...
                    ^

[SQL: INSERT INTO public.data_vasilias_weddings_2025_07_11 (text, metadata_, node_id, embedding) VALUES (%(text)s, %(metadata_)s::JSON, %(node_id)s, %(embedding)s) RETURNING public.data_vasilias_weddings_2025_07_11.id]
[parameters: {'text': 'Title: Why a Groom-To-Be Should Have a Stag Do\n\nContent: Why a Groom-To-Be Should Have a Stag Do Ball and chain jokes aside, there are some excelle ... (271276 characters truncated) ... ion to life. For our past couples, thank you for choosing us to be part of your unforgettable journey. God Bless!! From Christina and team\n\n---\n\n', 'metadata_': '{"file_path": "data/VW_dataMar25.txt", "file_name": "VW_dataMar25.txt", "file_type": "text/plain", "file_size": 271740, "creation_date": "2025-04-17" ... (278265 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id': 'c6751213-ce42-4a7b-b92b-c1035aef3755', 'embedding': '[-0.02314147725701332,-0.024927489459514618,-0.002672185655683279,-0.02657134272158146,0.026404282078146935,-0.0017854926409199834,-0.045410268008708 ... (15929 characters truncated) ... 018380574882030487,-0.04060577601194382,0.014149913564324379,-0.08689773827791214,0.0008354479214176536,-0.0012618799228221178,-0.020087536424398422]'}]
(Background on this error at: https://sqlalche.me/e/20/f405)
2025-07-11 13:27:09,468 - INFO - Local LLM initialized successfully
2025-07-11 13:27:09,483 - INFO - Local embedding model initialized successfully
2025-07-11 13:27:09,495 - INFO - Parsed 134 documents from CSV file ./data/VWFAQ24052025.csv
2025-07-11 13:27:09,495 - INFO - Documents loaded successfully from ./data/VWFAQ24052025.csv
2025-07-11 13:27:09,495 - INFO - First document: Question: Can you help with legal requirements for...
2025-07-11 13:27:09,560 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite-preview-06-17 "HTTP/1.1 200 OK"
2025-07-11 13:27:09,571 - INFO - Connecting to PostgreSQL database: chatbot_rag at 167.99.197.215:5432 as user chatbot
2025-07-11 13:27:09,571 - INFO - Using table name: vasilias_weddings_2025_07_11
2025-07-11 13:27:09,572 - INFO - Vector store created successfully: vasilias_weddings_2025_07_11
2025-07-11 13:27:09,572 - INFO - Storing documents in table: vasilias_weddings_2025_07_11
2025-07-11 13:27:09,920 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:10,153 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:10,391 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:10,614 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:10,945 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:11,253 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:11,558 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:11,782 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:12,175 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:12,481 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:12,789 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:13,094 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:13,367 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:13,596 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:13,916 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:14,222 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:14,529 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:14,837 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:15,143 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:15,451 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:15,758 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:16,066 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:16,372 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:16,679 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:16,988 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:17,294 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:17,601 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:17,909 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:18,215 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:18,522 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:18,780 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:19,036 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:19,445 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:19,751 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:27:20,060 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-07-11 13:29:14,262 - INFO - Local LLM initialized successfully
2025-07-11 13:29:14,597 - INFO - Local embedding model initialized successfully
2025-07-11 13:29:14,601 - INFO - Documents loaded successfully from ./data/VW_dataMar25.txt
2025-07-11 13:29:14,609 - INFO - Connecting to PostgreSQL database: chatbot_rag at 167.99.197.215:5432 as user chatbot
2025-07-11 13:29:14,609 - INFO - Using table name: vasilias_weddings_2025_07_11
2025-07-11 13:29:14,610 - INFO - Vector store created successfully: vasilias_weddings_2025_07_11
2025-07-11 13:29:14,610 - INFO - Storing documents in table: vasilias_weddings_2025_07_11
2025-07-11 13:29:14,621 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,622 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,622 - WARNING - Failed to embed document 4903f124-1a11-490d-bc0e-cbe7c2afacb6
2025-07-11 13:29:14,622 - WARNING - No nodes to store in vector store.
2025-07-11 13:29:14,622 - INFO - Local LLM initialized successfully
2025-07-11 13:29:14,630 - INFO - Local embedding model initialized successfully
2025-07-11 13:29:14,635 - INFO - Parsed 134 documents from CSV file ./data/VWFAQ24052025.csv
2025-07-11 13:29:14,635 - INFO - Documents loaded successfully from ./data/VWFAQ24052025.csv
2025-07-11 13:29:14,635 - INFO - First document: Question: Can you help with legal requirements for...
2025-07-11 13:29:14,643 - INFO - Connecting to PostgreSQL database: chatbot_rag at 167.99.197.215:5432 as user chatbot
2025-07-11 13:29:14,643 - INFO - Using table name: vasilias_weddings_2025_07_11
2025-07-11 13:29:14,644 - INFO - Vector store created successfully: vasilias_weddings_2025_07_11
2025-07-11 13:29:14,644 - INFO - Storing documents in table: vasilias_weddings_2025_07_11
2025-07-11 13:29:14,645 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,645 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,645 - WARNING - Failed to embed document 81963c02-35d6-4f3d-9769-7ab95951da59
2025-07-11 13:29:14,646 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,646 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,646 - WARNING - Failed to embed document a67198f4-7e7d-4ae4-a159-5f681b0e94e0
2025-07-11 13:29:14,647 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,647 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,647 - WARNING - Failed to embed document 431ad66b-7186-4f40-a89a-c1e03fb12f5a
2025-07-11 13:29:14,647 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,647 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,647 - WARNING - Failed to embed document d079fa77-2ccc-40dd-8be9-2369778ee5d4
2025-07-11 13:29:14,648 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,648 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,648 - WARNING - Failed to embed document 9cd11545-58d9-4ea0-97cd-9cec0f6b121e
2025-07-11 13:29:14,648 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,649 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,649 - WARNING - Failed to embed document 143f59cf-e88b-46fa-8657-ee1139159a75
2025-07-11 13:29:14,649 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,649 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,649 - WARNING - Failed to embed document cfd33756-de03-4e49-956a-4b731d253fc2
2025-07-11 13:29:14,649 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,650 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,650 - WARNING - Failed to embed document 636a36f2-d98c-4ffb-9542-43ec442831a3
2025-07-11 13:29:14,650 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,650 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,650 - WARNING - Failed to embed document f05e26f4-8369-4a01-aeae-7278893ace28
2025-07-11 13:29:14,650 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,651 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,651 - WARNING - Failed to embed document 90817559-a4b0-4eab-a756-430c7dfacd01
2025-07-11 13:29:14,651 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,651 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,651 - WARNING - Failed to embed document fcaf3355-0bd3-4297-ac49-5e5388e181d1
2025-07-11 13:29:14,651 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,651 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,651 - WARNING - Failed to embed document 0e855714-1e28-4e6c-be15-ecfd6c16d9d3
2025-07-11 13:29:14,652 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,652 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,652 - WARNING - Failed to embed document d8e944ea-b1fd-4356-8f3b-0d2658ad5eb6
2025-07-11 13:29:14,652 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,652 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,652 - WARNING - Failed to embed document ae38e961-1ddb-42b5-b157-30b02d104e23
2025-07-11 13:29:14,653 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,653 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,653 - WARNING - Failed to embed document 7198ee4f-ad64-41bc-afd1-3c26e6a51678
2025-07-11 13:29:14,653 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,653 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,653 - WARNING - Failed to embed document 1fd03726-6e59-4264-adb7-c56886d4a4c1
2025-07-11 13:29:14,654 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,654 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,654 - WARNING - Failed to embed document 89689013-ea38-4de8-9e6c-9a835eae285c
2025-07-11 13:29:14,654 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,654 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,654 - WARNING - Failed to embed document fc6f5ede-7aa7-454e-9e18-531520094f27
2025-07-11 13:29:14,654 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,655 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,655 - WARNING - Failed to embed document 1c41ea9d-1002-4eae-8848-259885f12e63
2025-07-11 13:29:14,660 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,660 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,660 - WARNING - Failed to embed document eeadc629-6d7a-41de-99d0-e2b233a61333
2025-07-11 13:29:14,663 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,663 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,663 - WARNING - Failed to embed document 8e3f0e15-ac7f-417e-9fff-1fe7cb5dd11d
2025-07-11 13:29:14,665 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,666 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,666 - WARNING - Failed to embed document 71601f30-5f55-49e8-81af-f5edcdefbb2f
2025-07-11 13:29:14,668 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,668 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,669 - WARNING - Failed to embed document 1b7b39c0-ba88-438b-8f6c-9aabe02380b2
2025-07-11 13:29:14,670 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,670 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,671 - WARNING - Failed to embed document 78496575-34a4-41d6-a28b-4d4b1d8518fd
2025-07-11 13:29:14,672 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,672 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,672 - WARNING - Failed to embed document 61e3f309-608f-4da9-b454-3f7ddf9b144b
2025-07-11 13:29:14,673 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,674 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,674 - WARNING - Failed to embed document 356b4dca-dbef-4a87-a4a6-ddaa741b685a
2025-07-11 13:29:14,674 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,675 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,675 - WARNING - Failed to embed document 7d8c909f-10c0-41bd-8e7b-0223871f8536
2025-07-11 13:29:14,675 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,675 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,675 - WARNING - Failed to embed document fb80958f-defe-4aa4-93a8-0418ec47acd5
2025-07-11 13:29:14,676 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,676 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,676 - WARNING - Failed to embed document 166ec137-fefa-4db1-8c0a-ff85e2bc9e2b
2025-07-11 13:29:14,676 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,676 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,676 - WARNING - Failed to embed document 5991c241-1e3a-402e-9525-c084efc1aef5
2025-07-11 13:29:14,677 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,677 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,677 - WARNING - Failed to embed document ba93c9a3-d81c-4edc-ac2e-a08c4df78daa
2025-07-11 13:29:14,677 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,678 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,678 - WARNING - Failed to embed document 91fa6c90-e53a-4993-b28f-431de3f77ed0
2025-07-11 13:29:14,679 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,679 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,679 - WARNING - Failed to embed document db4d493e-2560-492c-996c-4773c0c06795
2025-07-11 13:29:14,680 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,681 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,681 - WARNING - Failed to embed document 27d69070-4676-4559-b84c-ab10b8d14fb2
2025-07-11 13:29:14,682 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,682 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,682 - WARNING - Failed to embed document d31301cb-cce4-4bda-bdb2-0737d7877555
2025-07-11 13:29:14,683 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,683 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,683 - WARNING - Failed to embed document ae57e646-0067-43fe-8566-90bb3b76c484
2025-07-11 13:29:14,683 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,683 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,683 - WARNING - Failed to embed document bfcf600f-3329-4433-8fd4-52c3e8a969ac
2025-07-11 13:29:14,684 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,684 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,684 - WARNING - Failed to embed document f8c3b62a-18f3-4811-9573-bd2e4ff542b2
2025-07-11 13:29:14,684 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,684 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,684 - WARNING - Failed to embed document ae6e1d33-d276-4d0e-bab7-72f45d057aa3
2025-07-11 13:29:14,685 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,685 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,685 - WARNING - Failed to embed document c3ba592d-36d7-47db-9000-c2a74740bbaf
2025-07-11 13:29:14,685 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,685 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,685 - WARNING - Failed to embed document b591ee67-c1e4-454b-a26e-8bb8c12927c9
2025-07-11 13:29:14,685 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,686 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,686 - WARNING - Failed to embed document 070c6513-db3b-4af6-9fbb-357dd18cd368
2025-07-11 13:29:14,686 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,686 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,686 - WARNING - Failed to embed document c12b689f-928f-4f34-80fe-1130ad6afa7e
2025-07-11 13:29:14,686 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,686 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,686 - WARNING - Failed to embed document 303cedad-e97c-4181-bd79-599ab4e9e9d8
2025-07-11 13:29:14,687 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,687 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,687 - WARNING - Failed to embed document 4242cb57-f274-4150-8d12-563444e2a050
2025-07-11 13:29:14,687 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,687 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,687 - WARNING - Failed to embed document 64aa9b68-d2ff-43e3-a64c-ec8360e22dd4
2025-07-11 13:29:14,687 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,688 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,688 - WARNING - Failed to embed document b58b4bf0-3cff-4add-9046-d8539f015175
2025-07-11 13:29:14,688 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,688 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,688 - WARNING - Failed to embed document d6ffa095-e58b-4393-8461-afacd6b150c2
2025-07-11 13:29:14,688 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,688 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,688 - WARNING - Failed to embed document 596fde14-34d6-41b8-adbd-75afe7a3bdd1
2025-07-11 13:29:14,689 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,689 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,689 - WARNING - Failed to embed document 8cfab2aa-c333-4bbc-aa0a-5e957a147a1f
2025-07-11 13:29:14,689 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,689 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,689 - WARNING - Failed to embed document 6fecd470-56bb-4559-81b6-ab299569a2b6
2025-07-11 13:29:14,689 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,690 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,690 - WARNING - Failed to embed document 08bd3976-a64f-4a11-9bd3-24a26ec69ce7
2025-07-11 13:29:14,690 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,690 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,690 - WARNING - Failed to embed document 2e7066d7-c592-4a67-a6bf-fd5637d56a6a
2025-07-11 13:29:14,690 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,690 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,691 - WARNING - Failed to embed document 1ef7b20b-5ee9-42d4-a5ea-696ea6474126
2025-07-11 13:29:14,691 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,691 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,691 - WARNING - Failed to embed document fac26a99-9d04-4d3e-acea-438fac7ddaa1
2025-07-11 13:29:14,691 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,691 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,691 - WARNING - Failed to embed document 9a50b5d7-7ea5-43a9-b7f7-fd819566ac7c
2025-07-11 13:29:14,692 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,692 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,692 - WARNING - Failed to embed document 04755b12-cb9e-4e1b-9f32-02d23b25ed71
2025-07-11 13:29:14,692 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,692 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,692 - WARNING - Failed to embed document 64746788-4720-41d5-88b9-d8842d3e1178
2025-07-11 13:29:14,692 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,692 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,692 - WARNING - Failed to embed document 15a52f60-9d79-469b-9c15-16157f4f2646
2025-07-11 13:29:14,693 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,693 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,693 - WARNING - Failed to embed document 60857d86-e033-42bb-b2ea-70cf4c5b651c
2025-07-11 13:29:14,693 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,693 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,693 - WARNING - Failed to embed document 2159151e-b90b-43d1-b8d8-287772204437
2025-07-11 13:29:14,694 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,694 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,694 - WARNING - Failed to embed document 485bb186-d5d3-4b5e-8fa2-00c1eadbc87b
2025-07-11 13:29:14,694 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,694 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,694 - WARNING - Failed to embed document 9d10ad6a-149e-4264-8430-38bd7f924d2b
2025-07-11 13:29:14,694 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,695 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,695 - WARNING - Failed to embed document 313abd70-c4ec-4868-85d1-da4c67d56901
2025-07-11 13:29:14,695 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,695 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,695 - WARNING - Failed to embed document bfaca7fc-fe92-4b01-8920-83b1da904826
2025-07-11 13:29:14,695 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,695 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,695 - WARNING - Failed to embed document 6c3c0f92-785a-45bc-96c2-bd501dd97dc8
2025-07-11 13:29:14,696 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,696 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,696 - WARNING - Failed to embed document ee72735c-37d3-477e-bb89-30ee8166c109
2025-07-11 13:29:14,696 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,696 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,696 - WARNING - Failed to embed document d76f95ec-5da3-435f-ad20-1ff2e853999f
2025-07-11 13:29:14,697 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,697 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,697 - WARNING - Failed to embed document 0bdf63d8-91ef-4d1a-9424-835e45b60e17
2025-07-11 13:29:14,697 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,697 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,697 - WARNING - Failed to embed document 0b572920-6710-4ffe-a63a-68cfd3ad38aa
2025-07-11 13:29:14,698 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,698 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,698 - WARNING - Failed to embed document 15cbc9db-d4d2-47c2-86d8-9eb5d68acfbf
2025-07-11 13:29:14,698 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,698 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,698 - WARNING - Failed to embed document 27f4c176-0e56-44db-9939-602b19889cd4
2025-07-11 13:29:14,698 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,698 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,698 - WARNING - Failed to embed document 44523eaf-baf3-4644-8049-27405d99c05a
2025-07-11 13:29:14,699 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,699 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,699 - WARNING - Failed to embed document bba7f668-de04-47f1-9e5f-db5c6d6f8405
2025-07-11 13:29:14,699 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,699 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,699 - WARNING - Failed to embed document 912f1f9a-8355-4534-86d2-79fbad12d9c2
2025-07-11 13:29:14,699 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,699 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,700 - WARNING - Failed to embed document e1884b95-f6f8-4665-bc3b-2f4941b7267a
2025-07-11 13:29:14,700 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,700 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,700 - WARNING - Failed to embed document e0553ad8-d66e-410f-8136-c8296ab15a90
2025-07-11 13:29:14,700 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,700 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,700 - WARNING - Failed to embed document 06c4a625-9b9a-43e1-b456-17ca914aebfb
2025-07-11 13:29:14,701 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,701 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,701 - WARNING - Failed to embed document ab8057a2-824d-4b9c-b0b0-6ee3a83fb9c3
2025-07-11 13:29:14,701 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,701 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,701 - WARNING - Failed to embed document 5a67fb06-4504-48bf-aa5a-c54af9a4fa31
2025-07-11 13:29:14,701 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,701 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,702 - WARNING - Failed to embed document 11bd2aaa-0aee-4e3e-84ae-31169919281f
2025-07-11 13:29:14,702 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,702 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,702 - WARNING - Failed to embed document bf8e6151-5ef7-4590-8362-3c04ce96db32
2025-07-11 13:29:14,702 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,702 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,702 - WARNING - Failed to embed document 56b74930-e25d-4928-bf0b-e00566a5280c
2025-07-11 13:29:14,703 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,703 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,703 - WARNING - Failed to embed document d5505fb2-cfbc-4502-b406-29790c4a1e8a
2025-07-11 13:29:14,703 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,703 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,703 - WARNING - Failed to embed document 1452997a-5cad-4017-b44d-b10d6bcb762c
2025-07-11 13:29:14,703 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,703 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,703 - WARNING - Failed to embed document 10b302f3-0b90-4411-b1fb-1e4eee115162
2025-07-11 13:29:14,704 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,704 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,704 - WARNING - Failed to embed document 2a4a3a33-1956-40a4-965f-dea806a257f6
2025-07-11 13:29:14,704 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,704 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,704 - WARNING - Failed to embed document 16c538e9-a23e-4489-8eab-4c65b3fd0cc3
2025-07-11 13:29:14,704 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,705 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,705 - WARNING - Failed to embed document 526db69a-abb9-48c6-8bd7-d023cf5d9cbd
2025-07-11 13:29:14,705 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,705 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,705 - WARNING - Failed to embed document 2314ff5b-233f-4bf0-a9e1-45dc61ced31a
2025-07-11 13:29:14,705 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,705 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,705 - WARNING - Failed to embed document a2d7319c-1c30-404c-8603-f6fa43a0d057
2025-07-11 13:29:14,706 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,706 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,706 - WARNING - Failed to embed document eb72c6e7-1c15-4840-9c42-fe5e5c7600c3
2025-07-11 13:29:14,706 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,706 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,706 - WARNING - Failed to embed document b547d5e2-55d7-496c-b15f-34bf03b7aee9
2025-07-11 13:29:14,707 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,707 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,707 - WARNING - Failed to embed document 8f5cc7b0-328b-4f27-8cb1-9cde053dd95a
2025-07-11 13:29:14,707 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,708 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,708 - WARNING - Failed to embed document 6ad5896b-1915-46cd-a65e-5ecd61a79cd7
2025-07-11 13:29:14,708 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,708 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,708 - WARNING - Failed to embed document cf994b24-4d5c-42f4-99f0-568735c1ad63
2025-07-11 13:29:14,708 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,709 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,709 - WARNING - Failed to embed document 6d4c0ee8-a0f8-4d00-b888-9457538e7c48
2025-07-11 13:29:14,709 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,709 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,709 - WARNING - Failed to embed document 2447827f-cb1e-4e9e-964b-73be0d4dc796
2025-07-11 13:29:14,709 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,709 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,709 - WARNING - Failed to embed document f3598d82-9d91-40a6-aebd-da708dd58dcf
2025-07-11 13:29:14,710 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,710 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,710 - WARNING - Failed to embed document ee0926af-63f2-481b-b8cb-1f11439bd0e4
2025-07-11 13:29:14,711 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,711 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,711 - WARNING - Failed to embed document caab9c24-85e6-45ee-b476-527f344390ed
2025-07-11 13:29:14,711 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,711 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,711 - WARNING - Failed to embed document 30eca0bc-aafe-465d-a915-c411ac9d5ca8
2025-07-11 13:29:14,711 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,711 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,711 - WARNING - Failed to embed document 4bca94cc-3c90-490f-9de2-bde494835a4d
2025-07-11 13:29:14,712 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,712 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,712 - WARNING - Failed to embed document caf791c4-d1c3-4db8-a6d2-70ffbdda12e8
2025-07-11 13:29:14,712 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,712 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,712 - WARNING - Failed to embed document 84284aa2-e2aa-4178-9b51-e5f0b0793caf
2025-07-11 13:29:14,712 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,713 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,713 - WARNING - Failed to embed document c87b9708-1675-436a-b548-636e3eeb3d17
2025-07-11 13:29:14,713 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,713 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,713 - WARNING - Failed to embed document e3481a04-d245-4926-be19-33dc90f35901
2025-07-11 13:29:14,713 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,713 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,713 - WARNING - Failed to embed document bf8ec35d-bb34-4f9d-b342-e87e793a811f
2025-07-11 13:29:14,714 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,714 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,714 - WARNING - Failed to embed document af2122e8-f640-43ed-8f3b-0cd925991044
2025-07-11 13:29:14,714 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,714 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,714 - WARNING - Failed to embed document 005923a8-9273-4574-95c0-6db6b4147465
2025-07-11 13:29:14,715 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,715 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,715 - WARNING - Failed to embed document 83acd2ad-42f2-4567-bd87-c727dcd77509
2025-07-11 13:29:14,715 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,715 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,715 - WARNING - Failed to embed document 55990ea3-823a-4373-9b9b-d09dbd685282
2025-07-11 13:29:14,715 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,715 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,715 - WARNING - Failed to embed document 5fa6bb25-a590-4e25-8191-707a410044f2
2025-07-11 13:29:14,716 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,716 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,716 - WARNING - Failed to embed document 4cbc9895-2699-4fa2-b3d2-9c6d3b7186c3
2025-07-11 13:29:14,716 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,716 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,716 - WARNING - Failed to embed document f5151e69-0d08-48ce-bfe8-a7761a98cf01
2025-07-11 13:29:14,716 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,716 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,717 - WARNING - Failed to embed document 12e21417-cbbc-4f0d-9936-8908e09f5f7d
2025-07-11 13:29:14,717 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,717 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,717 - WARNING - Failed to embed document 5813ff47-eb56-4647-bb37-210e0fe74f29
2025-07-11 13:29:14,717 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,717 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,717 - WARNING - Failed to embed document ca8383ea-20b7-4bb8-90d6-056a592c6a82
2025-07-11 13:29:14,718 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,718 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,718 - WARNING - Failed to embed document 9c8f4d1d-bb89-4fc2-a66f-c998870a4ec5
2025-07-11 13:29:14,718 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,718 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,718 - WARNING - Failed to embed document ad8c7336-a6aa-4b60-b81c-ff19fabaafd8
2025-07-11 13:29:14,718 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,718 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,718 - WARNING - Failed to embed document 830862b3-d540-44ae-8fb6-be560c8c9e23
2025-07-11 13:29:14,719 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,719 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,719 - WARNING - Failed to embed document c3540d86-7256-4b38-9eb4-46546b742418
2025-07-11 13:29:14,719 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,719 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,719 - WARNING - Failed to embed document a7dd77fb-5fda-421b-a80d-4a0ed44222d4
2025-07-11 13:29:14,719 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,719 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,719 - WARNING - Failed to embed document e61b0a05-3192-4cb4-98c2-4077e84b0e29
2025-07-11 13:29:14,720 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,720 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,720 - WARNING - Failed to embed document f81f36b5-c07f-4a62-b9c7-bd6cad944af1
2025-07-11 13:29:14,720 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,720 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,720 - WARNING - Failed to embed document 0ec64873-d4b9-43d6-93f0-a70a1a58d9ee
2025-07-11 13:29:14,720 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,721 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,721 - WARNING - Failed to embed document 21c63357-aef0-4de2-a40c-2d3ee65157c2
2025-07-11 13:29:14,721 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,721 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,721 - WARNING - Failed to embed document 5fc53da3-9b47-40f9-a4e5-0131991445fc
2025-07-11 13:29:14,721 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,722 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,722 - WARNING - Failed to embed document 4b63b5a2-a58d-4661-bbd9-63e5eb072049
2025-07-11 13:29:14,722 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,722 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,722 - WARNING - Failed to embed document 51d076a2-0f60-418e-8f45-1b329f32255f
2025-07-11 13:29:14,722 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,722 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,722 - WARNING - Failed to embed document 33c8b9ef-af77-44eb-9c96-e720e4559de6
2025-07-11 13:29:14,723 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,723 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,723 - WARNING - Failed to embed document 0c9818e8-49f7-457f-965c-82915222c492
2025-07-11 13:29:14,723 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,723 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,723 - WARNING - Failed to embed document 8c833ebf-a01b-440c-9c75-0be5d3998f99
2025-07-11 13:29:14,723 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 404 Not Found"
2025-07-11 13:29:14,723 - ERROR - Error during embedding: model "mquentinz/bge-base-zh-v1.5:latest" not found, try pulling it first (status code: 404)
2025-07-11 13:29:14,723 - WARNING - Failed to embed document 0e382d29-2c05-424e-af49-dde7950913a0
2025-07-11 13:29:14,723 - WARNING - No nodes to store in vector store.
2025-07-11 13:31:13,296 - INFO - Local LLM initialized successfully
2025-07-11 13:31:13,627 - INFO - Local embedding model initialized successfully
2025-07-11 13:31:13,630 - INFO - Documents loaded successfully from ./data/VW_dataMar25.txt
2025-07-11 13:31:13,639 - INFO - Connecting to PostgreSQL database: chatbot_rag at 167.99.197.215:5432 as user chatbot
2025-07-11 13:31:13,639 - INFO - Using table name: vasilias_weddings_2025_07_11
2025-07-11 13:31:13,640 - INFO - Vector store created successfully: vasilias_weddings_2025_07_11
2025-07-11 13:31:13,640 - INFO - Storing documents in table: vasilias_weddings_2025_07_11
2025-07-11 13:31:14,319 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:14,586 - WARNING - PG Setup: Error creating extension: (psycopg2.errors.UndefinedFile) could not open extension control file "/usr/share/postgresql/14/extension/vector.control": No such file or directory

[SQL: CREATE EXTENSION IF NOT EXISTS vector]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
2025-07-11 13:31:14,633 - WARNING - PG Setup: Error creating tables: (psycopg2.errors.UndefinedObject) type "vector" does not exist
LINE 7:  embedding VECTOR(768), 
                   ^

[SQL: 
CREATE TABLE public.data_vasilias_weddings_2025_07_11 (
	id BIGSERIAL NOT NULL, 
	text VARCHAR NOT NULL, 
	metadata_ JSON, 
	node_id VARCHAR, 
	embedding VECTOR(768), 
	PRIMARY KEY (id)
)

]
(Background on this error at: https://sqlalche.me/e/20/f405)
2025-07-11 13:31:14,767 - ERROR - Error storing documents: (psycopg2.errors.UndefinedTable) relation "public.data_vasilias_weddings_2025_07_11" does not exist
LINE 1: INSERT INTO public.data_vasilias_weddings_2025_07_11 (text, ...
                    ^

[SQL: INSERT INTO public.data_vasilias_weddings_2025_07_11 (text, metadata_, node_id, embedding) VALUES (%(text)s, %(metadata_)s::JSON, %(node_id)s, %(embedding)s) RETURNING public.data_vasilias_weddings_2025_07_11.id]
[parameters: {'text': 'Title: Why a Groom-To-Be Should Have a Stag Do\n\nContent: Why a Groom-To-Be Should Have a Stag Do Ball and chain jokes aside, there are some excelle ... (271276 characters truncated) ... ion to life. For our past couples, thank you for choosing us to be part of your unforgettable journey. God Bless!! From Christina and team\n\n---\n\n', 'metadata_': '{"file_path": "data/VW_dataMar25.txt", "file_name": "VW_dataMar25.txt", "file_type": "text/plain", "file_size": 271740, "creation_date": "2025-04-17" ... (278265 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id': '13c41f17-b061-49ca-87f6-7980ba91cad2', 'embedding': '[-0.10581937432289124,0.14850890636444092,0.3408164978027344,0.25448232889175415,-0.27542349696159363,-0.02787790074944496,0.4859755039215088,-0.1216 ... (15168 characters truncated) ... 499573,0.23400819301605225,0.024371393024921417,0.14903010427951813,0.3223758935928345,-0.4297529458999634,-0.20167452096939087,-0.21129900217056274]'}]
(Background on this error at: https://sqlalche.me/e/20/f405)
2025-07-11 13:31:14,767 - INFO - Local LLM initialized successfully
2025-07-11 13:31:14,784 - INFO - Local embedding model initialized successfully
2025-07-11 13:31:14,795 - INFO - Parsed 134 documents from CSV file ./data/VWFAQ24052025.csv
2025-07-11 13:31:14,795 - INFO - Documents loaded successfully from ./data/VWFAQ24052025.csv
2025-07-11 13:31:14,795 - INFO - First document: Question: Can you help with legal requirements for...
2025-07-11 13:31:14,806 - INFO - Connecting to PostgreSQL database: chatbot_rag at 167.99.197.215:5432 as user chatbot
2025-07-11 13:31:14,807 - INFO - Using table name: vasilias_weddings_2025_07_11
2025-07-11 13:31:14,807 - INFO - Vector store created successfully: vasilias_weddings_2025_07_11
2025-07-11 13:31:14,807 - INFO - Storing documents in table: vasilias_weddings_2025_07_11
2025-07-11 13:31:14,849 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:14,874 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:14,895 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:14,917 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:14,940 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:14,965 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:14,989 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,015 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,041 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,066 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,090 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,114 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,141 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,170 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,196 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,225 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,254 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,277 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,303 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,330 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,356 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,380 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,403 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,432 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,461 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,494 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,518 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,543 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,573 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,592 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,611 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,633 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,655 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,677 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,699 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,721 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,740 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,762 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,787 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,804 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,827 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,849 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,878 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,901 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,923 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,948 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,972 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:15,994 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,014 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,032 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,053 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,076 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,101 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,118 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,136 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,152 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,167 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,193 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,214 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,240 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,264 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,292 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,311 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,330 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,351 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,377 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,400 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,428 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,453 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,472 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,493 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,514 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,535 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,555 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,578 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,597 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,619 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,640 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,662 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,688 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,705 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,728 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,749 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,770 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,800 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,819 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,842 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,861 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,883 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,902 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,924 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,951 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:16,973 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,000 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,020 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,041 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,063 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,086 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,110 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,130 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,155 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,181 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,206 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,237 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,263 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,290 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,313 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,337 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,355 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,379 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,400 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,421 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,441 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,459 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,480 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,500 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,521 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,544 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,566 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,588 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,611 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,635 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,663 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,685 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,707 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,725 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,743 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,763 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,782 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,804 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,825 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,847 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,872 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:17,895 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 13:31:18,149 - WARNING - PG Setup: Error creating extension: (psycopg2.errors.UndefinedFile) could not open extension control file "/usr/share/postgresql/14/extension/vector.control": No such file or directory

[SQL: CREATE EXTENSION IF NOT EXISTS vector]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
2025-07-11 13:31:18,196 - WARNING - PG Setup: Error creating tables: (psycopg2.errors.UndefinedObject) type "vector" does not exist
LINE 7:  embedding VECTOR(768), 
                   ^

[SQL: 
CREATE TABLE public.data_vasilias_weddings_2025_07_11 (
	id BIGSERIAL NOT NULL, 
	text VARCHAR NOT NULL, 
	metadata_ JSON, 
	node_id VARCHAR, 
	embedding VECTOR(768), 
	PRIMARY KEY (id)
)

]
(Background on this error at: https://sqlalche.me/e/20/f405)
2025-07-11 13:31:18,602 - ERROR - Error storing documents: (psycopg2.errors.UndefinedTable) relation "public.data_vasilias_weddings_2025_07_11" does not exist
LINE 1: INSERT INTO public.data_vasilias_weddings_2025_07_11 (text, ...
                    ^

[SQL: INSERT INTO public.data_vasilias_weddings_2025_07_11 (text, metadata_, node_id, embedding) SELECT p0::VARCHAR, p1::JSON, p2::VARCHAR, p3::VECTOR(768) FROM (VALUES (%(text__0)s, %(metadata___0)s::JSON, %(node_id__0)s, %(embedding__0)s, 0), (%(text__1) ... 10955 characters truncated ... NG public.data_vasilias_weddings_2025_07_11.id, public.data_vasilias_weddings_2025_07_11.id AS id__1]
[parameters: {'metadata___0': '{"faq_question": "Can you help with legal requirements for getting married in Cyprus?", "source_row": 0, "_node_content": "{\\"id_\\": \\"ea82be57-92 ... (1127 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__0': 'ea82be57-92c2-4518-aa08-0fbcebd22c80', 'text__0': 'Question: Can you help with legal requirements for getting married in Cyprus?\nAnswer: Absolutely! We offer this service by simply hiring our ceremon ... (185 characters truncated) ... ou through legal requirements, provide templates of documents to be prepared , we make sure all of documents are prepared before arriving to Cyprus. ', 'embedding__0': '[-0.20165786147117615,0.20912417769432068,-0.29612264037132263,-0.26974037289619446,-0.27693289518356323,0.15691886842250824,-0.11118408292531967,-0. ... (15189 characters truncated) ... 582403183,-0.2713311016559601,0.1540076583623886,0.021040700376033783,0.5482485890388489,-0.5529170632362366,0.1335674524307251,0.020951727405190468]', 'metadata___1': '{"faq_question": "Can you recommend vendors for photography, catering, flowers, and entertainment?", "source_row": 1, "_node_content": "{\\"id_\\": \ ... (1065 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__1': '47c18a96-cbbc-43a3-9ef9-e918ac62d5f8', 'text__1': 'Question: Can you recommend vendors for photography, catering, flowers, and entertainment?\nAnswer: We have a curated list of trusted vendors who con ... (97 characters truncated) ... . We also provide packages to cover your needs and requirements. Get in touch to inquire information for our signature and finishing touches packages', 'embedding__1': '[-0.0819723904132843,-0.10836923122406006,-0.16320297122001648,-0.33021724224090576,-0.11030369997024536,-0.1031828299164772,0.10917200148105621,0.04 ... (15214 characters truncated) ... 3502559662,-0.4169313311576843,0.4638821482658386,0.2635745704174042,0.3864617347717285,-0.5137797594070435,0.06900743395090103,-0.40863102674484253]', 'metadata___2': '{"faq_question": "What is the average cost of a wedding in Cyprus?", "source_row": 2, "_node_content": "{\\"id_\\": \\"64c17fc1-fd5a-439b-815e-92740f ... (808 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__2': '64c17fc1-fd5a-439b-815e-92740f4e706f', 'text__2': 'Question: What is the average cost of a wedding in Cyprus?\nAnswer: Costs can vary depending on the number of guests and chosen services. We can provide you with detailed estimates based on your vision.', 'embedding__2': '[-0.420177698135376,0.4699915647506714,-0.3565334379673004,-0.1809481978416443,-0.37624019384384155,-0.13426610827445984,0.18435636162757874,-0.10760 ... (15204 characters truncated) ... 78844070435,0.1889885663986206,0.19340425729751587,0.23943771421909332,0.3766965866088867,-0.6282048225402832,0.2569825351238251,0.18638364970684052]', 'metadata___3': '{"faq_question": "Can you assist with accommodation for our guests?", "source_row": 3, "_node_content": "{\\"id_\\": \\"f7c597ed-695e-4f77-a907-1b58e ... (802 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__3': 'f7c597ed-695e-4f77-a907-1b58e5016eb4', 'text__3': 'Question: Can you assist with accommodation for our guests?\nAnswer: We offer 8 double rooms to accomodate up to 16 guests , baby cots and z beds available in some rooms to accomodate families. ', 'embedding__3': '[-0.026103680953383446,0.36038726568222046,0.24818947911262512,-0.1889800727367401,-0.2442002296447754,-0.24406544864177704,0.24183648824691772,-0.08 ... (15201 characters truncated) ... 2097587585,0.15302544832229614,0.1522578001022339,0.3672211766242981,0.2483658790588379,-0.7429863810539246,0.06254269182682037,0.028388487175107002]', 'metadata___4': '{"faq_question": "What are your packages and services, and are they customizable?", "source_row": 4, "_node_content": "{\\"id_\\": \\"5363e5b7-aade-4 ... (874 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__4': '5363e5b7-aade-42bf-a002-c95e9fa5a5a2', 'text__4': 'Question: What are your packages and services, and are they customizable?\nAnswer: We offer various packages to suit different budgets and needs, but everything is customizable. We want to create a wedding that reflects your unique style.', 'embedding__4': '[0.18516114354133606,0.18176941573619843,-0.4807659089565277,0.07530543208122253,-0.2630999982357025,-0.3887941241264343,0.11461488902568817,0.260589 ... (15212 characters truncated) ... 48058795929,0.28130581974983215,0.5471723675727844,0.35616534948349,0.29723745584487915,-0.7444131374359131,0.17499440908432007,-0.06981135904788971]', 'metadata___5': '{"faq_question": "Can you help with transportation for us and our guests?", "source_row": 5, "_node_content": "{\\"id_\\": \\"e624d2e2-9354-4db5-8309 ... (910 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__5': 'e624d2e2-9354-4db5-8309-39de3610d02a', 'text__5': 'Question: Can you help with transportation for us and our guests?\nAnswer: Yes sure! We have a list of trusted transport suppliers which we bring you in touch with, you can easily book transports to and from the venue and also any other transports you might need during your stay in Cyprus ', 'embedding__5': '[-0.01891215518116951,0.27805036306381226,-0.26254090666770935,-0.3483521640300751,0.2280627191066742,0.040553923696279526,0.3802729547023773,0.00970 ... (15230 characters truncated) ... 4461746,-0.15183523297309875,0.21415379643440247,0.04669906944036484,0.004004284739494324,-0.40705549716949463,0.3739958703517914,-0.234460711479187]', 'metadata___6': '{"faq_question": "How can we incorporate local traditions and customs into our wedding?", "source_row": 6, "_node_content": "{\\"id_\\": \\"8aba435a- ... (870 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__6': '8aba435a-8cad-4b5e-9a26-56e4f51a92fe', 'text__6': 'Question: How can we incorporate local traditions and customs into our wedding?\nAnswer: Cyprus has beautiful traditions we can incorporate, such as traditional music, food, or even a local priest for a religious ceremony.', 'embedding__6': '[-0.23409371078014374,0.4929719567298889,-0.23213011026382446,-0.06337838619947433,-0.024335697293281555,-0.327396959066391,0.36467206478118896,0.424 ... (15200 characters truncated) ... 8970032,0.23291796445846558,0.08278027176856995,0.3010680079460144,0.26749566197395325,-0.47162240743637085,0.14225147664546967,-0.11935684084892273]', 'metadata___7': '{"faq_question": "Do you have experience with weddings for couples of different nationalities or religions?", "source_row": 7, "_node_content": "{\\" ... (940 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__7': '79135e45-4d86-40f4-9039-0786c30fbe4c', 'text__7': "Question: Do you have experience with weddings for couples of different nationalities or religions?\nAnswer: Yes, we've organized weddings for couples from all over the world and various backgrounds. We respect and accommodate all beliefs and customs.", 'embedding__7': '[0.06875752657651901,0.27722012996673584,-0.06382660567760468,-0.19314879179000854,-0.09819400310516357,0.008859539404511452,-0.009044598788022995,0. ... (15179 characters truncated) ... 7883815765,0.05352269858121872,0.43855059146881104,0.0607406422495842,0.2252410352230072,-0.2941257655620575,0.3680281341075897,-0.22929289937019348]', 'metadata___8': '{"faq_question": "What is your cancellation policy in case of unforeseen circumstances?", "source_row": 8, "_node_content": "{\\"id_\\": \\"de0fc271- ... (902 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__8': 'de0fc271-248d-4ff7-afa7-fb21e1df6c2a', 'text__8': 'Question: What is your cancellation policy in case of unforeseen circumstances?\nAnswer: We have a transparent cancellation policy outlined in our contract, protecting both your investment and our services. We can discuss details during our consultation.', 'embedding__8': '[-0.020357811823487282,-0.10924111306667328,-0.2745758295059204,-0.5551841259002686,0.04945188760757446,0.35376301407814026,0.3879642188549042,-0.024 ... (15196 characters truncated) ... 329216,0.053629495203495026,0.35228097438812256,0.07057338953018188,0.14756573736667633,-0.3221468925476074,0.07415144890546799,-0.26672065258026123]', 'metadata___9': '{"faq_question": "How far in advance should we book your services?", "source_row": 9, "_node_content": "{\\"id_\\": \\"496cb40d-ec33-4b6f-8757-ad282f ... (805 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__9': '496cb40d-ec33-4b6f-8757-ad282fa3d0bd', 'text__9': 'Question: How far in advance should we book your services?\nAnswer: We recommend booking as early as possible, especially during peak season, to ensure we can secure your preferred dates and vendors.', 'embedding__9': '[-0.06584720313549042,-0.08790576457977295,-0.5529351234436035,-0.3439289629459381,-0.2877660393714905,-0.25096753239631653,0.12659229338169098,-0.04 ... (15147 characters truncated) ... 9424744,-0.35994887351989746,0.014688100665807724,0.08320001512765884,0.41052085161209106,-0.6536276936531067,0.04381462186574936,-0.308606892824173]', 'metadata___10': '{"faq_question": "Can you help with obtaining marriage licenses and translating documents if needed?", "source_row": 10, "_node_content": "{\\"id_\\" ... (887 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__10': '08ab0ad0-5590-4c7e-8f66-74de349fff59', 'text__10': 'Question: Can you help with obtaining marriage licenses and translating documents if needed?\nAnswer: Yes, we can guide you through the legal process, including obtaining and translating any necessary documents.', 'embedding__10': '[-0.2637054920196533,-0.08686833083629608,-0.19600872695446014,-0.055557601153850555,-0.36177223920822144,0.17875684797763824,-0.2390909641981125,0.2 ... (15160 characters truncated) ... 861389,-0.37473657727241516,0.26984959840774536,-0.12421508878469467,0.3806533217430115,-0.2524639070034027,0.33675071597099304,-0.04006791114807129]', 'metadata___11': '{"faq_question": "How can we personalize our wedding ceremony and reception?", "source_row": 11, "_node_content": "{\\"id_\\": \\"aab872ce-7271-46d6- ... (837 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__11': 'aab872ce-7271-46d6-b8d5-18203751e2a5', 'text__11': 'Question: How can we personalize our wedding ceremony and reception?\nAnswer: We can incorporate your personal touches, such as special music, readings, vows, decorations, and even unique activities or themes.', 'embedding__11': '[-0.02683606930077076,-0.04357989504933357,-0.1951148360967636,-0.013088025152683258,-0.1886277198791504,-0.1433347910642624,-0.14888396859169006,0.2 ... (15173 characters truncated) ... 9779053,-0.17095160484313965,0.16696088016033173,0.2502313256263733,0.4208065867424011,-0.5173802971839905,-0.17734214663505554,-0.32119297981262207]', 'metadata___12': '{"faq_question": "What happens if the weather is bad on our wedding day?", "source_row": 12, "_node_content": "{\\"id_\\": \\"1fa0f2e2-76e4-470c-a73f ... (889 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__12': '1fa0f2e2-76e4-470c-a73f-ec7da200b8c2' ... 436 parameters truncated ... 'text__121': 'Question: How much does a taxi costs from Paphos to Vasilias ? \nAnswer: Around 40 euro ', 'embedding__121': '[-0.15770503878593445,0.6388754844665527,-0.27804720401763916,-0.6920127868652344,0.058542609214782715,0.06835844367742538,0.8335205912590027,-0.0971 ... (15161 characters truncated) ... 8740387,0.4010736346244812,0.27147984504699707,-0.44448158144950867,0.08031021058559418,-0.05627095699310303,0.048078734427690506,0.1959514170885086]', 'metadata___122': '{"faq_question": "Can we post wedding items to the venue before our wedding?", "source_row": 122, "_node_content": "{\\"id_\\": \\"144c38cd-3b55-4e01 ... (753 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__122': '144c38cd-3b55-4e01-9cb8-df18f698f539', 'text__122': 'Question: Can we post wedding items to the venue before our wedding?\nAnswer: Yes you can post the earliest a month before ', 'embedding__122': '[-0.19515231251716614,0.3147919476032257,-0.23045963048934937,-0.11553336679935455,-0.04599759727716446,0.06320822238922119,-0.14123480021953583,-0.2 ... (15201 characters truncated) ... 936676025,-0.3647647500038147,0.4395207166671753,-0.28580960631370544,0.6473212838172913,-0.8310924768447876,0.3402029275894165,-0.09353954344987869]', 'metadata___123': '{"faq_question": "Can we bring our own favors ?", "source_row": 123, "_node_content": "{\\"id_\\": \\"58d8298e-157f-4f56-a6ac-cc99488306d3\\", \\"emb ... (649 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__123': '58d8298e-157f-4f56-a6ac-cc99488306d3', 'text__123': 'Question: Can we bring our own favors ?\nAnswer: Yes you can provide your own', 'embedding__123': '[0.025506503880023956,0.22347140312194824,-0.06367059797048569,-0.24240809679031372,0.03935837745666504,-0.09016233682632446,0.041989147663116455,0.3 ... (15229 characters truncated) ... 689041,0.1275702863931656,0.3553296625614166,-0.054992515593767166,0.35539400577545166,-0.4604572653770447,-0.02917395532131195,-0.31847524642944336]', 'metadata___124': '{"faq_question": "How far in advance do you take bookigs?", "source_row": 124, "_node_content": "{\\"id_\\": \\"b11a7cba-b79c-407d-b00c-8af45ffce3fc\ ... (676 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__124': 'b11a7cba-b79c-407d-b00c-8af45ffce3fc', 'text__124': 'Question: How far in advance do you take bookigs?\nAnswer: Up to 2 years in advance ', 'embedding__124': '[-0.30216097831726074,-0.00017205998301506042,-0.15174444019794464,-0.34879064559936523,-0.3267870545387268,-0.09297134727239609,0.1500449925661087,- ... (15226 characters truncated) ... 1817703247,0.012481000274419785,0.4267958700656891,0.32594993710517883,0.04610157012939453,0.182928666472435,-0.391973078250885,-0.09705314040184021]', 'metadata___125': '{"faq_question": "How far in advance are you booked up?", "source_row": 125, "_node_content": "{\\"id_\\": \\"bcb59374-d6e4-4c6d-a438-c0dfed4c3ad9\\" ... (669 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__125': 'bcb59374-d6e4-4c6d-a438-c0dfed4c3ad9', 'text__125': 'Question: How far in advance are you booked up?\nAnswer: Up to 1 year in advance ', 'embedding__125': '[-0.33688053488731384,-0.21530936658382416,-0.16100652515888214,-0.2653713524341583,-0.2903323769569397,-0.22002924978733063,0.08994083106517792,-0.2 ... (15202 characters truncated) ... 09845,0.24601230025291443,-0.09794764965772629,-0.06763912737369537,0.01398925855755806,0.31628912687301636,-0.31945517659187317,-0.1583274006843567]', 'metadata___126': '{"faq_question": "Is there a first aid kit available ?", "source_row": 126, "_node_content": "{\\"id_\\": \\"c4ea4283-193a-45ef-ad7c-df43784082e8\\", ... (655 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__126': 'c4ea4283-193a-45ef-ad7c-df43784082e8', 'text__126': 'Question: Is there a first aid kit available ?\nAnswer: Yes there is ', 'embedding__126': '[0.0304524227976799,-0.14606139063835144,-0.2239091992378235,-0.37444695830345154,0.024784967303276062,0.222834512591362,0.1782919466495514,-0.272564 ... (15196 characters truncated) ... 647140503,0.40965139865875244,0.12355506420135498,-0.2090899497270584,0.287910133600235,-0.2985665202140808,-0.25728705525398254,0.05402957275509834]', 'metadata___127': '{"faq_question": "Up to what age do you consider a child?", "source_row": 127, "_node_content": "{\\"id_\\": \\"47749321-40bc-416c-8521-fcd10cc7b8f9\ ... (697 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__127': '47749321-40bc-416c-8521-fcd10cc7b8f9', 'text__127': 'Question: Up to what age do you consider a child?\nAnswer: Up to 12 years can order from childrens meals ', 'embedding__127': '[-0.2324862778186798,0.3412618637084961,-0.10883787274360657,-0.221495121717453,0.10904595255851746,-0.5179325938224792,0.24970993399620056,0.1242596 ... (15184 characters truncated) ... 5817,0.36752042174339294,-0.13929787278175354,-0.2686048150062561,-0.13785038888454437,-0.3750908374786377,-0.07507124543190002,-0.00916360318660736]', 'metadata___128': '{"faq_question": "Do you offer non alcoholic drinks ", "source_row": 128, "_node_content": "{\\"id_\\": \\"2f524dfc-fbfe-4d9b-a479-22ad0c3e6533\\", \ ... (743 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__128': '2f524dfc-fbfe-4d9b-a479-22ad0c3e6533', 'text__128': 'Question: Do you offer non alcoholic drinks \nAnswer: Yes of course,we offer non alcoholic cocktails from the bar, non alcoholic beer and non alcoholic prosecco ', 'embedding__128': '[0.34326720237731934,0.20031070709228516,-0.5987007021903992,-0.1334114819765091,0.1741781234741211,-0.5700263381004333,-0.181863471865654,0.03126370 ... (15175 characters truncated) ... 16518402,0.08591493964195251,0.06669119745492935,-0.08271299302577972,0.14794357120990753,-0.5042476058006287,0.7182580232620239,0.40741899609565735]', 'metadata___129': '{"faq_question": "Does the venue have fairy lights? Do they cost extra? ", "source_row": 129, "_node_content": "{\\"id_\\": \\"c61a11db-a20d-4755-a1d ... (776 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__129': 'c61a11db-a20d-4755-a1de-224d525ebd75', 'text__129': 'Question: Does the venue have fairy lights? Do they cost extra? \nAnswer: Yes fairy lights are set above the main dinner area no additional charge applies', 'embedding__129': '[0.16269883513450623,0.28159794211387634,-0.10124820470809937,-0.3691040575504303,-0.005947142839431763,-0.6862460374832153,0.028522752225399017,-0.2 ... (15212 characters truncated) ... 9022217,-0.007166797295212746,0.26253095269203186,0.23211561143398285,0.014487173408269882,-0.4490588903427124,0.340745210647583,0.47061339020729065]', 'metadata___130': '{"faq_question": "Do you offer fairy lights packages?", "source_row": 130, "_node_content": "{\\"id_\\": \\"57dac944-60a8-4934-8bb0-73820db15c7b\\",  ... (700 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__130': '57dac944-60a8-4934-8bb0-73820db15c7b', 'text__130': 'Question: Do you offer fairy lights packages?\nAnswer: Yes you can hire fairy light packages from suggested ventors ', 'embedding__130': '[-0.14023417234420776,0.36608266830444336,0.0024645747616887093,-0.15101459622383118,-0.13540729880332947,-0.7092093825340271,0.17226211726665497,-0. ... (15149 characters truncated) ... 279404,-0.09151139855384827,0.5400651097297668,-0.13986440002918243,0.27341264486312866,-0.31935176253318787,0.27299264073371887,0.08155647665262222]', 'metadata___131': '{"faq_question": "Is your venue child friendly?", "source_row": 131, "_node_content": "{\\"id_\\": \\"8a03e895-5b1f-42d5-8d9b-7b94b67db0bb\\", \\"emb ... (724 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__131': '8a03e895-5b1f-42d5-8d9b-7b94b67db0bb', 'text__131': 'Question: Is your venue child friendly?\nAnswer: Yes we would say our venue is child friendly, we welcome families with young children most of the time ', 'embedding__131': '[-0.04612556844949722,0.16317394375801086,-0.1737814098596573,-0.04784194380044937,0.06411148607730865,-0.32366329431533813,0.0945717841386795,-0.193 ... (15236 characters truncated) ... 567139,0.4568428695201874,0.12162032723426819,-0.48239704966545105,-0.08953899145126343,-0.6002140045166016,0.32986390590667725,-0.05565628409385681]', 'metadata___132': '{"faq_question": "Are there any facilities in rooms?", "source_row": 132, "_node_content": "{\\"id_\\": \\"6d96da56-7094-40b4-b495-66842882336e\\", \ ... (807 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__132': '6d96da56-7094-40b4-b495-66842882336e', 'text__132': 'Question: Are there any facilities in rooms?\nAnswer: Yes of course, in our rooms we provide tea and coffee facilities, hairdryer, safe, mini fridge with small bottles of water. For the shower we provide shower gel and soap. ', 'embedding__132': '[-0.3447050154209137,0.021847084164619446,-0.1448233723640442,-0.3473523259162903,0.258108526468277,-0.32724320888519287,0.18152084946632385,0.205354 ... (15184 characters truncated) ... 8361377716,0.18088412284851074,0.7909275889396667,0.6805284023284912,0.16548079252243042,-0.515394389629364,0.28657087683677673,-0.00385187566280365]', 'metadata___133': '{"faq_question": "Is there a smoking area? ", "source_row": 133, "_node_content": "{\\"id_\\": \\"7788517f-b6a5-414f-baa2-c7de195b5460\\", \\"embeddi ... (746 characters truncated) ... \\", \\"class_name\\": \\"Document\\", \\"text\\": \\"\\"}", "_node_type": "Document", "document_id": "None", "doc_id": "None", "ref_doc_id": "None"}', 'node_id__133': '7788517f-b6a5-414f-baa2-c7de195b5460', 'text__133': 'Question: Is there a smoking area? \nAnswer: There is no designated area for smoking however we encourage guests to use the carob tree area for smoking as we provide ashtrays there. ', 'embedding__133': '[-0.06579308211803436,0.3279893398284912,0.05980006605386734,-0.14079144597053528,-0.2322801947593689,-0.41900554299354553,0.0006515756249427795,0.37 ... (15202 characters truncated) ... 53666687,-0.002482471987605095,0.28870058059692383,0.27223315834999084,0.1544445902109146,-0.4236335754394531,0.26030421257019043,0.2745744585990906]'}]
(Background on this error at: https://sqlalche.me/e/20/f405)
2025-07-11 16:13:51,298 - INFO - Local LLM initialized successfully
2025-07-11 16:13:51,654 - INFO - Local embedding model initialized successfully
2025-07-11 16:13:51,661 - INFO - Documents loaded successfully from ./data/VW_dataMar25.txt
2025-07-11 16:13:51,670 - INFO - Connecting to PostgreSQL database: chatbot_rag at 167.99.197.215:5432 as user chatbot
2025-07-11 16:13:51,670 - INFO - Using table name: vasilias_weddings_2025_07_11
2025-07-11 16:13:51,671 - INFO - Vector store created successfully: vasilias_weddings_2025_07_11
2025-07-11 16:13:51,671 - INFO - Storing documents in table: vasilias_weddings_2025_07_11
2025-07-11 16:13:52,032 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:52,544 - INFO - Stored 1 documents in table: vasilias_weddings_2025_07_11
2025-07-11 16:13:52,545 - INFO - Local LLM initialized successfully
2025-07-11 16:13:52,569 - INFO - Local embedding model initialized successfully
2025-07-11 16:13:52,581 - INFO - Parsed 134 documents from CSV file ./data/VWFAQ24052025.csv
2025-07-11 16:13:52,581 - INFO - Documents loaded successfully from ./data/VWFAQ24052025.csv
2025-07-11 16:13:52,581 - INFO - First document: Question: Can you help with legal requirements for...
2025-07-11 16:13:52,595 - INFO - Connecting to PostgreSQL database: chatbot_rag at 167.99.197.215:5432 as user chatbot
2025-07-11 16:13:52,595 - INFO - Using table name: vasilias_weddings_2025_07_11
2025-07-11 16:13:52,596 - INFO - Vector store created successfully: vasilias_weddings_2025_07_11
2025-07-11 16:13:52,596 - INFO - Storing documents in table: vasilias_weddings_2025_07_11
2025-07-11 16:13:52,638 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:52,665 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:52,687 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:52,710 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:52,730 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:52,756 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:52,780 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:52,806 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:52,834 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:52,862 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:52,891 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:52,920 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:52,949 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:52,973 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:52,995 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,018 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,042 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,060 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,081 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,103 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,124 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,144 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,161 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,183 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,207 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,235 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,259 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,282 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,306 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,323 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,340 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,360 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,378 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,401 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,419 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,440 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,461 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,479 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,501 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,518 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,538 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,554 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,573 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,589 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,607 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,626 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,648 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,671 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,691 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,708 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,730 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,752 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,778 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,794 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,813 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,830 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,847 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,868 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,888 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,914 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,939 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,965 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,983 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:53,999 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,017 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,043 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,061 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,083 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,104 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,117 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,133 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,150 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,169 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,187 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,206 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,223 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,244 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,266 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,288 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,307 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,324 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,343 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,362 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,377 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,394 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,409 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,425 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,440 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,456 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,473 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,490 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,512 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,531 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,554 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,572 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,589 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,611 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,629 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,651 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,667 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,687 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,708 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,726 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,750 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,770 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,792 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,810 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,830 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,848 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,871 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,888 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,906 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,924 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,940 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,964 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:54,986 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:55,008 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:55,030 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:55,047 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:55,067 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:55,088 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:55,110 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:55,130 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:55,148 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:55,169 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:55,190 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:55,208 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:55,231 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:55,253 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:55,279 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:55,301 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:55,327 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:55,358 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:55,382 - INFO - HTTP Request: POST http://localhost:11434/api/embeddings "HTTP/1.1 200 OK"
2025-07-11 16:13:56,080 - INFO - Stored 134 documents in table: vasilias_weddings_2025_07_11
